I0603 04:24:33.434226   822 caffe.cpp:279] Use CPU.
I0603 04:24:33.434690   822 solver.cpp:108] Initializing solver from parameters: 
base_lr: 0.01
display: 2
max_iter: 960
lr_policy: "poly"
power: 0.5
momentum: 0.9
weight_decay: 0.0002
snapshot: 32
snapshot_prefix: "/workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot"
solver_mode: CPU
net: "/workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
regularization_type: "L2"
clip_gradients: -1
type: "SGD"
engine: "MKL2017"
I0603 04:24:33.434700   822 solver.cpp:157] Creating training net from net file: /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/train_val.prototxt
I0603 04:24:33.437870   822 cpu_info.cpp:452] Processor speed [MHz]: 2300
I0603 04:24:33.437887   822 cpu_info.cpp:455] Total number of sockets: 1
I0603 04:24:33.437892   822 cpu_info.cpp:458] Total number of CPU cores: 2
I0603 04:24:33.437896   822 cpu_info.cpp:461] Total number of processors: 4
I0603 04:24:33.437901   822 cpu_info.cpp:464] GPU is used: no
I0603 04:24:33.437904   822 cpu_info.cpp:467] OpenMP environmental variables are specified: no
I0603 04:24:33.437908   822 cpu_info.cpp:470] OpenMP thread bind allowed: yes
I0603 04:24:33.437913   822 cpu_info.cpp:473] Number of OpenMP threads: 2
I0603 04:24:33.438385   822 net.cpp:790] The NetState phase (0) differed from the phase (1) specified by a rule in layer DataColor256
I0603 04:24:33.438454   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/ave_pool
I0603 04:24:33.438462   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/conv
I0603 04:24:33.438469   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/relu_conv
I0603 04:24:33.438475   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/fc
I0603 04:24:33.438482   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/relu_fc
I0603 04:24:33.438488   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/drop_fc
I0603 04:24:33.438493   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/classifier
I0603 04:24:33.438500   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/loss
I0603 04:24:33.438508   822 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss1/top-1
I0603 04:24:33.438513   822 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss1/top-5
I0603 04:24:33.438554   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/ave_pool
I0603 04:24:33.438561   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/conv
I0603 04:24:33.438568   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/relu_conv
I0603 04:24:33.438573   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/fc
I0603 04:24:33.438580   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/relu_fc
I0603 04:24:33.438585   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/drop_fc
I0603 04:24:33.438591   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/classifier
I0603 04:24:33.438597   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/loss
I0603 04:24:33.438603   822 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss2/top-1
I0603 04:24:33.438608   822 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss2/top-5
I0603 04:24:33.438652   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss3/loss
I0603 04:24:33.438659   822 net.cpp:790] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I0603 04:24:33.438683   822 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer softmax
I0603 04:24:33.441599   822 net.cpp:156] Initializing net from parameters: 
I0603 04:24:33.441619   822 net.cpp:157] 
name: "Model4.256"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "DataColor256"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    mean_file: "/workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/mean.binaryproto"
  }
  data_param {
    source: "/workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/train.txt_LMDB"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "label_DataColor256_1_split"
  type: "Split"
  bottom: "label"
  top: "label_DataColor256_1_split_0"
  top: "label_DataColor256_1_split_1"
  top: "label_DataColor256_1_split_2"
  top: "label_DataColor256_1_split_3"
}
layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "data"
  top: "conv1/7x7_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu_7x7"
  type: "ReLU"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/7x7_s2"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1/norm1"
  type: "LRN"
  bottom: "pool1/3x3_s2"
  top: "pool1/norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2/3x3_reduce"
  type: "Convolution"
  bottom: "pool1/norm1"
  top: "conv2/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu_3x3_reduce"
  type: "ReLU"
  bottom: "conv2/3x3_reduce"
  top: "conv2/3x3_reduce"
}
layer {
  name: "conv2/3x3"
  type: "Convolution"
  bottom: "conv2/3x3_reduce"
  top: "conv2/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu_3x3"
  type: "ReLU"
  bottom: "conv2/3x3"
  top: "conv2/3x3"
}
layer {
  name: "conv2/norm2"
  type: "LRN"
  bottom: "conv2/3x3"
  top: "conv2/norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2/3x3_s2"
  type: "Pooling"
  bottom: "conv2/norm2"
  top: "pool2/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2/3x3_s2_pool2/3x3_s2_0_split"
  type: "Split"
  bottom: "pool2/3x3_s2"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_0"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_1"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_2"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_3"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_0"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_1"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/5x5_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_2"
  top: "inception_3a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_3a/5x5_reduce"
  top: "inception_3a/5x5_reduce"
}
layer {
  name: "inception_3a/5x5"
  type: "Convolution"
  bottom: "inception_3a/5x5_reduce"
  top: "inception_3a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_5x5"
  type: "ReLU"
  bottom: "inception_3a/5x5"
  top: "inception_3a/5x5"
}
layer {
  name: "inception_3a/pool"
  type: "Pooling"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_3"
  top: "inception_3a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3a/pool_proj"
  type: "Convolution"
  bottom: "inception_3a/pool"
  top: "inception_3a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/pool_proj"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  bottom: "inception_3a/5x5"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/output"
}
layer {
  name: "inception_3a/output_inception_3a/output_0_split"
  type: "Split"
  bottom: "inception_3a/output"
  top: "inception_3a/output_inception_3a/output_0_split_0"
  top: "inception_3a/output_inception_3a/output_0_split_1"
  top: "inception_3a/output_inception_3a/output_0_split_2"
  top: "inception_3a/output_inception_3a/output_0_split_3"
}
layer {
  name: "inception_3b/1x1"
  type: "Convolution"
  bottom: "inception_3a/output_inception_3a/output_0_split_0"
  top: "inception_3b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_1x1"
  type: "ReLU"
  bottom: "inception_3b/1x1"
  top: "inception_3b/1x1"
}
layer {
  name: "inception_3b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3a/output_inception_3a/output_0_split_1"
  top: "inception_3b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3b/3x3_reduce"
  top: "inception_3b/3x3_reduce"
}
layer {
  name: "inception_3b/3x3"
  type: "Convolution"
  bottom: "inception_3b/3x3_reduce"
  top: "inception_3b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_3x3"
  type: "ReLU"
  bottom: "inception_3b/3x3"
  top: "inception_3b/3x3"
}
layer {
  name: "inception_3b/5x5_reduce"
  type: "Convolution"
  bottom: "inception_3a/output_inception_3a/output_0_split_2"
  top: "inception_3b/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_3b/5x5_reduce"
  top: "inception_3b/5x5_reduce"
}
layer {
  name: "inception_3b/5x5"
  type: "Convolution"
  bottom: "inception_3b/5x5_reduce"
  top: "inception_3b/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_5x5"
  type: "ReLU"
  bottom: "inception_3b/5x5"
  top: "inception_3b/5x5"
}
layer {
  name: "inception_3b/pool"
  type: "Pooling"
  bottom: "inception_3a/output_inception_3a/output_0_split_3"
  top: "inception_3b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3b/pool_proj"
  type: "Convolution"
  bottom: "inception_3b/pool"
  top: "inception_3b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3b/pool_proj"
  top: "inception_3b/pool_proj"
}
layer {
  name: "inception_3b/output"
  type: "Concat"
  bottom: "inception_3b/1x1"
  bottom: "inception_3b/3x3"
  bottom: "inception_3b/5x5"
  bottom: "inception_3b/pool_proj"
  top: "inception_3b/output"
}
layer {
  name: "pool3/3x3_s2"
  type: "Pooling"
  bottom: "inception_3b/output"
  top: "pool3/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool3/3x3_s2_pool3/3x3_s2_0_split"
  type: "Split"
  bottom: "pool3/3x3_s2"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_0"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_1"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_2"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_3"
}
layer {
  name: "inception_4a/1x1"
  type: "Convolution"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_0"
  top: "inception_4a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_1x1"
  type: "ReLU"
  bottom: "inception_4a/1x1"
  top: "inception_4a/1x1"
}
layer {
  name: "inception_4a/3x3_reduce"
  type: "Convolution"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_1"
  top: "inception_4a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4a/3x3_reduce"
  top: "inception_4a/3x3_reduce"
}
layer {
  name: "inception_4a/3x3"
  type: "Convolution"
  bottom: "inception_4a/3x3_reduce"
  top: "inception_4a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 208
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_3x3"
  type: "ReLU"
  bottom: "inception_4a/3x3"
  top: "inception_4a/3x3"
}
layer {
  name: "inception_4a/5x5_reduce"
  type: "Convolution"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_2"
  top: "inception_4a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4a/5x5_reduce"
  top: "inception_4a/5x5_reduce"
}
layer {
  name: "inception_4a/5x5"
  type: "Convolution"
  bottom: "inception_4a/5x5_reduce"
  top: "inception_4a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_5x5"
  type: "ReLU"
  bottom: "inception_4a/5x5"
  top: "inception_4a/5x5"
}
layer {
  name: "inception_4a/pool"
  type: "Pooling"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_3"
  top: "inception_4a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4a/pool_proj"
  type: "Convolution"
  bottom: "inception_4a/pool"
  top: "inception_4a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4a/pool_proj"
  top: "inception_4a/pool_proj"
}
layer {
  name: "inception_4a/output"
  type: "Concat"
  bottom: "inception_4a/1x1"
  bottom: "inception_4a/3x3"
  bottom: "inception_4a/5x5"
  bottom: "inception_4a/pool_proj"
  top: "inception_4a/output"
}
layer {
  name: "inception_4a/output_inception_4a/output_0_split"
  type: "Split"
  bottom: "inception_4a/output"
  top: "inception_4a/output_inception_4a/output_0_split_0"
  top: "inception_4a/output_inception_4a/output_0_split_1"
  top: "inception_4a/output_inception_4a/output_0_split_2"
  top: "inception_4a/output_inception_4a/output_0_split_3"
  top: "inception_4a/output_inception_4a/output_0_split_4"
}
layer {
  name: "loss1/ave_pool"
  type: "Pooling"
  bottom: "inception_4a/output_inception_4a/output_0_split_0"
  top: "loss1/ave_pool"
  exclude {
    stage: "deploy"
  }
  pooling_param {
    pool: AVE
    kernel_size: 5
    stride: 3
  }
}
layer {
  name: "loss1/conv"
  type: "Convolution"
  bottom: "loss1/ave_pool"
  top: "loss1/conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss1/relu_conv"
  type: "ReLU"
  bottom: "loss1/conv"
  top: "loss1/conv"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss1/fc"
  type: "InnerProduct"
  bottom: "loss1/conv"
  top: "loss1/fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
      std: 0.02
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss1/relu_fc"
  type: "ReLU"
  bottom: "loss1/fc"
  top: "loss1/fc"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss1/drop_fc"
  type: "Dropout"
  bottom: "loss1/fc"
  top: "loss1/fc"
  exclude {
    stage: "deploy"
  }
  dropout_param {
    dropout_ratio: 0.7
  }
}
layer {
  name: "loss1/classifier"
  type: "InnerProduct"
  bottom: "loss1/fc"
  top: "loss1/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
      std: 0.0009765625
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss1/loss"
  type: "SoftmaxWithLoss"
  bottom: "loss1/classifier"
  bottom: "label_DataColor256_1_split_0"
  top: "loss1/loss"
  loss_weight: 0.3
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "inception_4b/1x1"
  type: "Convolution"
  bottom: "inception_4a/output_inception_4a/output_0_split_1"
  top: "inception_4b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_1x1"
  type: "ReLU"
  bottom: "inception_4b/1x1"
  top: "inception_4b/1x1"
}
layer {
  name: "inception_4b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4a/output_inception_4a/output_0_split_2"
  top: "inception_4b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4b/3x3_reduce"
  top: "inception_4b/3x3_reduce"
}
layer {
  name: "inception_4b/3x3"
  type: "Convolution"
  bottom: "inception_4b/3x3_reduce"
  top: "inception_4b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 224
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_3x3"
  type: "ReLU"
  bottom: "inception_4b/3x3"
  top: "inception_4b/3x3"
}
layer {
  name: "inception_4b/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4a/output_inception_4a/output_0_split_3"
  top: "inception_4b/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4b/5x5_reduce"
  top: "inception_4b/5x5_reduce"
}
layer {
  name: "inception_4b/5x5"
  type: "Convolution"
  bottom: "inception_4b/5x5_reduce"
  top: "inception_4b/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_5x5"
  type: "ReLU"
  bottom: "inception_4b/5x5"
  top: "inception_4b/5x5"
}
layer {
  name: "inception_4b/pool"
  type: "Pooling"
  bottom: "inception_4a/output_inception_4a/output_0_split_4"
  top: "inception_4b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4b/pool_proj"
  type: "Convolution"
  bottom: "inception_4b/pool"
  top: "inception_4b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4b/pool_proj"
  top: "inception_4b/pool_proj"
}
layer {
  name: "inception_4b/output"
  type: "Concat"
  bottom: "inception_4b/1x1"
  bottom: "inception_4b/3x3"
  bottom: "inception_4b/5x5"
  bottom: "inception_4b/pool_proj"
  top: "inception_4b/output"
}
layer {
  name: "inception_4b/output_inception_4b/output_0_split"
  type: "Split"
  bottom: "inception_4b/output"
  top: "inception_4b/output_inception_4b/output_0_split_0"
  top: "inception_4b/output_inception_4b/output_0_split_1"
  top: "inception_4b/output_inception_4b/output_0_split_2"
  top: "inception_4b/output_inception_4b/output_0_split_3"
}
layer {
  name: "inception_4c/1x1"
  type: "Convolution"
  bottom: "inception_4b/output_inception_4b/output_0_split_0"
  top: "inception_4c/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_1x1"
  type: "ReLU"
  bottom: "inception_4c/1x1"
  top: "inception_4c/1x1"
}
layer {
  name: "inception_4c/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4b/output_inception_4b/output_0_split_1"
  top: "inception_4c/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4c/3x3_reduce"
  top: "inception_4c/3x3_reduce"
}
layer {
  name: "inception_4c/3x3"
  type: "Convolution"
  bottom: "inception_4c/3x3_reduce"
  top: "inception_4c/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_3x3"
  type: "ReLU"
  bottom: "inception_4c/3x3"
  top: "inception_4c/3x3"
}
layer {
  name: "inception_4c/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4b/output_inception_4b/output_0_split_2"
  top: "inception_4c/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4c/5x5_reduce"
  top: "inception_4c/5x5_reduce"
}
layer {
  name: "inception_4c/5x5"
  type: "Convolution"
  bottom: "inception_4c/5x5_reduce"
  top: "inception_4c/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_5x5"
  type: "ReLU"
  bottom: "inception_4c/5x5"
  top: "inception_4c/5x5"
}
layer {
  name: "inception_4c/pool"
  type: "Pooling"
  bottom: "inception_4b/output_inception_4b/output_0_split_3"
  top: "inception_4c/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4c/pool_proj"
  type: "Convolution"
  bottom: "inception_4c/pool"
  top: "inception_4c/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4c/pool_proj"
  top: "inception_4c/pool_proj"
}
layer {
  name: "inception_4c/output"
  type: "Concat"
  bottom: "inception_4c/1x1"
  bottom: "inception_4c/3x3"
  bottom: "inception_4c/5x5"
  bottom: "inception_4c/pool_proj"
  top: "inception_4c/output"
}
layer {
  name: "inception_4c/output_inception_4c/output_0_split"
  type: "Split"
  bottom: "inception_4c/output"
  top: "inception_4c/output_inception_4c/output_0_split_0"
  top: "inception_4c/output_inception_4c/output_0_split_1"
  top: "inception_4c/output_inception_4c/output_0_split_2"
  top: "inception_4c/output_inception_4c/output_0_split_3"
}
layer {
  name: "inception_4d/1x1"
  type: "Convolution"
  bottom: "inception_4c/output_inception_4c/output_0_split_0"
  top: "inception_4d/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_1x1"
  type: "ReLU"
  bottom: "inception_4d/1x1"
  top: "inception_4d/1x1"
}
layer {
  name: "inception_4d/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4c/output_inception_4c/output_0_split_1"
  top: "inception_4d/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4d/3x3_reduce"
  top: "inception_4d/3x3_reduce"
}
layer {
  name: "inception_4d/3x3"
  type: "Convolution"
  bottom: "inception_4d/3x3_reduce"
  top: "inception_4d/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 288
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_3x3"
  type: "ReLU"
  bottom: "inception_4d/3x3"
  top: "inception_4d/3x3"
}
layer {
  name: "inception_4d/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4c/output_inception_4c/output_0_split_2"
  top: "inception_4d/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4d/5x5_reduce"
  top: "inception_4d/5x5_reduce"
}
layer {
  name: "inception_4d/5x5"
  type: "Convolution"
  bottom: "inception_4d/5x5_reduce"
  top: "inception_4d/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_5x5"
  type: "ReLU"
  bottom: "inception_4d/5x5"
  top: "inception_4d/5x5"
}
layer {
  name: "inception_4d/pool"
  type: "Pooling"
  bottom: "inception_4c/output_inception_4c/output_0_split_3"
  top: "inception_4d/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4d/pool_proj"
  type: "Convolution"
  bottom: "inception_4d/pool"
  top: "inception_4d/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4d/pool_proj"
  top: "inception_4d/pool_proj"
}
layer {
  name: "inception_4d/output"
  type: "Concat"
  bottom: "inception_4d/1x1"
  bottom: "inception_4d/3x3"
  bottom: "inception_4d/5x5"
  bottom: "inception_4d/pool_proj"
  top: "inception_4d/output"
}
layer {
  name: "inception_4d/output_inception_4d/output_0_split"
  type: "Split"
  bottom: "inception_4d/output"
  top: "inception_4d/output_inception_4d/output_0_split_0"
  top: "inception_4d/output_inception_4d/output_0_split_1"
  top: "inception_4d/output_inception_4d/output_0_split_2"
  top: "inception_4d/output_inception_4d/output_0_split_3"
  top: "inception_4d/output_inception_4d/output_0_split_4"
}
layer {
  name: "loss2/ave_pool"
  type: "Pooling"
  bottom: "inception_4d/output_inception_4d/output_0_split_0"
  top: "loss2/ave_pool"
  exclude {
    stage: "deploy"
  }
  pooling_param {
    pool: AVE
    kernel_size: 5
    stride: 3
  }
}
layer {
  name: "loss2/conv"
  type: "Convolution"
  bottom: "loss2/ave_pool"
  top: "loss2/conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss2/relu_conv"
  type: "ReLU"
  bottom: "loss2/conv"
  top: "loss2/conv"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss2/fc"
  type: "InnerProduct"
  bottom: "loss2/conv"
  top: "loss2/fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
      std: 0.02
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss2/relu_fc"
  type: "ReLU"
  bottom: "loss2/fc"
  top: "loss2/fc"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss2/drop_fc"
  type: "Dropout"
  bottom: "loss2/fc"
  top: "loss2/fc"
  exclude {
    stage: "deploy"
  }
  dropout_param {
    dropout_ratio: 0.7
  }
}
layer {
  name: "loss2/classifier"
  type: "InnerProduct"
  bottom: "loss2/fc"
  top: "loss2/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
      std: 0.0009765625
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss2/loss"
  type: "SoftmaxWithLoss"
  bottom: "loss2/classifier"
  bottom: "label_DataColor256_1_split_1"
  top: "loss2/loss"
  loss_weight: 0.3
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "inception_4e/1x1"
  type: "Convolution"
  bottom: "inception_4d/output_inception_4d/output_0_split_1"
  top: "inception_4e/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_1x1"
  type: "ReLU"
  bottom: "inception_4e/1x1"
  top: "inception_4e/1x1"
}
layer {
  name: "inception_4e/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4d/output_inception_4d/output_0_split_2"
  top: "inception_4e/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4e/3x3_reduce"
  top: "inception_4e/3x3_reduce"
}
layer {
  name: "inception_4e/3x3"
  type: "Convolution"
  bottom: "inception_4e/3x3_reduce"
  top: "inception_4e/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_3x3"
  type: "ReLU"
  bottom: "inception_4e/3x3"
  top: "inception_4e/3x3"
}
layer {
  name: "inception_4e/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4d/output_inception_4d/output_0_split_3"
  top: "inception_4e/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4e/5x5_reduce"
  top: "inception_4e/5x5_reduce"
}
layer {
  name: "inception_4e/5x5"
  type: "Convolution"
  bottom: "inception_4e/5x5_reduce"
  top: "inception_4e/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_5x5"
  type: "ReLU"
  bottom: "inception_4e/5x5"
  top: "inception_4e/5x5"
}
layer {
  name: "inception_4e/pool"
  type: "Pooling"
  bottom: "inception_4d/output_inception_4d/output_0_split_4"
  top: "inception_4e/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4e/pool_proj"
  type: "Convolution"
  bottom: "inception_4e/pool"
  top: "inception_4e/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4e/pool_proj"
  top: "inception_4e/pool_proj"
}
layer {
  name: "inception_4e/output"
  type: "Concat"
  bottom: "inception_4e/1x1"
  bottom: "inception_4e/3x3"
  bottom: "inception_4e/5x5"
  bottom: "inception_4e/pool_proj"
  top: "inception_4e/output"
}
layer {
  name: "pool4/3x3_s2"
  type: "Pooling"
  bottom: "inception_4e/output"
  top: "pool4/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool4/3x3_s2_pool4/3x3_s2_0_split"
  type: "Split"
  bottom: "pool4/3x3_s2"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_0"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_1"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_2"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_3"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_0"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_1x1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3_reduce"
  type: "Convolution"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_1"
  top: "inception_5a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_5a/3x3_reduce"
  top: "inception_5a/3x3_reduce"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "inception_5a/3x3_reduce"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_3x3"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/5x5_reduce"
  type: "Convolution"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_2"
  top: "inception_5a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_5a/5x5_reduce"
  top: "inception_5a/5x5_reduce"
}
layer {
  name: "inception_5a/5x5"
  type: "Convolution"
  bottom: "inception_5a/5x5_reduce"
  top: "inception_5a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_5x5"
  type: "ReLU"
  bottom: "inception_5a/5x5"
  top: "inception_5a/5x5"
}
layer {
  name: "inception_5a/pool"
  type: "Pooling"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_3"
  top: "inception_5a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_5a/pool_proj"
  type: "Convolution"
  bottom: "inception_5a/pool"
  top: "inception_5a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_5a/pool_proj"
  top: "inception_5a/pool_proj"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  bottom: "inception_5a/5x5"
  bottom: "inception_5a/pool_proj"
  top: "inception_5a/output"
}
layer {
  name: "inception_5a/output_inception_5a/output_0_split"
  type: "Split"
  bottom: "inception_5a/output"
  top: "inception_5a/output_inception_5a/output_0_split_0"
  top: "inception_5a/output_inception_5a/output_0_split_1"
  top: "inception_5a/output_inception_5a/output_0_split_2"
  top: "inception_5a/output_inception_5a/output_0_split_3"
}
layer {
  name: "inception_5b/1x1"
  type: "Convolution"
  bottom: "inception_5a/output_inception_5a/output_0_split_0"
  top: "inception_5b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_1x1"
  type: "ReLU"
  bottom: "inception_5b/1x1"
  top: "inception_5b/1x1"
}
layer {
  name: "inception_5b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_5a/output_inception_5a/output_0_split_1"
  top: "inception_5b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_5b/3x3_reduce"
  top: "inception_5b/3x3_reduce"
}
layer {
  name: "inception_5b/3x3"
  type: "Convolution"
  bottom: "inception_5b/3x3_reduce"
  top: "inception_5b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_3x3"
  type: "ReLU"
  bottom: "inception_5b/3x3"
  top: "inception_5b/3x3"
}
layer {
  name: "inception_5b/5x5_reduce"
  type: "Convolution"
  bottom: "inception_5a/output_inception_5a/output_0_split_2"
  top: "inception_5b/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_5b/5x5_reduce"
  top: "inception_5b/5x5_reduce"
}
layer {
  name: "inception_5b/5x5"
  type: "Convolution"
  bottom: "inception_5b/5x5_reduce"
  top: "inception_5b/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_5x5"
  type: "ReLU"
  bottom: "inception_5b/5x5"
  top: "inception_5b/5x5"
}
layer {
  name: "inception_5b/pool"
  type: "Pooling"
  bottom: "inception_5a/output_inception_5a/output_0_split_3"
  top: "inception_5b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_5b/pool_proj"
  type: "Convolution"
  bottom: "inception_5b/pool"
  top: "inception_5b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_5b/pool_proj"
  top: "inception_5b/pool_proj"
}
layer {
  name: "inception_5b/output"
  type: "Concat"
  bottom: "inception_5b/1x1"
  bottom: "inception_5b/3x3"
  bottom: "inception_5b/5x5"
  bottom: "inception_5b/pool_proj"
  top: "inception_5b/output"
}
layer {
  name: "pool5/7x7_s1"
  type: "Pooling"
  bottom: "inception_5b/output"
  top: "pool5/7x7_s1"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "pool5/drop_7x7_s1"
  type: "Dropout"
  bottom: "pool5/7x7_s1"
  top: "pool5/7x7_s1"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "loss3/classifier"
  type: "InnerProduct"
  bottom: "pool5/7x7_s1"
  top: "loss3/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss3/classifier_loss3/classifier_0_split"
  type: "Split"
  bottom: "loss3/classifier"
  top: "loss3/classifier_loss3/classifier_0_split_0"
  top: "loss3/classifier_loss3/classifier_0_split_1"
}
layer {
  name: "loss3/loss"
  type: "SoftmaxWithLoss"
  bottom: "loss3/classifier_loss3/classifier_0_split_0"
  bottom: "label_DataColor256_1_split_2"
  top: "loss"
  loss_weight: 1
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss3/classifier_loss3/classifier_0_split_1"
  bottom: "label_DataColor256_1_split_3"
  top: "accuracy"
}
I0603 04:24:33.443286   822 layer_factory.hpp:114] Creating layer DataColor256
I0603 04:24:33.443928   822 net.cpp:201] Creating Layer DataColor256
I0603 04:24:33.443943   822 net.cpp:876] DataColor256 -> data
I0603 04:24:33.443967   822 net.cpp:876] DataColor256 -> label
W0603 04:24:33.443977   822 net.cpp:265] SetMinibatchSize 32
I0603 04:24:33.444205   822 data_transformer.cpp:63] Loading mean file from: /workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/mean.binaryproto
I0603 04:24:33.448348   825 db_lmdb.cpp:72] Opened lmdb /workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/train.txt_LMDB
I0603 04:24:33.448560   822 data_layer.cpp:80] output data size: 32,3,256,256
I0603 04:24:33.490195   822 net.cpp:286] Setting up DataColor256
I0603 04:24:33.498323   822 net.cpp:293] Top shape: 32 3 256 256 (6291456)
I0603 04:24:33.498477   822 net.cpp:293] Top shape: 32 (32)
I0603 04:24:33.498569   822 net.cpp:301] Memory required for data: 25165952
I0603 04:24:33.498697   822 layer_factory.hpp:114] Creating layer label_DataColor256_1_split
I0603 04:24:33.498888   822 net.cpp:201] Creating Layer label_DataColor256_1_split
I0603 04:24:33.499033   822 net.cpp:902] label_DataColor256_1_split <- label
I0603 04:24:33.499166   822 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_0
I0603 04:24:33.499372   822 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_1
I0603 04:24:33.499567   822 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_2
I0603 04:24:33.499758   822 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_3
I0603 04:24:33.500788   822 net.cpp:286] Setting up label_DataColor256_1_split
I0603 04:24:33.500850   822 net.cpp:293] Top shape: 32 (32)
I0603 04:24:33.500859   822 net.cpp:293] Top shape: 32 (32)
I0603 04:24:33.500866   822 net.cpp:293] Top shape: 32 (32)
I0603 04:24:33.500872   822 net.cpp:293] Top shape: 32 (32)
I0603 04:24:33.500876   822 net.cpp:301] Memory required for data: 25166464
I0603 04:24:33.500883   822 layer_factory.hpp:114] Creating layer conv1/7x7_s2
I0603 04:24:33.500913   822 net.cpp:201] Creating Layer conv1/7x7_s2
I0603 04:24:33.500921   822 net.cpp:902] conv1/7x7_s2 <- data
I0603 04:24:33.500931   822 net.cpp:876] conv1/7x7_s2 -> conv1/7x7_s2
I0603 04:24:33.513841   822 net.cpp:286] Setting up conv1/7x7_s2
I0603 04:24:33.513872   822 net.cpp:293] Top shape: 32 64 128 128 (33554432)
I0603 04:24:33.513878   822 net.cpp:301] Memory required for data: 159384192
I0603 04:24:33.513900   822 layer_factory.hpp:114] Creating layer conv1/relu_7x7
I0603 04:24:33.513921   822 net.cpp:201] Creating Layer conv1/relu_7x7
I0603 04:24:33.513928   822 net.cpp:902] conv1/relu_7x7 <- conv1/7x7_s2
I0603 04:24:33.513937   822 net.cpp:863] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)
I0603 04:24:33.513964   822 net.cpp:286] Setting up conv1/relu_7x7
I0603 04:24:33.513972   822 net.cpp:293] Top shape: 32 64 128 128 (33554432)
I0603 04:24:33.513977   822 net.cpp:301] Memory required for data: 293601920
I0603 04:24:33.513983   822 layer_factory.hpp:114] Creating layer pool1/3x3_s2
I0603 04:24:33.513998   822 net.cpp:201] Creating Layer pool1/3x3_s2
I0603 04:24:33.514003   822 net.cpp:902] pool1/3x3_s2 <- conv1/7x7_s2
I0603 04:24:33.514010   822 net.cpp:876] pool1/3x3_s2 -> pool1/3x3_s2
I0603 04:24:33.514034   822 net.cpp:286] Setting up pool1/3x3_s2
I0603 04:24:33.514042   822 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:24:33.514047   822 net.cpp:301] Memory required for data: 327156352
I0603 04:24:33.514052   822 layer_factory.hpp:114] Creating layer pool1/norm1
I0603 04:24:33.514065   822 net.cpp:201] Creating Layer pool1/norm1
I0603 04:24:33.514071   822 net.cpp:902] pool1/norm1 <- pool1/3x3_s2
I0603 04:24:33.514078   822 net.cpp:876] pool1/norm1 -> pool1/norm1
I0603 04:24:33.514097   822 net.cpp:286] Setting up pool1/norm1
I0603 04:24:33.514106   822 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:24:33.514111   822 net.cpp:301] Memory required for data: 360710784
I0603 04:24:33.514116   822 layer_factory.hpp:114] Creating layer conv2/3x3_reduce
I0603 04:24:33.514166   822 net.cpp:201] Creating Layer conv2/3x3_reduce
I0603 04:24:33.514173   822 net.cpp:902] conv2/3x3_reduce <- pool1/norm1
I0603 04:24:33.514183   822 net.cpp:876] conv2/3x3_reduce -> conv2/3x3_reduce
I0603 04:24:33.516448   822 net.cpp:286] Setting up conv2/3x3_reduce
I0603 04:24:33.516469   822 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:24:33.516475   822 net.cpp:301] Memory required for data: 394265216
I0603 04:24:33.516490   822 layer_factory.hpp:114] Creating layer conv2/relu_3x3_reduce
I0603 04:24:33.516507   822 net.cpp:201] Creating Layer conv2/relu_3x3_reduce
I0603 04:24:33.516515   822 net.cpp:902] conv2/relu_3x3_reduce <- conv2/3x3_reduce
I0603 04:24:33.516522   822 net.cpp:863] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)
I0603 04:24:33.516544   822 net.cpp:286] Setting up conv2/relu_3x3_reduce
I0603 04:24:33.516552   822 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:24:33.516557   822 net.cpp:301] Memory required for data: 427819648
I0603 04:24:33.516562   822 layer_factory.hpp:114] Creating layer conv2/3x3
I0603 04:24:33.516584   822 net.cpp:201] Creating Layer conv2/3x3
I0603 04:24:33.516590   822 net.cpp:902] conv2/3x3 <- conv2/3x3_reduce
I0603 04:24:33.516600   822 net.cpp:876] conv2/3x3 -> conv2/3x3
I0603 04:24:33.524682   822 net.cpp:286] Setting up conv2/3x3
I0603 04:24:33.524704   822 net.cpp:293] Top shape: 32 192 64 64 (25165824)
I0603 04:24:33.524711   822 net.cpp:301] Memory required for data: 528482944
I0603 04:24:33.524726   822 layer_factory.hpp:114] Creating layer conv2/relu_3x3
I0603 04:24:33.524741   822 net.cpp:201] Creating Layer conv2/relu_3x3
I0603 04:24:33.524749   822 net.cpp:902] conv2/relu_3x3 <- conv2/3x3
I0603 04:24:33.524756   822 net.cpp:863] conv2/relu_3x3 -> conv2/3x3 (in-place)
I0603 04:24:33.524777   822 net.cpp:286] Setting up conv2/relu_3x3
I0603 04:24:33.524785   822 net.cpp:293] Top shape: 32 192 64 64 (25165824)
I0603 04:24:33.524790   822 net.cpp:301] Memory required for data: 629146240
I0603 04:24:33.524796   822 layer_factory.hpp:114] Creating layer conv2/norm2
I0603 04:24:33.524806   822 net.cpp:201] Creating Layer conv2/norm2
I0603 04:24:33.524812   822 net.cpp:902] conv2/norm2 <- conv2/3x3
I0603 04:24:33.524819   822 net.cpp:876] conv2/norm2 -> conv2/norm2
I0603 04:24:33.524837   822 net.cpp:286] Setting up conv2/norm2
I0603 04:24:33.524843   822 net.cpp:293] Top shape: 32 192 64 64 (25165824)
I0603 04:24:33.524848   822 net.cpp:301] Memory required for data: 729809536
I0603 04:24:33.524853   822 layer_factory.hpp:114] Creating layer pool2/3x3_s2
I0603 04:24:33.524864   822 net.cpp:201] Creating Layer pool2/3x3_s2
I0603 04:24:33.524869   822 net.cpp:902] pool2/3x3_s2 <- conv2/norm2
I0603 04:24:33.524876   822 net.cpp:876] pool2/3x3_s2 -> pool2/3x3_s2
I0603 04:24:33.524910   822 net.cpp:286] Setting up pool2/3x3_s2
I0603 04:24:33.524919   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.524924   822 net.cpp:301] Memory required for data: 754975360
I0603 04:24:33.524930   822 layer_factory.hpp:114] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0603 04:24:33.524941   822 net.cpp:201] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0603 04:24:33.524946   822 net.cpp:902] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I0603 04:24:33.524955   822 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0603 04:24:33.524963   822 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0603 04:24:33.524971   822 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0603 04:24:33.524981   822 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0603 04:24:33.525005   822 net.cpp:286] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I0603 04:24:33.525014   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.525022   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.525027   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.525051   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.525056   822 net.cpp:301] Memory required for data: 855638656
I0603 04:24:33.525061   822 layer_factory.hpp:114] Creating layer inception_3a/1x1
I0603 04:24:33.525080   822 net.cpp:201] Creating Layer inception_3a/1x1
I0603 04:24:33.525085   822 net.cpp:902] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0603 04:24:33.525094   822 net.cpp:876] inception_3a/1x1 -> inception_3a/1x1
I0603 04:24:33.527189   822 net.cpp:286] Setting up inception_3a/1x1
I0603 04:24:33.527204   822 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:24:33.527209   822 net.cpp:301] Memory required for data: 864027264
I0603 04:24:33.527221   822 layer_factory.hpp:114] Creating layer inception_3a/relu_1x1
I0603 04:24:33.527235   822 net.cpp:201] Creating Layer inception_3a/relu_1x1
I0603 04:24:33.527240   822 net.cpp:902] inception_3a/relu_1x1 <- inception_3a/1x1
I0603 04:24:33.527248   822 net.cpp:863] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)
I0603 04:24:33.527268   822 net.cpp:286] Setting up inception_3a/relu_1x1
I0603 04:24:33.527276   822 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:24:33.527281   822 net.cpp:301] Memory required for data: 872415872
I0603 04:24:33.527287   822 layer_factory.hpp:114] Creating layer inception_3a/3x3_reduce
I0603 04:24:33.527304   822 net.cpp:201] Creating Layer inception_3a/3x3_reduce
I0603 04:24:33.527310   822 net.cpp:902] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0603 04:24:33.527321   822 net.cpp:876] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0603 04:24:33.529588   822 net.cpp:286] Setting up inception_3a/3x3_reduce
I0603 04:24:33.529604   822 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:24:33.529609   822 net.cpp:301] Memory required for data: 884998784
I0603 04:24:33.529623   822 layer_factory.hpp:114] Creating layer inception_3a/relu_3x3_reduce
I0603 04:24:33.529641   822 net.cpp:201] Creating Layer inception_3a/relu_3x3_reduce
I0603 04:24:33.529647   822 net.cpp:902] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce
I0603 04:24:33.529657   822 net.cpp:863] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)
I0603 04:24:33.529680   822 net.cpp:286] Setting up inception_3a/relu_3x3_reduce
I0603 04:24:33.529687   822 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:24:33.529692   822 net.cpp:301] Memory required for data: 897581696
I0603 04:24:33.529698   822 layer_factory.hpp:114] Creating layer inception_3a/3x3
I0603 04:24:33.529721   822 net.cpp:201] Creating Layer inception_3a/3x3
I0603 04:24:33.529726   822 net.cpp:902] inception_3a/3x3 <- inception_3a/3x3_reduce
I0603 04:24:33.529734   822 net.cpp:876] inception_3a/3x3 -> inception_3a/3x3
I0603 04:24:33.534471   822 net.cpp:286] Setting up inception_3a/3x3
I0603 04:24:33.534492   822 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:24:33.534498   822 net.cpp:301] Memory required for data: 914358912
I0603 04:24:33.534509   822 layer_factory.hpp:114] Creating layer inception_3a/relu_3x3
I0603 04:24:33.534523   822 net.cpp:201] Creating Layer inception_3a/relu_3x3
I0603 04:24:33.534530   822 net.cpp:902] inception_3a/relu_3x3 <- inception_3a/3x3
I0603 04:24:33.534538   822 net.cpp:863] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)
I0603 04:24:33.534559   822 net.cpp:286] Setting up inception_3a/relu_3x3
I0603 04:24:33.534566   822 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:24:33.534571   822 net.cpp:301] Memory required for data: 931136128
I0603 04:24:33.534576   822 layer_factory.hpp:114] Creating layer inception_3a/5x5_reduce
I0603 04:24:33.534595   822 net.cpp:201] Creating Layer inception_3a/5x5_reduce
I0603 04:24:33.534600   822 net.cpp:902] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0603 04:24:33.534610   822 net.cpp:876] inception_3a/5x5_reduce -> inception_3a/5x5_reduce
I0603 04:24:33.536366   822 net.cpp:286] Setting up inception_3a/5x5_reduce
I0603 04:24:33.536388   822 net.cpp:293] Top shape: 32 16 32 32 (524288)
I0603 04:24:33.536412   822 net.cpp:301] Memory required for data: 933233280
I0603 04:24:33.536424   822 layer_factory.hpp:114] Creating layer inception_3a/relu_5x5_reduce
I0603 04:24:33.536437   822 net.cpp:201] Creating Layer inception_3a/relu_5x5_reduce
I0603 04:24:33.536444   822 net.cpp:902] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce
I0603 04:24:33.536453   822 net.cpp:863] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)
I0603 04:24:33.536471   822 net.cpp:286] Setting up inception_3a/relu_5x5_reduce
I0603 04:24:33.536479   822 net.cpp:293] Top shape: 32 16 32 32 (524288)
I0603 04:24:33.536484   822 net.cpp:301] Memory required for data: 935330432
I0603 04:24:33.536489   822 layer_factory.hpp:114] Creating layer inception_3a/5x5
I0603 04:24:33.536515   822 net.cpp:201] Creating Layer inception_3a/5x5
I0603 04:24:33.536522   822 net.cpp:902] inception_3a/5x5 <- inception_3a/5x5_reduce
I0603 04:24:33.536533   822 net.cpp:876] inception_3a/5x5 -> inception_3a/5x5
I0603 04:24:33.538900   822 net.cpp:286] Setting up inception_3a/5x5
I0603 04:24:33.538923   822 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:24:33.538930   822 net.cpp:301] Memory required for data: 939524736
I0603 04:24:33.538942   822 layer_factory.hpp:114] Creating layer inception_3a/relu_5x5
I0603 04:24:33.538957   822 net.cpp:201] Creating Layer inception_3a/relu_5x5
I0603 04:24:33.538964   822 net.cpp:902] inception_3a/relu_5x5 <- inception_3a/5x5
I0603 04:24:33.538972   822 net.cpp:863] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)
I0603 04:24:33.538993   822 net.cpp:286] Setting up inception_3a/relu_5x5
I0603 04:24:33.539001   822 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:24:33.539006   822 net.cpp:301] Memory required for data: 943719040
I0603 04:24:33.539011   822 layer_factory.hpp:114] Creating layer inception_3a/pool
I0603 04:24:33.539023   822 net.cpp:201] Creating Layer inception_3a/pool
I0603 04:24:33.539029   822 net.cpp:902] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0603 04:24:33.539037   822 net.cpp:876] inception_3a/pool -> inception_3a/pool
I0603 04:24:33.539062   822 net.cpp:286] Setting up inception_3a/pool
I0603 04:24:33.539068   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.539073   822 net.cpp:301] Memory required for data: 968884864
I0603 04:24:33.539078   822 layer_factory.hpp:114] Creating layer inception_3a/pool_proj
I0603 04:24:33.539095   822 net.cpp:201] Creating Layer inception_3a/pool_proj
I0603 04:24:33.539101   822 net.cpp:902] inception_3a/pool_proj <- inception_3a/pool
I0603 04:24:33.539110   822 net.cpp:876] inception_3a/pool_proj -> inception_3a/pool_proj
I0603 04:24:33.541110   822 net.cpp:286] Setting up inception_3a/pool_proj
I0603 04:24:33.541131   822 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:24:33.541137   822 net.cpp:301] Memory required for data: 973079168
I0603 04:24:33.541153   822 layer_factory.hpp:114] Creating layer inception_3a/relu_pool_proj
I0603 04:24:33.541167   822 net.cpp:201] Creating Layer inception_3a/relu_pool_proj
I0603 04:24:33.541174   822 net.cpp:902] inception_3a/relu_pool_proj <- inception_3a/pool_proj
I0603 04:24:33.541182   822 net.cpp:863] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)
I0603 04:24:33.541201   822 net.cpp:286] Setting up inception_3a/relu_pool_proj
I0603 04:24:33.541209   822 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:24:33.541214   822 net.cpp:301] Memory required for data: 977273472
I0603 04:24:33.541219   822 layer_factory.hpp:114] Creating layer inception_3a/output
I0603 04:24:33.541231   822 net.cpp:201] Creating Layer inception_3a/output
I0603 04:24:33.541236   822 net.cpp:902] inception_3a/output <- inception_3a/1x1
I0603 04:24:33.541242   822 net.cpp:902] inception_3a/output <- inception_3a/3x3
I0603 04:24:33.541249   822 net.cpp:902] inception_3a/output <- inception_3a/5x5
I0603 04:24:33.541255   822 net.cpp:902] inception_3a/output <- inception_3a/pool_proj
I0603 04:24:33.541262   822 net.cpp:876] inception_3a/output -> inception_3a/output
I0603 04:24:33.541327   822 net.cpp:286] Setting up inception_3a/output
I0603 04:24:33.541338   822 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:24:33.541343   822 net.cpp:301] Memory required for data: 1010827904
I0603 04:24:33.541349   822 layer_factory.hpp:114] Creating layer inception_3a/output_inception_3a/output_0_split
I0603 04:24:33.541359   822 net.cpp:201] Creating Layer inception_3a/output_inception_3a/output_0_split
I0603 04:24:33.541365   822 net.cpp:902] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0603 04:24:33.541373   822 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0603 04:24:33.541383   822 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0603 04:24:33.541390   822 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0603 04:24:33.541399   822 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I0603 04:24:33.541425   822 net.cpp:286] Setting up inception_3a/output_inception_3a/output_0_split
I0603 04:24:33.541435   822 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:24:33.541441   822 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:24:33.541447   822 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:24:33.541453   822 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:24:33.541458   822 net.cpp:301] Memory required for data: 1145045632
I0603 04:24:33.541463   822 layer_factory.hpp:114] Creating layer inception_3b/1x1
I0603 04:24:33.541487   822 net.cpp:201] Creating Layer inception_3b/1x1
I0603 04:24:33.541493   822 net.cpp:902] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I0603 04:24:33.541502   822 net.cpp:876] inception_3b/1x1 -> inception_3b/1x1
I0603 04:24:33.544378   822 net.cpp:286] Setting up inception_3b/1x1
I0603 04:24:33.544392   822 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:24:33.544399   822 net.cpp:301] Memory required for data: 1161822848
I0603 04:24:33.544409   822 layer_factory.hpp:114] Creating layer inception_3b/relu_1x1
I0603 04:24:33.544425   822 net.cpp:201] Creating Layer inception_3b/relu_1x1
I0603 04:24:33.544431   822 net.cpp:902] inception_3b/relu_1x1 <- inception_3b/1x1
I0603 04:24:33.544440   822 net.cpp:863] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)
I0603 04:24:33.544464   822 net.cpp:286] Setting up inception_3b/relu_1x1
I0603 04:24:33.544472   822 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:24:33.544477   822 net.cpp:301] Memory required for data: 1178600064
I0603 04:24:33.544482   822 layer_factory.hpp:114] Creating layer inception_3b/3x3_reduce
I0603 04:24:33.544503   822 net.cpp:201] Creating Layer inception_3b/3x3_reduce
I0603 04:24:33.544509   822 net.cpp:902] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0603 04:24:33.544519   822 net.cpp:876] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0603 04:24:33.547245   822 net.cpp:286] Setting up inception_3b/3x3_reduce
I0603 04:24:33.547267   822 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:24:33.547273   822 net.cpp:301] Memory required for data: 1195377280
I0603 04:24:33.547286   822 layer_factory.hpp:114] Creating layer inception_3b/relu_3x3_reduce
I0603 04:24:33.547303   822 net.cpp:201] Creating Layer inception_3b/relu_3x3_reduce
I0603 04:24:33.547310   822 net.cpp:902] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce
I0603 04:24:33.547319   822 net.cpp:863] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)
I0603 04:24:33.547344   822 net.cpp:286] Setting up inception_3b/relu_3x3_reduce
I0603 04:24:33.547353   822 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:24:33.547358   822 net.cpp:301] Memory required for data: 1212154496
I0603 04:24:33.547363   822 layer_factory.hpp:114] Creating layer inception_3b/3x3
I0603 04:24:33.547406   822 net.cpp:201] Creating Layer inception_3b/3x3
I0603 04:24:33.547413   822 net.cpp:902] inception_3b/3x3 <- inception_3b/3x3_reduce
I0603 04:24:33.547422   822 net.cpp:876] inception_3b/3x3 -> inception_3b/3x3
I0603 04:24:33.554532   822 net.cpp:286] Setting up inception_3b/3x3
I0603 04:24:33.554553   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.554558   822 net.cpp:301] Memory required for data: 1237320320
I0603 04:24:33.554570   822 layer_factory.hpp:114] Creating layer inception_3b/relu_3x3
I0603 04:24:33.554584   822 net.cpp:201] Creating Layer inception_3b/relu_3x3
I0603 04:24:33.554591   822 net.cpp:902] inception_3b/relu_3x3 <- inception_3b/3x3
I0603 04:24:33.554600   822 net.cpp:863] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)
I0603 04:24:33.554620   822 net.cpp:286] Setting up inception_3b/relu_3x3
I0603 04:24:33.554628   822 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:24:33.554633   822 net.cpp:301] Memory required for data: 1262486144
I0603 04:24:33.554638   822 layer_factory.hpp:114] Creating layer inception_3b/5x5_reduce
I0603 04:24:33.554656   822 net.cpp:201] Creating Layer inception_3b/5x5_reduce
I0603 04:24:33.554662   822 net.cpp:902] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2
I0603 04:24:33.554672   822 net.cpp:876] inception_3b/5x5_reduce -> inception_3b/5x5_reduce
I0603 04:24:33.556707   822 net.cpp:286] Setting up inception_3b/5x5_reduce
I0603 04:24:33.556730   822 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:24:33.556736   822 net.cpp:301] Memory required for data: 1266680448
I0603 04:24:33.556748   822 layer_factory.hpp:114] Creating layer inception_3b/relu_5x5_reduce
I0603 04:24:33.556762   822 net.cpp:201] Creating Layer inception_3b/relu_5x5_reduce
I0603 04:24:33.556771   822 net.cpp:902] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce
I0603 04:24:33.556778   822 net.cpp:863] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)
I0603 04:24:33.556800   822 net.cpp:286] Setting up inception_3b/relu_5x5_reduce
I0603 04:24:33.556809   822 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:24:33.556814   822 net.cpp:301] Memory required for data: 1270874752
I0603 04:24:33.556819   822 layer_factory.hpp:114] Creating layer inception_3b/5x5
I0603 04:24:33.556838   822 net.cpp:201] Creating Layer inception_3b/5x5
I0603 04:24:33.556843   822 net.cpp:902] inception_3b/5x5 <- inception_3b/5x5_reduce
I0603 04:24:33.556851   822 net.cpp:876] inception_3b/5x5 -> inception_3b/5x5
I0603 04:24:33.561182   822 net.cpp:286] Setting up inception_3b/5x5
I0603 04:24:33.561203   822 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:24:33.561210   822 net.cpp:301] Memory required for data: 1283457664
I0603 04:24:33.561223   822 layer_factory.hpp:114] Creating layer inception_3b/relu_5x5
I0603 04:24:33.561236   822 net.cpp:201] Creating Layer inception_3b/relu_5x5
I0603 04:24:33.561244   822 net.cpp:902] inception_3b/relu_5x5 <- inception_3b/5x5
I0603 04:24:33.561252   822 net.cpp:863] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)
I0603 04:24:33.561272   822 net.cpp:286] Setting up inception_3b/relu_5x5
I0603 04:24:33.561280   822 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:24:33.561285   822 net.cpp:301] Memory required for data: 1296040576
I0603 04:24:33.561290   822 layer_factory.hpp:114] Creating layer inception_3b/pool
I0603 04:24:33.561302   822 net.cpp:201] Creating Layer inception_3b/pool
I0603 04:24:33.561308   822 net.cpp:902] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I0603 04:24:33.561316   822 net.cpp:876] inception_3b/pool -> inception_3b/pool
I0603 04:24:33.561336   822 net.cpp:286] Setting up inception_3b/pool
I0603 04:24:33.561343   822 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:24:33.561348   822 net.cpp:301] Memory required for data: 1329595008
I0603 04:24:33.561353   822 layer_factory.hpp:114] Creating layer inception_3b/pool_proj
I0603 04:24:33.561372   822 net.cpp:201] Creating Layer inception_3b/pool_proj
I0603 04:24:33.561394   822 net.cpp:902] inception_3b/pool_proj <- inception_3b/pool
I0603 04:24:33.561403   822 net.cpp:876] inception_3b/pool_proj -> inception_3b/pool_proj
I0603 04:24:33.563724   822 net.cpp:286] Setting up inception_3b/pool_proj
I0603 04:24:33.563746   822 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:24:33.563752   822 net.cpp:301] Memory required for data: 1337983616
I0603 04:24:33.563763   822 layer_factory.hpp:114] Creating layer inception_3b/relu_pool_proj
I0603 04:24:33.563781   822 net.cpp:201] Creating Layer inception_3b/relu_pool_proj
I0603 04:24:33.563789   822 net.cpp:902] inception_3b/relu_pool_proj <- inception_3b/pool_proj
I0603 04:24:33.563797   822 net.cpp:863] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)
I0603 04:24:33.563827   822 net.cpp:286] Setting up inception_3b/relu_pool_proj
I0603 04:24:33.563833   822 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:24:33.563838   822 net.cpp:301] Memory required for data: 1346372224
I0603 04:24:33.563844   822 layer_factory.hpp:114] Creating layer inception_3b/output
I0603 04:24:33.563858   822 net.cpp:201] Creating Layer inception_3b/output
I0603 04:24:33.563863   822 net.cpp:902] inception_3b/output <- inception_3b/1x1
I0603 04:24:33.563869   822 net.cpp:902] inception_3b/output <- inception_3b/3x3
I0603 04:24:33.563876   822 net.cpp:902] inception_3b/output <- inception_3b/5x5
I0603 04:24:33.563882   822 net.cpp:902] inception_3b/output <- inception_3b/pool_proj
I0603 04:24:33.563889   822 net.cpp:876] inception_3b/output -> inception_3b/output
I0603 04:24:33.563932   822 net.cpp:286] Setting up inception_3b/output
I0603 04:24:33.563941   822 net.cpp:293] Top shape: 32 480 32 32 (15728640)
I0603 04:24:33.563946   822 net.cpp:301] Memory required for data: 1409286784
I0603 04:24:33.563951   822 layer_factory.hpp:114] Creating layer pool3/3x3_s2
I0603 04:24:33.563966   822 net.cpp:201] Creating Layer pool3/3x3_s2
I0603 04:24:33.563971   822 net.cpp:902] pool3/3x3_s2 <- inception_3b/output
I0603 04:24:33.563978   822 net.cpp:876] pool3/3x3_s2 -> pool3/3x3_s2
I0603 04:24:33.563997   822 net.cpp:286] Setting up pool3/3x3_s2
I0603 04:24:33.564004   822 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:24:33.564009   822 net.cpp:301] Memory required for data: 1425015424
I0603 04:24:33.564014   822 layer_factory.hpp:114] Creating layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0603 04:24:33.564025   822 net.cpp:201] Creating Layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0603 04:24:33.564031   822 net.cpp:902] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2
I0603 04:24:33.564039   822 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0603 04:24:33.564049   822 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0603 04:24:33.564059   822 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0603 04:24:33.564069   822 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0603 04:24:33.564090   822 net.cpp:286] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split
I0603 04:24:33.564097   822 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:24:33.564105   822 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:24:33.564110   822 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:24:33.564116   822 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:24:33.564121   822 net.cpp:301] Memory required for data: 1487929984
I0603 04:24:33.564126   822 layer_factory.hpp:114] Creating layer inception_4a/1x1
I0603 04:24:33.564143   822 net.cpp:201] Creating Layer inception_4a/1x1
I0603 04:24:33.564149   822 net.cpp:902] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0603 04:24:33.564158   822 net.cpp:876] inception_4a/1x1 -> inception_4a/1x1
I0603 04:24:33.567569   822 net.cpp:286] Setting up inception_4a/1x1
I0603 04:24:33.567584   822 net.cpp:293] Top shape: 32 192 16 16 (1572864)
I0603 04:24:33.567589   822 net.cpp:301] Memory required for data: 1494221440
I0603 04:24:33.567615   822 layer_factory.hpp:114] Creating layer inception_4a/relu_1x1
I0603 04:24:33.567631   822 net.cpp:201] Creating Layer inception_4a/relu_1x1
I0603 04:24:33.567638   822 net.cpp:902] inception_4a/relu_1x1 <- inception_4a/1x1
I0603 04:24:33.567646   822 net.cpp:863] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)
I0603 04:24:33.567669   822 net.cpp:286] Setting up inception_4a/relu_1x1
I0603 04:24:33.567677   822 net.cpp:293] Top shape: 32 192 16 16 (1572864)
I0603 04:24:33.567682   822 net.cpp:301] Memory required for data: 1500512896
I0603 04:24:33.567687   822 layer_factory.hpp:114] Creating layer inception_4a/3x3_reduce
I0603 04:24:33.567713   822 net.cpp:201] Creating Layer inception_4a/3x3_reduce
I0603 04:24:33.567719   822 net.cpp:902] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0603 04:24:33.567729   822 net.cpp:876] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I0603 04:24:33.570026   822 net.cpp:286] Setting up inception_4a/3x3_reduce
I0603 04:24:33.570047   822 net.cpp:293] Top shape: 32 96 16 16 (786432)
I0603 04:24:33.570055   822 net.cpp:301] Memory required for data: 1503658624
I0603 04:24:33.570071   822 layer_factory.hpp:114] Creating layer inception_4a/relu_3x3_reduce
I0603 04:24:33.570089   822 net.cpp:201] Creating Layer inception_4a/relu_3x3_reduce
I0603 04:24:33.570096   822 net.cpp:902] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce
I0603 04:24:33.570106   822 net.cpp:863] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)
I0603 04:24:33.570132   822 net.cpp:286] Setting up inception_4a/relu_3x3_reduce
I0603 04:24:33.570140   822 net.cpp:293] Top shape: 32 96 16 16 (786432)
I0603 04:24:33.570145   822 net.cpp:301] Memory required for data: 1506804352
I0603 04:24:33.570152   822 layer_factory.hpp:114] Creating layer inception_4a/3x3
I0603 04:24:33.570173   822 net.cpp:201] Creating Layer inception_4a/3x3
I0603 04:24:33.570179   822 net.cpp:902] inception_4a/3x3 <- inception_4a/3x3_reduce
I0603 04:24:33.570188   822 net.cpp:876] inception_4a/3x3 -> inception_4a/3x3
I0603 04:24:33.574362   822 net.cpp:286] Setting up inception_4a/3x3
I0603 04:24:33.574383   822 net.cpp:293] Top shape: 32 208 16 16 (1703936)
I0603 04:24:33.574389   822 net.cpp:301] Memory required for data: 1513620096
I0603 04:24:33.574401   822 layer_factory.hpp:114] Creating layer inception_4a/relu_3x3
I0603 04:24:33.574415   822 net.cpp:201] Creating Layer inception_4a/relu_3x3
I0603 04:24:33.574422   822 net.cpp:902] inception_4a/relu_3x3 <- inception_4a/3x3
I0603 04:24:33.574430   822 net.cpp:863] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)
I0603 04:24:33.574451   822 net.cpp:286] Setting up inception_4a/relu_3x3
I0603 04:24:33.574458   822 net.cpp:293] Top shape: 32 208 16 16 (1703936)
I0603 04:24:33.574463   822 net.cpp:301] Memory required for data: 1520435840
I0603 04:24:33.574470   822 layer_factory.hpp:114] Creating layer inception_4a/5x5_reduce
I0603 04:24:33.574486   822 net.cpp:201] Creating Layer inception_4a/5x5_reduce
I0603 04:24:33.574492   822 net.cpp:902] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0603 04:24:33.574501   822 net.cpp:876] inception_4a/5x5_reduce -> inception_4a/5x5_reduce
I0603 04:24:33.576019   822 net.cpp:286] Setting up inception_4a/5x5_reduce
I0603 04:24:33.576040   822 net.cpp:293] Top shape: 32 16 16 16 (131072)
I0603 04:24:33.576046   822 net.cpp:301] Memory required for data: 1520960128
I0603 04:24:33.576057   822 layer_factory.hpp:114] Creating layer inception_4a/relu_5x5_reduce
I0603 04:24:33.576071   822 net.cpp:201] Creating Layer inception_4a/relu_5x5_reduce
I0603 04:24:33.576079   822 net.cpp:902] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce
I0603 04:24:33.576087   822 net.cpp:863] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)
I0603 04:24:33.576107   822 net.cpp:286] Setting up inception_4a/relu_5x5_reduce
I0603 04:24:33.576114   822 net.cpp:293] Top shape: 32 16 16 16 (131072)
I0603 04:24:33.576119   822 net.cpp:301] Memory required for data: 1521484416
I0603 04:24:33.576143   822 layer_factory.hpp:114] Creating layer inception_4a/5x5
I0603 04:24:33.576161   822 net.cpp:201] Creating Layer inception_4a/5x5
I0603 04:24:33.576169   822 net.cpp:902] inception_4a/5x5 <- inception_4a/5x5_reduce
I0603 04:24:33.576176   822 net.cpp:876] inception_4a/5x5 -> inception_4a/5x5
I0603 04:24:33.577925   822 net.cpp:286] Setting up inception_4a/5x5
I0603 04:24:33.577946   822 net.cpp:293] Top shape: 32 48 16 16 (393216)
I0603 04:24:33.577952   822 net.cpp:301] Memory required for data: 1523057280
I0603 04:24:33.577963   822 layer_factory.hpp:114] Creating layer inception_4a/relu_5x5
I0603 04:24:33.577978   822 net.cpp:201] Creating Layer inception_4a/relu_5x5
I0603 04:24:33.577986   822 net.cpp:902] inception_4a/relu_5x5 <- inception_4a/5x5
I0603 04:24:33.577993   822 net.cpp:863] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)
I0603 04:24:33.578013   822 net.cpp:286] Setting up inception_4a/relu_5x5
I0603 04:24:33.578022   822 net.cpp:293] Top shape: 32 48 16 16 (393216)
I0603 04:24:33.578027   822 net.cpp:301] Memory required for data: 1524630144
I0603 04:24:33.578032   822 layer_factory.hpp:114] Creating layer inception_4a/pool
I0603 04:24:33.578042   822 net.cpp:201] Creating Layer inception_4a/pool
I0603 04:24:33.578048   822 net.cpp:902] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0603 04:24:33.578057   822 net.cpp:876] inception_4a/pool -> inception_4a/pool
I0603 04:24:33.578080   822 net.cpp:286] Setting up inception_4a/pool
I0603 04:24:33.578088   822 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:24:33.578094   822 net.cpp:301] Memory required for data: 1540358784
I0603 04:24:33.578099   822 layer_factory.hpp:114] Creating layer inception_4a/pool_proj
I0603 04:24:33.578115   822 net.cpp:201] Creating Layer inception_4a/pool_proj
I0603 04:24:33.578121   822 net.cpp:902] inception_4a/pool_proj <- inception_4a/pool
I0603 04:24:33.578130   822 net.cpp:876] inception_4a/pool_proj -> inception_4a/pool_proj
I0603 04:24:33.580246   822 net.cpp:286] Setting up inception_4a/pool_proj
I0603 04:24:33.580268   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.580274   822 net.cpp:301] Memory required for data: 1542455936
I0603 04:24:33.580286   822 layer_factory.hpp:114] Creating layer inception_4a/relu_pool_proj
I0603 04:24:33.580303   822 net.cpp:201] Creating Layer inception_4a/relu_pool_proj
I0603 04:24:33.580312   822 net.cpp:902] inception_4a/relu_pool_proj <- inception_4a/pool_proj
I0603 04:24:33.580322   822 net.cpp:863] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)
I0603 04:24:33.580345   822 net.cpp:286] Setting up inception_4a/relu_pool_proj
I0603 04:24:33.580353   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.580358   822 net.cpp:301] Memory required for data: 1544553088
I0603 04:24:33.580364   822 layer_factory.hpp:114] Creating layer inception_4a/output
I0603 04:24:33.580377   822 net.cpp:201] Creating Layer inception_4a/output
I0603 04:24:33.580384   822 net.cpp:902] inception_4a/output <- inception_4a/1x1
I0603 04:24:33.580390   822 net.cpp:902] inception_4a/output <- inception_4a/3x3
I0603 04:24:33.580396   822 net.cpp:902] inception_4a/output <- inception_4a/5x5
I0603 04:24:33.580402   822 net.cpp:902] inception_4a/output <- inception_4a/pool_proj
I0603 04:24:33.580410   822 net.cpp:876] inception_4a/output -> inception_4a/output
I0603 04:24:33.580457   822 net.cpp:286] Setting up inception_4a/output
I0603 04:24:33.580466   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.580471   822 net.cpp:301] Memory required for data: 1561330304
I0603 04:24:33.580476   822 layer_factory.hpp:114] Creating layer inception_4a/output_inception_4a/output_0_split
I0603 04:24:33.580487   822 net.cpp:201] Creating Layer inception_4a/output_inception_4a/output_0_split
I0603 04:24:33.580492   822 net.cpp:902] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I0603 04:24:33.580503   822 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I0603 04:24:33.580528   822 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I0603 04:24:33.580538   822 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I0603 04:24:33.580546   822 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I0603 04:24:33.580555   822 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_4
I0603 04:24:33.580586   822 net.cpp:286] Setting up inception_4a/output_inception_4a/output_0_split
I0603 04:24:33.580595   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.580602   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.580608   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.580615   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.580621   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.580626   822 net.cpp:301] Memory required for data: 1645216384
I0603 04:24:33.580631   822 layer_factory.hpp:114] Creating layer loss1/ave_pool
I0603 04:24:33.580646   822 net.cpp:201] Creating Layer loss1/ave_pool
I0603 04:24:33.580651   822 net.cpp:902] loss1/ave_pool <- inception_4a/output_inception_4a/output_0_split_0
I0603 04:24:33.580659   822 net.cpp:876] loss1/ave_pool -> loss1/ave_pool
I0603 04:24:33.580680   822 net.cpp:286] Setting up loss1/ave_pool
I0603 04:24:33.580687   822 net.cpp:293] Top shape: 32 512 5 5 (409600)
I0603 04:24:33.580693   822 net.cpp:301] Memory required for data: 1646854784
I0603 04:24:33.580698   822 layer_factory.hpp:114] Creating layer loss1/conv
I0603 04:24:33.580715   822 net.cpp:201] Creating Layer loss1/conv
I0603 04:24:33.580723   822 net.cpp:902] loss1/conv <- loss1/ave_pool
I0603 04:24:33.580730   822 net.cpp:876] loss1/conv -> loss1/conv
I0603 04:24:33.583092   822 net.cpp:286] Setting up loss1/conv
I0603 04:24:33.583108   822 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:24:33.583113   822 net.cpp:301] Memory required for data: 1647264384
I0603 04:24:33.583124   822 layer_factory.hpp:114] Creating layer loss1/relu_conv
I0603 04:24:33.583138   822 net.cpp:201] Creating Layer loss1/relu_conv
I0603 04:24:33.583144   822 net.cpp:902] loss1/relu_conv <- loss1/conv
I0603 04:24:33.583155   822 net.cpp:863] loss1/relu_conv -> loss1/conv (in-place)
I0603 04:24:33.583179   822 net.cpp:286] Setting up loss1/relu_conv
I0603 04:24:33.583187   822 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:24:33.583192   822 net.cpp:301] Memory required for data: 1647673984
I0603 04:24:33.583197   822 layer_factory.hpp:114] Creating layer loss1/fc
I0603 04:24:33.583214   822 net.cpp:201] Creating Layer loss1/fc
I0603 04:24:33.583220   822 net.cpp:902] loss1/fc <- loss1/conv
I0603 04:24:33.583230   822 net.cpp:876] loss1/fc -> loss1/fc
I0603 04:24:33.604929   822 net.cpp:286] Setting up loss1/fc
I0603 04:24:33.604949   822 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:24:33.604955   822 net.cpp:301] Memory required for data: 1647805056
I0603 04:24:33.604966   822 layer_factory.hpp:114] Creating layer loss1/relu_fc
I0603 04:24:33.604984   822 net.cpp:201] Creating Layer loss1/relu_fc
I0603 04:24:33.604991   822 net.cpp:902] loss1/relu_fc <- loss1/fc
I0603 04:24:33.605000   822 net.cpp:863] loss1/relu_fc -> loss1/fc (in-place)
I0603 04:24:33.605022   822 net.cpp:286] Setting up loss1/relu_fc
I0603 04:24:33.605031   822 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:24:33.605034   822 net.cpp:301] Memory required for data: 1647936128
I0603 04:24:33.605041   822 layer_factory.hpp:114] Creating layer loss1/drop_fc
I0603 04:24:33.605062   822 net.cpp:201] Creating Layer loss1/drop_fc
I0603 04:24:33.605067   822 net.cpp:902] loss1/drop_fc <- loss1/fc
I0603 04:24:33.605074   822 net.cpp:863] loss1/drop_fc -> loss1/fc (in-place)
I0603 04:24:33.605089   822 net.cpp:286] Setting up loss1/drop_fc
I0603 04:24:33.605096   822 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:24:33.605116   822 net.cpp:301] Memory required for data: 1648067200
I0603 04:24:33.605123   822 layer_factory.hpp:114] Creating layer loss1/classifier
I0603 04:24:33.605137   822 net.cpp:201] Creating Layer loss1/classifier
I0603 04:24:33.605142   822 net.cpp:902] loss1/classifier <- loss1/fc
I0603 04:24:33.605151   822 net.cpp:876] loss1/classifier -> loss1/classifier
I0603 04:24:33.605209   822 net.cpp:286] Setting up loss1/classifier
I0603 04:24:33.605218   822 net.cpp:293] Top shape: 32 3 (96)
I0603 04:24:33.605223   822 net.cpp:301] Memory required for data: 1648067584
I0603 04:24:33.605232   822 layer_factory.hpp:114] Creating layer loss1/loss
I0603 04:24:33.605249   822 net.cpp:201] Creating Layer loss1/loss
I0603 04:24:33.605254   822 net.cpp:902] loss1/loss <- loss1/classifier
I0603 04:24:33.605262   822 net.cpp:902] loss1/loss <- label_DataColor256_1_split_0
I0603 04:24:33.605269   822 net.cpp:876] loss1/loss -> loss1/loss
I0603 04:24:33.605286   822 layer_factory.hpp:114] Creating layer loss1/loss
I0603 04:24:33.605319   822 net.cpp:286] Setting up loss1/loss
I0603 04:24:33.605329   822 net.cpp:293] Top shape: (1)
I0603 04:24:33.605334   822 net.cpp:296]     with loss weight 0.3
I0603 04:24:33.605365   822 net.cpp:301] Memory required for data: 1648067588
I0603 04:24:33.605370   822 layer_factory.hpp:114] Creating layer inception_4b/1x1
I0603 04:24:33.605389   822 net.cpp:201] Creating Layer inception_4b/1x1
I0603 04:24:33.605396   822 net.cpp:902] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_1
I0603 04:24:33.605406   822 net.cpp:876] inception_4b/1x1 -> inception_4b/1x1
I0603 04:24:33.608503   822 net.cpp:286] Setting up inception_4b/1x1
I0603 04:24:33.608525   822 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:24:33.608532   822 net.cpp:301] Memory required for data: 1653310468
I0603 04:24:33.608546   822 layer_factory.hpp:114] Creating layer inception_4b/relu_1x1
I0603 04:24:33.608562   822 net.cpp:201] Creating Layer inception_4b/relu_1x1
I0603 04:24:33.608569   822 net.cpp:902] inception_4b/relu_1x1 <- inception_4b/1x1
I0603 04:24:33.608579   822 net.cpp:863] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)
I0603 04:24:33.608604   822 net.cpp:286] Setting up inception_4b/relu_1x1
I0603 04:24:33.608613   822 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:24:33.608618   822 net.cpp:301] Memory required for data: 1658553348
I0603 04:24:33.608623   822 layer_factory.hpp:114] Creating layer inception_4b/3x3_reduce
I0603 04:24:33.608645   822 net.cpp:201] Creating Layer inception_4b/3x3_reduce
I0603 04:24:33.608651   822 net.cpp:902] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_2
I0603 04:24:33.608661   822 net.cpp:876] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I0603 04:24:33.610991   822 net.cpp:286] Setting up inception_4b/3x3_reduce
I0603 04:24:33.611013   822 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:24:33.611019   822 net.cpp:301] Memory required for data: 1662223364
I0603 04:24:33.611030   822 layer_factory.hpp:114] Creating layer inception_4b/relu_3x3_reduce
I0603 04:24:33.611048   822 net.cpp:201] Creating Layer inception_4b/relu_3x3_reduce
I0603 04:24:33.611055   822 net.cpp:902] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce
I0603 04:24:33.611064   822 net.cpp:863] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)
I0603 04:24:33.611088   822 net.cpp:286] Setting up inception_4b/relu_3x3_reduce
I0603 04:24:33.611099   822 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:24:33.611104   822 net.cpp:301] Memory required for data: 1665893380
I0603 04:24:33.611109   822 layer_factory.hpp:114] Creating layer inception_4b/3x3
I0603 04:24:33.611131   822 net.cpp:201] Creating Layer inception_4b/3x3
I0603 04:24:33.611137   822 net.cpp:902] inception_4b/3x3 <- inception_4b/3x3_reduce
I0603 04:24:33.611148   822 net.cpp:876] inception_4b/3x3 -> inception_4b/3x3
I0603 04:24:33.615885   822 net.cpp:286] Setting up inception_4b/3x3
I0603 04:24:33.615906   822 net.cpp:293] Top shape: 32 224 16 16 (1835008)
I0603 04:24:33.615929   822 net.cpp:301] Memory required for data: 1673233412
I0603 04:24:33.615943   822 layer_factory.hpp:114] Creating layer inception_4b/relu_3x3
I0603 04:24:33.615957   822 net.cpp:201] Creating Layer inception_4b/relu_3x3
I0603 04:24:33.615963   822 net.cpp:902] inception_4b/relu_3x3 <- inception_4b/3x3
I0603 04:24:33.615972   822 net.cpp:863] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)
I0603 04:24:33.615991   822 net.cpp:286] Setting up inception_4b/relu_3x3
I0603 04:24:33.615999   822 net.cpp:293] Top shape: 32 224 16 16 (1835008)
I0603 04:24:33.616004   822 net.cpp:301] Memory required for data: 1680573444
I0603 04:24:33.616009   822 layer_factory.hpp:114] Creating layer inception_4b/5x5_reduce
I0603 04:24:33.616029   822 net.cpp:201] Creating Layer inception_4b/5x5_reduce
I0603 04:24:33.616035   822 net.cpp:902] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_3
I0603 04:24:33.616044   822 net.cpp:876] inception_4b/5x5_reduce -> inception_4b/5x5_reduce
I0603 04:24:33.619523   822 net.cpp:286] Setting up inception_4b/5x5_reduce
I0603 04:24:33.619545   822 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:24:33.619551   822 net.cpp:301] Memory required for data: 1681359876
I0603 04:24:33.619562   822 layer_factory.hpp:114] Creating layer inception_4b/relu_5x5_reduce
I0603 04:24:33.619577   822 net.cpp:201] Creating Layer inception_4b/relu_5x5_reduce
I0603 04:24:33.619585   822 net.cpp:902] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce
I0603 04:24:33.619593   822 net.cpp:863] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)
I0603 04:24:33.619616   822 net.cpp:286] Setting up inception_4b/relu_5x5_reduce
I0603 04:24:33.619623   822 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:24:33.619628   822 net.cpp:301] Memory required for data: 1682146308
I0603 04:24:33.619633   822 layer_factory.hpp:114] Creating layer inception_4b/5x5
I0603 04:24:33.619652   822 net.cpp:201] Creating Layer inception_4b/5x5
I0603 04:24:33.619658   822 net.cpp:902] inception_4b/5x5 <- inception_4b/5x5_reduce
I0603 04:24:33.619668   822 net.cpp:876] inception_4b/5x5 -> inception_4b/5x5
I0603 04:24:33.621793   822 net.cpp:286] Setting up inception_4b/5x5
I0603 04:24:33.621814   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.621820   822 net.cpp:301] Memory required for data: 1684243460
I0603 04:24:33.621832   822 layer_factory.hpp:114] Creating layer inception_4b/relu_5x5
I0603 04:24:33.621846   822 net.cpp:201] Creating Layer inception_4b/relu_5x5
I0603 04:24:33.621855   822 net.cpp:902] inception_4b/relu_5x5 <- inception_4b/5x5
I0603 04:24:33.621862   822 net.cpp:863] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)
I0603 04:24:33.621881   822 net.cpp:286] Setting up inception_4b/relu_5x5
I0603 04:24:33.621889   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.621894   822 net.cpp:301] Memory required for data: 1686340612
I0603 04:24:33.621899   822 layer_factory.hpp:114] Creating layer inception_4b/pool
I0603 04:24:33.621912   822 net.cpp:201] Creating Layer inception_4b/pool
I0603 04:24:33.621917   822 net.cpp:902] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_4
I0603 04:24:33.621925   822 net.cpp:876] inception_4b/pool -> inception_4b/pool
I0603 04:24:33.621945   822 net.cpp:286] Setting up inception_4b/pool
I0603 04:24:33.621953   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.621958   822 net.cpp:301] Memory required for data: 1703117828
I0603 04:24:33.621963   822 layer_factory.hpp:114] Creating layer inception_4b/pool_proj
I0603 04:24:33.621980   822 net.cpp:201] Creating Layer inception_4b/pool_proj
I0603 04:24:33.621985   822 net.cpp:902] inception_4b/pool_proj <- inception_4b/pool
I0603 04:24:33.621994   822 net.cpp:876] inception_4b/pool_proj -> inception_4b/pool_proj
I0603 04:24:33.624198   822 net.cpp:286] Setting up inception_4b/pool_proj
I0603 04:24:33.624220   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.624243   822 net.cpp:301] Memory required for data: 1705214980
I0603 04:24:33.624256   822 layer_factory.hpp:114] Creating layer inception_4b/relu_pool_proj
I0603 04:24:33.624270   822 net.cpp:201] Creating Layer inception_4b/relu_pool_proj
I0603 04:24:33.624277   822 net.cpp:902] inception_4b/relu_pool_proj <- inception_4b/pool_proj
I0603 04:24:33.624289   822 net.cpp:863] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)
I0603 04:24:33.624313   822 net.cpp:286] Setting up inception_4b/relu_pool_proj
I0603 04:24:33.624321   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.624326   822 net.cpp:301] Memory required for data: 1707312132
I0603 04:24:33.624331   822 layer_factory.hpp:114] Creating layer inception_4b/output
I0603 04:24:33.624346   822 net.cpp:201] Creating Layer inception_4b/output
I0603 04:24:33.624352   822 net.cpp:902] inception_4b/output <- inception_4b/1x1
I0603 04:24:33.624359   822 net.cpp:902] inception_4b/output <- inception_4b/3x3
I0603 04:24:33.624366   822 net.cpp:902] inception_4b/output <- inception_4b/5x5
I0603 04:24:33.624372   822 net.cpp:902] inception_4b/output <- inception_4b/pool_proj
I0603 04:24:33.624379   822 net.cpp:876] inception_4b/output -> inception_4b/output
I0603 04:24:33.624425   822 net.cpp:286] Setting up inception_4b/output
I0603 04:24:33.624434   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.624439   822 net.cpp:301] Memory required for data: 1724089348
I0603 04:24:33.624445   822 layer_factory.hpp:114] Creating layer inception_4b/output_inception_4b/output_0_split
I0603 04:24:33.624455   822 net.cpp:201] Creating Layer inception_4b/output_inception_4b/output_0_split
I0603 04:24:33.624461   822 net.cpp:902] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I0603 04:24:33.624469   822 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I0603 04:24:33.624480   822 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I0603 04:24:33.624488   822 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I0603 04:24:33.624496   822 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I0603 04:24:33.624519   822 net.cpp:286] Setting up inception_4b/output_inception_4b/output_0_split
I0603 04:24:33.624527   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.624533   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.624539   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.624547   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.624550   822 net.cpp:301] Memory required for data: 1791198212
I0603 04:24:33.624557   822 layer_factory.hpp:114] Creating layer inception_4c/1x1
I0603 04:24:33.624577   822 net.cpp:201] Creating Layer inception_4c/1x1
I0603 04:24:33.624583   822 net.cpp:902] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I0603 04:24:33.624594   822 net.cpp:876] inception_4c/1x1 -> inception_4c/1x1
I0603 04:24:33.627497   822 net.cpp:286] Setting up inception_4c/1x1
I0603 04:24:33.627513   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.627519   822 net.cpp:301] Memory required for data: 1795392516
I0603 04:24:33.627530   822 layer_factory.hpp:114] Creating layer inception_4c/relu_1x1
I0603 04:24:33.627545   822 net.cpp:201] Creating Layer inception_4c/relu_1x1
I0603 04:24:33.627553   822 net.cpp:902] inception_4c/relu_1x1 <- inception_4c/1x1
I0603 04:24:33.627563   822 net.cpp:863] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)
I0603 04:24:33.627586   822 net.cpp:286] Setting up inception_4c/relu_1x1
I0603 04:24:33.627594   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.627599   822 net.cpp:301] Memory required for data: 1799586820
I0603 04:24:33.627604   822 layer_factory.hpp:114] Creating layer inception_4c/3x3_reduce
I0603 04:24:33.627650   822 net.cpp:201] Creating Layer inception_4c/3x3_reduce
I0603 04:24:33.627656   822 net.cpp:902] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I0603 04:24:33.627665   822 net.cpp:876] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I0603 04:24:33.630411   822 net.cpp:286] Setting up inception_4c/3x3_reduce
I0603 04:24:33.630432   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.630439   822 net.cpp:301] Memory required for data: 1803781124
I0603 04:24:33.630450   822 layer_factory.hpp:114] Creating layer inception_4c/relu_3x3_reduce
I0603 04:24:33.630468   822 net.cpp:201] Creating Layer inception_4c/relu_3x3_reduce
I0603 04:24:33.630476   822 net.cpp:902] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce
I0603 04:24:33.630484   822 net.cpp:863] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)
I0603 04:24:33.630509   822 net.cpp:286] Setting up inception_4c/relu_3x3_reduce
I0603 04:24:33.630517   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.630522   822 net.cpp:301] Memory required for data: 1807975428
I0603 04:24:33.630528   822 layer_factory.hpp:114] Creating layer inception_4c/3x3
I0603 04:24:33.630553   822 net.cpp:201] Creating Layer inception_4c/3x3
I0603 04:24:33.630558   822 net.cpp:902] inception_4c/3x3 <- inception_4c/3x3_reduce
I0603 04:24:33.630569   822 net.cpp:876] inception_4c/3x3 -> inception_4c/3x3
I0603 04:24:33.636493   822 net.cpp:286] Setting up inception_4c/3x3
I0603 04:24:33.636515   822 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:24:33.636520   822 net.cpp:301] Memory required for data: 1816364036
I0603 04:24:33.636546   822 layer_factory.hpp:114] Creating layer inception_4c/relu_3x3
I0603 04:24:33.636562   822 net.cpp:201] Creating Layer inception_4c/relu_3x3
I0603 04:24:33.636569   822 net.cpp:902] inception_4c/relu_3x3 <- inception_4c/3x3
I0603 04:24:33.636579   822 net.cpp:863] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)
I0603 04:24:33.636602   822 net.cpp:286] Setting up inception_4c/relu_3x3
I0603 04:24:33.636610   822 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:24:33.636615   822 net.cpp:301] Memory required for data: 1824752644
I0603 04:24:33.636620   822 layer_factory.hpp:114] Creating layer inception_4c/5x5_reduce
I0603 04:24:33.636642   822 net.cpp:201] Creating Layer inception_4c/5x5_reduce
I0603 04:24:33.636648   822 net.cpp:902] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2
I0603 04:24:33.636660   822 net.cpp:876] inception_4c/5x5_reduce -> inception_4c/5x5_reduce
I0603 04:24:33.640251   822 net.cpp:286] Setting up inception_4c/5x5_reduce
I0603 04:24:33.640274   822 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:24:33.640278   822 net.cpp:301] Memory required for data: 1825539076
I0603 04:24:33.640290   822 layer_factory.hpp:114] Creating layer inception_4c/relu_5x5_reduce
I0603 04:24:33.640305   822 net.cpp:201] Creating Layer inception_4c/relu_5x5_reduce
I0603 04:24:33.640312   822 net.cpp:902] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce
I0603 04:24:33.640321   822 net.cpp:863] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)
I0603 04:24:33.640341   822 net.cpp:286] Setting up inception_4c/relu_5x5_reduce
I0603 04:24:33.640349   822 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:24:33.640354   822 net.cpp:301] Memory required for data: 1826325508
I0603 04:24:33.640360   822 layer_factory.hpp:114] Creating layer inception_4c/5x5
I0603 04:24:33.640378   822 net.cpp:201] Creating Layer inception_4c/5x5
I0603 04:24:33.640384   822 net.cpp:902] inception_4c/5x5 <- inception_4c/5x5_reduce
I0603 04:24:33.640393   822 net.cpp:876] inception_4c/5x5 -> inception_4c/5x5
I0603 04:24:33.642544   822 net.cpp:286] Setting up inception_4c/5x5
I0603 04:24:33.642565   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.642570   822 net.cpp:301] Memory required for data: 1828422660
I0603 04:24:33.642582   822 layer_factory.hpp:114] Creating layer inception_4c/relu_5x5
I0603 04:24:33.642612   822 net.cpp:201] Creating Layer inception_4c/relu_5x5
I0603 04:24:33.642621   822 net.cpp:902] inception_4c/relu_5x5 <- inception_4c/5x5
I0603 04:24:33.642628   822 net.cpp:863] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)
I0603 04:24:33.642649   822 net.cpp:286] Setting up inception_4c/relu_5x5
I0603 04:24:33.642657   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.642662   822 net.cpp:301] Memory required for data: 1830519812
I0603 04:24:33.642666   822 layer_factory.hpp:114] Creating layer inception_4c/pool
I0603 04:24:33.642678   822 net.cpp:201] Creating Layer inception_4c/pool
I0603 04:24:33.642684   822 net.cpp:902] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I0603 04:24:33.642693   822 net.cpp:876] inception_4c/pool -> inception_4c/pool
I0603 04:24:33.642711   822 net.cpp:286] Setting up inception_4c/pool
I0603 04:24:33.642719   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.642724   822 net.cpp:301] Memory required for data: 1847297028
I0603 04:24:33.642729   822 layer_factory.hpp:114] Creating layer inception_4c/pool_proj
I0603 04:24:33.642747   822 net.cpp:201] Creating Layer inception_4c/pool_proj
I0603 04:24:33.642753   822 net.cpp:902] inception_4c/pool_proj <- inception_4c/pool
I0603 04:24:33.642762   822 net.cpp:876] inception_4c/pool_proj -> inception_4c/pool_proj
I0603 04:24:33.644922   822 net.cpp:286] Setting up inception_4c/pool_proj
I0603 04:24:33.644943   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.644949   822 net.cpp:301] Memory required for data: 1849394180
I0603 04:24:33.644961   822 layer_factory.hpp:114] Creating layer inception_4c/relu_pool_proj
I0603 04:24:33.644978   822 net.cpp:201] Creating Layer inception_4c/relu_pool_proj
I0603 04:24:33.644985   822 net.cpp:902] inception_4c/relu_pool_proj <- inception_4c/pool_proj
I0603 04:24:33.644994   822 net.cpp:863] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)
I0603 04:24:33.645020   822 net.cpp:286] Setting up inception_4c/relu_pool_proj
I0603 04:24:33.645027   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.645032   822 net.cpp:301] Memory required for data: 1851491332
I0603 04:24:33.645037   822 layer_factory.hpp:114] Creating layer inception_4c/output
I0603 04:24:33.645051   822 net.cpp:201] Creating Layer inception_4c/output
I0603 04:24:33.645057   822 net.cpp:902] inception_4c/output <- inception_4c/1x1
I0603 04:24:33.645064   822 net.cpp:902] inception_4c/output <- inception_4c/3x3
I0603 04:24:33.645071   822 net.cpp:902] inception_4c/output <- inception_4c/5x5
I0603 04:24:33.645076   822 net.cpp:902] inception_4c/output <- inception_4c/pool_proj
I0603 04:24:33.645087   822 net.cpp:876] inception_4c/output -> inception_4c/output
I0603 04:24:33.645129   822 net.cpp:286] Setting up inception_4c/output
I0603 04:24:33.645138   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.645143   822 net.cpp:301] Memory required for data: 1868268548
I0603 04:24:33.645148   822 layer_factory.hpp:114] Creating layer inception_4c/output_inception_4c/output_0_split
I0603 04:24:33.645159   822 net.cpp:201] Creating Layer inception_4c/output_inception_4c/output_0_split
I0603 04:24:33.645164   822 net.cpp:902] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I0603 04:24:33.645172   822 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I0603 04:24:33.645181   822 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I0603 04:24:33.645190   822 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I0603 04:24:33.645198   822 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I0603 04:24:33.645221   822 net.cpp:286] Setting up inception_4c/output_inception_4c/output_0_split
I0603 04:24:33.645229   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.645252   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.645259   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.645265   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.645270   822 net.cpp:301] Memory required for data: 1935377412
I0603 04:24:33.645277   822 layer_factory.hpp:114] Creating layer inception_4d/1x1
I0603 04:24:33.645299   822 net.cpp:201] Creating Layer inception_4d/1x1
I0603 04:24:33.645305   822 net.cpp:902] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I0603 04:24:33.645314   822 net.cpp:876] inception_4d/1x1 -> inception_4d/1x1
I0603 04:24:33.648063   822 net.cpp:286] Setting up inception_4d/1x1
I0603 04:24:33.648079   822 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:24:33.648085   822 net.cpp:301] Memory required for data: 1939047428
I0603 04:24:33.648097   822 layer_factory.hpp:114] Creating layer inception_4d/relu_1x1
I0603 04:24:33.648111   822 net.cpp:201] Creating Layer inception_4d/relu_1x1
I0603 04:24:33.648118   822 net.cpp:902] inception_4d/relu_1x1 <- inception_4d/1x1
I0603 04:24:33.648126   822 net.cpp:863] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)
I0603 04:24:33.648149   822 net.cpp:286] Setting up inception_4d/relu_1x1
I0603 04:24:33.648159   822 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:24:33.648164   822 net.cpp:301] Memory required for data: 1942717444
I0603 04:24:33.648169   822 layer_factory.hpp:114] Creating layer inception_4d/3x3_reduce
I0603 04:24:33.648190   822 net.cpp:201] Creating Layer inception_4d/3x3_reduce
I0603 04:24:33.648196   822 net.cpp:902] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I0603 04:24:33.648207   822 net.cpp:876] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I0603 04:24:33.651206   822 net.cpp:286] Setting up inception_4d/3x3_reduce
I0603 04:24:33.651229   822 net.cpp:293] Top shape: 32 144 16 16 (1179648)
I0603 04:24:33.651235   822 net.cpp:301] Memory required for data: 1947436036
I0603 04:24:33.651247   822 layer_factory.hpp:114] Creating layer inception_4d/relu_3x3_reduce
I0603 04:24:33.651262   822 net.cpp:201] Creating Layer inception_4d/relu_3x3_reduce
I0603 04:24:33.651269   822 net.cpp:902] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce
I0603 04:24:33.651278   822 net.cpp:863] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)
I0603 04:24:33.651304   822 net.cpp:286] Setting up inception_4d/relu_3x3_reduce
I0603 04:24:33.651310   822 net.cpp:293] Top shape: 32 144 16 16 (1179648)
I0603 04:24:33.651315   822 net.cpp:301] Memory required for data: 1952154628
I0603 04:24:33.651321   822 layer_factory.hpp:114] Creating layer inception_4d/3x3
I0603 04:24:33.651343   822 net.cpp:201] Creating Layer inception_4d/3x3
I0603 04:24:33.651350   822 net.cpp:902] inception_4d/3x3 <- inception_4d/3x3_reduce
I0603 04:24:33.651361   822 net.cpp:876] inception_4d/3x3 -> inception_4d/3x3
I0603 04:24:33.658191   822 net.cpp:286] Setting up inception_4d/3x3
I0603 04:24:33.658215   822 net.cpp:293] Top shape: 32 288 16 16 (2359296)
I0603 04:24:33.658221   822 net.cpp:301] Memory required for data: 1961591812
I0603 04:24:33.658233   822 layer_factory.hpp:114] Creating layer inception_4d/relu_3x3
I0603 04:24:33.658252   822 net.cpp:201] Creating Layer inception_4d/relu_3x3
I0603 04:24:33.658259   822 net.cpp:902] inception_4d/relu_3x3 <- inception_4d/3x3
I0603 04:24:33.658268   822 net.cpp:863] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)
I0603 04:24:33.658313   822 net.cpp:286] Setting up inception_4d/relu_3x3
I0603 04:24:33.658321   822 net.cpp:293] Top shape: 32 288 16 16 (2359296)
I0603 04:24:33.658326   822 net.cpp:301] Memory required for data: 1971028996
I0603 04:24:33.658331   822 layer_factory.hpp:114] Creating layer inception_4d/5x5_reduce
I0603 04:24:33.658355   822 net.cpp:201] Creating Layer inception_4d/5x5_reduce
I0603 04:24:33.658361   822 net.cpp:902] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2
I0603 04:24:33.658372   822 net.cpp:876] inception_4d/5x5_reduce -> inception_4d/5x5_reduce
I0603 04:24:33.660223   822 net.cpp:286] Setting up inception_4d/5x5_reduce
I0603 04:24:33.660245   822 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:24:33.660253   822 net.cpp:301] Memory required for data: 1972077572
I0603 04:24:33.660264   822 layer_factory.hpp:114] Creating layer inception_4d/relu_5x5_reduce
I0603 04:24:33.660279   822 net.cpp:201] Creating Layer inception_4d/relu_5x5_reduce
I0603 04:24:33.660287   822 net.cpp:902] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce
I0603 04:24:33.660295   822 net.cpp:863] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)
I0603 04:24:33.660315   822 net.cpp:286] Setting up inception_4d/relu_5x5_reduce
I0603 04:24:33.660323   822 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:24:33.660328   822 net.cpp:301] Memory required for data: 1973126148
I0603 04:24:33.660334   822 layer_factory.hpp:114] Creating layer inception_4d/5x5
I0603 04:24:33.660352   822 net.cpp:201] Creating Layer inception_4d/5x5
I0603 04:24:33.660357   822 net.cpp:902] inception_4d/5x5 <- inception_4d/5x5_reduce
I0603 04:24:33.660367   822 net.cpp:876] inception_4d/5x5 -> inception_4d/5x5
I0603 04:24:33.662880   822 net.cpp:286] Setting up inception_4d/5x5
I0603 04:24:33.662901   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.662907   822 net.cpp:301] Memory required for data: 1975223300
I0603 04:24:33.662919   822 layer_factory.hpp:114] Creating layer inception_4d/relu_5x5
I0603 04:24:33.662933   822 net.cpp:201] Creating Layer inception_4d/relu_5x5
I0603 04:24:33.662941   822 net.cpp:902] inception_4d/relu_5x5 <- inception_4d/5x5
I0603 04:24:33.662950   822 net.cpp:863] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)
I0603 04:24:33.662971   822 net.cpp:286] Setting up inception_4d/relu_5x5
I0603 04:24:33.662978   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.662983   822 net.cpp:301] Memory required for data: 1977320452
I0603 04:24:33.662989   822 layer_factory.hpp:114] Creating layer inception_4d/pool
I0603 04:24:33.663000   822 net.cpp:201] Creating Layer inception_4d/pool
I0603 04:24:33.663007   822 net.cpp:902] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I0603 04:24:33.663015   822 net.cpp:876] inception_4d/pool -> inception_4d/pool
I0603 04:24:33.663034   822 net.cpp:286] Setting up inception_4d/pool
I0603 04:24:33.663043   822 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:24:33.663046   822 net.cpp:301] Memory required for data: 1994097668
I0603 04:24:33.663053   822 layer_factory.hpp:114] Creating layer inception_4d/pool_proj
I0603 04:24:33.663069   822 net.cpp:201] Creating Layer inception_4d/pool_proj
I0603 04:24:33.663074   822 net.cpp:902] inception_4d/pool_proj <- inception_4d/pool
I0603 04:24:33.663084   822 net.cpp:876] inception_4d/pool_proj -> inception_4d/pool_proj
I0603 04:24:33.665194   822 net.cpp:286] Setting up inception_4d/pool_proj
I0603 04:24:33.665215   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.665221   822 net.cpp:301] Memory required for data: 1996194820
I0603 04:24:33.665233   822 layer_factory.hpp:114] Creating layer inception_4d/relu_pool_proj
I0603 04:24:33.665251   822 net.cpp:201] Creating Layer inception_4d/relu_pool_proj
I0603 04:24:33.665259   822 net.cpp:902] inception_4d/relu_pool_proj <- inception_4d/pool_proj
I0603 04:24:33.665267   822 net.cpp:863] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)
I0603 04:24:33.665292   822 net.cpp:286] Setting up inception_4d/relu_pool_proj
I0603 04:24:33.665300   822 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:24:33.665305   822 net.cpp:301] Memory required for data: 1998291972
I0603 04:24:33.665311   822 layer_factory.hpp:114] Creating layer inception_4d/output
I0603 04:24:33.665321   822 net.cpp:201] Creating Layer inception_4d/output
I0603 04:24:33.665328   822 net.cpp:902] inception_4d/output <- inception_4d/1x1
I0603 04:24:33.665334   822 net.cpp:902] inception_4d/output <- inception_4d/3x3
I0603 04:24:33.665356   822 net.cpp:902] inception_4d/output <- inception_4d/5x5
I0603 04:24:33.665362   822 net.cpp:902] inception_4d/output <- inception_4d/pool_proj
I0603 04:24:33.665370   822 net.cpp:876] inception_4d/output -> inception_4d/output
I0603 04:24:33.665417   822 net.cpp:286] Setting up inception_4d/output
I0603 04:24:33.665426   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.665431   822 net.cpp:301] Memory required for data: 2015593476
I0603 04:24:33.665436   822 layer_factory.hpp:114] Creating layer inception_4d/output_inception_4d/output_0_split
I0603 04:24:33.665451   822 net.cpp:201] Creating Layer inception_4d/output_inception_4d/output_0_split
I0603 04:24:33.665455   822 net.cpp:902] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I0603 04:24:33.665463   822 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I0603 04:24:33.665473   822 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I0603 04:24:33.665482   822 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I0603 04:24:33.665490   822 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3
I0603 04:24:33.665499   822 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_4
I0603 04:24:33.665529   822 net.cpp:286] Setting up inception_4d/output_inception_4d/output_0_split
I0603 04:24:33.665539   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.665546   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.665552   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.665558   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.665565   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.665570   822 net.cpp:301] Memory required for data: 2102100996
I0603 04:24:33.665575   822 layer_factory.hpp:114] Creating layer loss2/ave_pool
I0603 04:24:33.665588   822 net.cpp:201] Creating Layer loss2/ave_pool
I0603 04:24:33.665594   822 net.cpp:902] loss2/ave_pool <- inception_4d/output_inception_4d/output_0_split_0
I0603 04:24:33.665602   822 net.cpp:876] loss2/ave_pool -> loss2/ave_pool
I0603 04:24:33.665623   822 net.cpp:286] Setting up loss2/ave_pool
I0603 04:24:33.665630   822 net.cpp:293] Top shape: 32 528 5 5 (422400)
I0603 04:24:33.665635   822 net.cpp:301] Memory required for data: 2103790596
I0603 04:24:33.665640   822 layer_factory.hpp:114] Creating layer loss2/conv
I0603 04:24:33.665659   822 net.cpp:201] Creating Layer loss2/conv
I0603 04:24:33.665666   822 net.cpp:902] loss2/conv <- loss2/ave_pool
I0603 04:24:33.665675   822 net.cpp:876] loss2/conv -> loss2/conv
I0603 04:24:33.668072   822 net.cpp:286] Setting up loss2/conv
I0603 04:24:33.668088   822 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:24:33.668093   822 net.cpp:301] Memory required for data: 2104200196
I0603 04:24:33.668104   822 layer_factory.hpp:114] Creating layer loss2/relu_conv
I0603 04:24:33.668118   822 net.cpp:201] Creating Layer loss2/relu_conv
I0603 04:24:33.668124   822 net.cpp:902] loss2/relu_conv <- loss2/conv
I0603 04:24:33.668135   822 net.cpp:863] loss2/relu_conv -> loss2/conv (in-place)
I0603 04:24:33.668160   822 net.cpp:286] Setting up loss2/relu_conv
I0603 04:24:33.668167   822 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:24:33.668172   822 net.cpp:301] Memory required for data: 2104609796
I0603 04:24:33.668177   822 layer_factory.hpp:114] Creating layer loss2/fc
I0603 04:24:33.668195   822 net.cpp:201] Creating Layer loss2/fc
I0603 04:24:33.668200   822 net.cpp:902] loss2/fc <- loss2/conv
I0603 04:24:33.668211   822 net.cpp:876] loss2/fc -> loss2/fc
I0603 04:24:33.689893   822 net.cpp:286] Setting up loss2/fc
I0603 04:24:33.689915   822 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:24:33.689921   822 net.cpp:301] Memory required for data: 2104740868
I0603 04:24:33.689951   822 layer_factory.hpp:114] Creating layer loss2/relu_fc
I0603 04:24:33.689970   822 net.cpp:201] Creating Layer loss2/relu_fc
I0603 04:24:33.689976   822 net.cpp:902] loss2/relu_fc <- loss2/fc
I0603 04:24:33.689985   822 net.cpp:863] loss2/relu_fc -> loss2/fc (in-place)
I0603 04:24:33.690008   822 net.cpp:286] Setting up loss2/relu_fc
I0603 04:24:33.690017   822 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:24:33.690022   822 net.cpp:301] Memory required for data: 2104871940
I0603 04:24:33.690027   822 layer_factory.hpp:114] Creating layer loss2/drop_fc
I0603 04:24:33.690037   822 net.cpp:201] Creating Layer loss2/drop_fc
I0603 04:24:33.690043   822 net.cpp:902] loss2/drop_fc <- loss2/fc
I0603 04:24:33.690050   822 net.cpp:863] loss2/drop_fc -> loss2/fc (in-place)
I0603 04:24:33.690064   822 net.cpp:286] Setting up loss2/drop_fc
I0603 04:24:33.690071   822 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:24:33.690076   822 net.cpp:301] Memory required for data: 2105003012
I0603 04:24:33.690081   822 layer_factory.hpp:114] Creating layer loss2/classifier
I0603 04:24:33.690096   822 net.cpp:201] Creating Layer loss2/classifier
I0603 04:24:33.690102   822 net.cpp:902] loss2/classifier <- loss2/fc
I0603 04:24:33.690111   822 net.cpp:876] loss2/classifier -> loss2/classifier
I0603 04:24:33.690174   822 net.cpp:286] Setting up loss2/classifier
I0603 04:24:33.690183   822 net.cpp:293] Top shape: 32 3 (96)
I0603 04:24:33.690188   822 net.cpp:301] Memory required for data: 2105003396
I0603 04:24:33.690197   822 layer_factory.hpp:114] Creating layer loss2/loss
I0603 04:24:33.690207   822 net.cpp:201] Creating Layer loss2/loss
I0603 04:24:33.690213   822 net.cpp:902] loss2/loss <- loss2/classifier
I0603 04:24:33.690220   822 net.cpp:902] loss2/loss <- label_DataColor256_1_split_1
I0603 04:24:33.690228   822 net.cpp:876] loss2/loss -> loss2/loss
I0603 04:24:33.690240   822 layer_factory.hpp:114] Creating layer loss2/loss
I0603 04:24:33.690264   822 net.cpp:286] Setting up loss2/loss
I0603 04:24:33.690286   822 net.cpp:293] Top shape: (1)
I0603 04:24:33.690292   822 net.cpp:296]     with loss weight 0.3
I0603 04:24:33.690315   822 net.cpp:301] Memory required for data: 2105003400
I0603 04:24:33.690320   822 layer_factory.hpp:114] Creating layer inception_4e/1x1
I0603 04:24:33.690340   822 net.cpp:201] Creating Layer inception_4e/1x1
I0603 04:24:33.690346   822 net.cpp:902] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_1
I0603 04:24:33.690354   822 net.cpp:876] inception_4e/1x1 -> inception_4e/1x1
I0603 04:24:33.694195   822 net.cpp:286] Setting up inception_4e/1x1
I0603 04:24:33.694217   822 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:24:33.694223   822 net.cpp:301] Memory required for data: 2113392008
I0603 04:24:33.694236   822 layer_factory.hpp:114] Creating layer inception_4e/relu_1x1
I0603 04:24:33.694254   822 net.cpp:201] Creating Layer inception_4e/relu_1x1
I0603 04:24:33.694262   822 net.cpp:902] inception_4e/relu_1x1 <- inception_4e/1x1
I0603 04:24:33.694286   822 net.cpp:863] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)
I0603 04:24:33.694314   822 net.cpp:286] Setting up inception_4e/relu_1x1
I0603 04:24:33.694322   822 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:24:33.694327   822 net.cpp:301] Memory required for data: 2121780616
I0603 04:24:33.694334   822 layer_factory.hpp:114] Creating layer inception_4e/3x3_reduce
I0603 04:24:33.694356   822 net.cpp:201] Creating Layer inception_4e/3x3_reduce
I0603 04:24:33.694362   822 net.cpp:902] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_2
I0603 04:24:33.694373   822 net.cpp:876] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I0603 04:24:33.697036   822 net.cpp:286] Setting up inception_4e/3x3_reduce
I0603 04:24:33.697058   822 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:24:33.697064   822 net.cpp:301] Memory required for data: 2127023496
I0603 04:24:33.697075   822 layer_factory.hpp:114] Creating layer inception_4e/relu_3x3_reduce
I0603 04:24:33.697110   822 net.cpp:201] Creating Layer inception_4e/relu_3x3_reduce
I0603 04:24:33.697118   822 net.cpp:902] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce
I0603 04:24:33.697126   822 net.cpp:863] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)
I0603 04:24:33.697151   822 net.cpp:286] Setting up inception_4e/relu_3x3_reduce
I0603 04:24:33.697160   822 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:24:33.697165   822 net.cpp:301] Memory required for data: 2132266376
I0603 04:24:33.697170   822 layer_factory.hpp:114] Creating layer inception_4e/3x3
I0603 04:24:33.697194   822 net.cpp:201] Creating Layer inception_4e/3x3
I0603 04:24:33.697201   822 net.cpp:902] inception_4e/3x3 <- inception_4e/3x3_reduce
I0603 04:24:33.697216   822 net.cpp:876] inception_4e/3x3 -> inception_4e/3x3
I0603 04:24:33.705121   822 net.cpp:286] Setting up inception_4e/3x3
I0603 04:24:33.705143   822 net.cpp:293] Top shape: 32 320 16 16 (2621440)
I0603 04:24:33.705149   822 net.cpp:301] Memory required for data: 2142752136
I0603 04:24:33.705160   822 layer_factory.hpp:114] Creating layer inception_4e/relu_3x3
I0603 04:24:33.705176   822 net.cpp:201] Creating Layer inception_4e/relu_3x3
I0603 04:24:33.705183   822 net.cpp:902] inception_4e/relu_3x3 <- inception_4e/3x3
I0603 04:24:33.705193   822 net.cpp:863] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)
I0603 04:24:33.705219   822 net.cpp:286] Setting up inception_4e/relu_3x3
I0603 04:24:33.705226   822 net.cpp:293] Top shape: 32 320 16 16 (2621440)
I0603 04:24:33.705231   822 net.cpp:301] Memory required for data: 2153237896
I0603 04:24:33.705236   822 layer_factory.hpp:114] Creating layer inception_4e/5x5_reduce
I0603 04:24:33.705256   822 net.cpp:201] Creating Layer inception_4e/5x5_reduce
I0603 04:24:33.705263   822 net.cpp:902] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_3
I0603 04:24:33.705274   822 net.cpp:876] inception_4e/5x5_reduce -> inception_4e/5x5_reduce
I0603 04:24:33.707146   822 net.cpp:286] Setting up inception_4e/5x5_reduce
I0603 04:24:33.707168   822 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:24:33.707175   822 net.cpp:301] Memory required for data: 2154286472
I0603 04:24:33.707185   822 layer_factory.hpp:114] Creating layer inception_4e/relu_5x5_reduce
I0603 04:24:33.707200   822 net.cpp:201] Creating Layer inception_4e/relu_5x5_reduce
I0603 04:24:33.707207   822 net.cpp:902] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce
I0603 04:24:33.707216   822 net.cpp:863] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)
I0603 04:24:33.707237   822 net.cpp:286] Setting up inception_4e/relu_5x5_reduce
I0603 04:24:33.707244   822 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:24:33.707249   822 net.cpp:301] Memory required for data: 2155335048
I0603 04:24:33.707254   822 layer_factory.hpp:114] Creating layer inception_4e/5x5
I0603 04:24:33.707276   822 net.cpp:201] Creating Layer inception_4e/5x5
I0603 04:24:33.707283   822 net.cpp:902] inception_4e/5x5 <- inception_4e/5x5_reduce
I0603 04:24:33.707293   822 net.cpp:876] inception_4e/5x5 -> inception_4e/5x5
I0603 04:24:33.710562   822 net.cpp:286] Setting up inception_4e/5x5
I0603 04:24:33.710583   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.710589   822 net.cpp:301] Memory required for data: 2159529352
I0603 04:24:33.710602   822 layer_factory.hpp:114] Creating layer inception_4e/relu_5x5
I0603 04:24:33.710616   822 net.cpp:201] Creating Layer inception_4e/relu_5x5
I0603 04:24:33.710624   822 net.cpp:902] inception_4e/relu_5x5 <- inception_4e/5x5
I0603 04:24:33.710633   822 net.cpp:863] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)
I0603 04:24:33.710654   822 net.cpp:286] Setting up inception_4e/relu_5x5
I0603 04:24:33.710661   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.710666   822 net.cpp:301] Memory required for data: 2163723656
I0603 04:24:33.710671   822 layer_factory.hpp:114] Creating layer inception_4e/pool
I0603 04:24:33.710683   822 net.cpp:201] Creating Layer inception_4e/pool
I0603 04:24:33.710706   822 net.cpp:902] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_4
I0603 04:24:33.710716   822 net.cpp:876] inception_4e/pool -> inception_4e/pool
I0603 04:24:33.710737   822 net.cpp:286] Setting up inception_4e/pool
I0603 04:24:33.710744   822 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:24:33.710749   822 net.cpp:301] Memory required for data: 2181025160
I0603 04:24:33.710754   822 layer_factory.hpp:114] Creating layer inception_4e/pool_proj
I0603 04:24:33.710772   822 net.cpp:201] Creating Layer inception_4e/pool_proj
I0603 04:24:33.710778   822 net.cpp:902] inception_4e/pool_proj <- inception_4e/pool
I0603 04:24:33.710786   822 net.cpp:876] inception_4e/pool_proj -> inception_4e/pool_proj
I0603 04:24:33.713425   822 net.cpp:286] Setting up inception_4e/pool_proj
I0603 04:24:33.713448   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.713454   822 net.cpp:301] Memory required for data: 2185219464
I0603 04:24:33.713464   822 layer_factory.hpp:114] Creating layer inception_4e/relu_pool_proj
I0603 04:24:33.713482   822 net.cpp:201] Creating Layer inception_4e/relu_pool_proj
I0603 04:24:33.713490   822 net.cpp:902] inception_4e/relu_pool_proj <- inception_4e/pool_proj
I0603 04:24:33.713500   822 net.cpp:863] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)
I0603 04:24:33.713526   822 net.cpp:286] Setting up inception_4e/relu_pool_proj
I0603 04:24:33.713533   822 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:24:33.713537   822 net.cpp:301] Memory required for data: 2189413768
I0603 04:24:33.713543   822 layer_factory.hpp:114] Creating layer inception_4e/output
I0603 04:24:33.713556   822 net.cpp:201] Creating Layer inception_4e/output
I0603 04:24:33.713562   822 net.cpp:902] inception_4e/output <- inception_4e/1x1
I0603 04:24:33.713569   822 net.cpp:902] inception_4e/output <- inception_4e/3x3
I0603 04:24:33.713575   822 net.cpp:902] inception_4e/output <- inception_4e/5x5
I0603 04:24:33.713582   822 net.cpp:902] inception_4e/output <- inception_4e/pool_proj
I0603 04:24:33.713591   822 net.cpp:876] inception_4e/output -> inception_4e/output
I0603 04:24:33.713636   822 net.cpp:286] Setting up inception_4e/output
I0603 04:24:33.713644   822 net.cpp:293] Top shape: 32 832 16 16 (6815744)
I0603 04:24:33.713649   822 net.cpp:301] Memory required for data: 2216676744
I0603 04:24:33.713655   822 layer_factory.hpp:114] Creating layer pool4/3x3_s2
I0603 04:24:33.713666   822 net.cpp:201] Creating Layer pool4/3x3_s2
I0603 04:24:33.713672   822 net.cpp:902] pool4/3x3_s2 <- inception_4e/output
I0603 04:24:33.713681   822 net.cpp:876] pool4/3x3_s2 -> pool4/3x3_s2
I0603 04:24:33.713699   822 net.cpp:286] Setting up pool4/3x3_s2
I0603 04:24:33.713706   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.713711   822 net.cpp:301] Memory required for data: 2223492488
I0603 04:24:33.713717   822 layer_factory.hpp:114] Creating layer pool4/3x3_s2_pool4/3x3_s2_0_split
I0603 04:24:33.713726   822 net.cpp:201] Creating Layer pool4/3x3_s2_pool4/3x3_s2_0_split
I0603 04:24:33.713732   822 net.cpp:902] pool4/3x3_s2_pool4/3x3_s2_0_split <- pool4/3x3_s2
I0603 04:24:33.713740   822 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_0
I0603 04:24:33.713750   822 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_1
I0603 04:24:33.713760   822 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_2
I0603 04:24:33.713769   822 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_3
I0603 04:24:33.713793   822 net.cpp:286] Setting up pool4/3x3_s2_pool4/3x3_s2_0_split
I0603 04:24:33.713800   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.713806   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.713814   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.713819   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.713824   822 net.cpp:301] Memory required for data: 2250755464
I0603 04:24:33.713845   822 layer_factory.hpp:114] Creating layer inception_5a/1x1
I0603 04:24:33.713862   822 net.cpp:201] Creating Layer inception_5a/1x1
I0603 04:24:33.713868   822 net.cpp:902] inception_5a/1x1 <- pool4/3x3_s2_pool4/3x3_s2_0_split_0
I0603 04:24:33.713877   822 net.cpp:876] inception_5a/1x1 -> inception_5a/1x1
I0603 04:24:33.718878   822 net.cpp:286] Setting up inception_5a/1x1
I0603 04:24:33.718899   822 net.cpp:293] Top shape: 32 256 8 8 (524288)
I0603 04:24:33.718905   822 net.cpp:301] Memory required for data: 2252852616
I0603 04:24:33.718916   822 layer_factory.hpp:114] Creating layer inception_5a/relu_1x1
I0603 04:24:33.718931   822 net.cpp:201] Creating Layer inception_5a/relu_1x1
I0603 04:24:33.718938   822 net.cpp:902] inception_5a/relu_1x1 <- inception_5a/1x1
I0603 04:24:33.718950   822 net.cpp:863] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)
I0603 04:24:33.718976   822 net.cpp:286] Setting up inception_5a/relu_1x1
I0603 04:24:33.718984   822 net.cpp:293] Top shape: 32 256 8 8 (524288)
I0603 04:24:33.718989   822 net.cpp:301] Memory required for data: 2254949768
I0603 04:24:33.718996   822 layer_factory.hpp:114] Creating layer inception_5a/3x3_reduce
I0603 04:24:33.719022   822 net.cpp:201] Creating Layer inception_5a/3x3_reduce
I0603 04:24:33.719028   822 net.cpp:902] inception_5a/3x3_reduce <- pool4/3x3_s2_pool4/3x3_s2_0_split_1
I0603 04:24:33.719039   822 net.cpp:876] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I0603 04:24:33.721935   822 net.cpp:286] Setting up inception_5a/3x3_reduce
I0603 04:24:33.721956   822 net.cpp:293] Top shape: 32 160 8 8 (327680)
I0603 04:24:33.721962   822 net.cpp:301] Memory required for data: 2256260488
I0603 04:24:33.721974   822 layer_factory.hpp:114] Creating layer inception_5a/relu_3x3_reduce
I0603 04:24:33.721988   822 net.cpp:201] Creating Layer inception_5a/relu_3x3_reduce
I0603 04:24:33.721997   822 net.cpp:902] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce
I0603 04:24:33.722005   822 net.cpp:863] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)
I0603 04:24:33.722025   822 net.cpp:286] Setting up inception_5a/relu_3x3_reduce
I0603 04:24:33.722033   822 net.cpp:293] Top shape: 32 160 8 8 (327680)
I0603 04:24:33.722038   822 net.cpp:301] Memory required for data: 2257571208
I0603 04:24:33.722044   822 layer_factory.hpp:114] Creating layer inception_5a/3x3
I0603 04:24:33.722064   822 net.cpp:201] Creating Layer inception_5a/3x3
I0603 04:24:33.722069   822 net.cpp:902] inception_5a/3x3 <- inception_5a/3x3_reduce
I0603 04:24:33.722077   822 net.cpp:876] inception_5a/3x3 -> inception_5a/3x3
I0603 04:24:33.728528   822 net.cpp:286] Setting up inception_5a/3x3
I0603 04:24:33.728550   822 net.cpp:293] Top shape: 32 320 8 8 (655360)
I0603 04:24:33.728556   822 net.cpp:301] Memory required for data: 2260192648
I0603 04:24:33.728567   822 layer_factory.hpp:114] Creating layer inception_5a/relu_3x3
I0603 04:24:33.728582   822 net.cpp:201] Creating Layer inception_5a/relu_3x3
I0603 04:24:33.728590   822 net.cpp:902] inception_5a/relu_3x3 <- inception_5a/3x3
I0603 04:24:33.728598   822 net.cpp:863] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)
I0603 04:24:33.728619   822 net.cpp:286] Setting up inception_5a/relu_3x3
I0603 04:24:33.728627   822 net.cpp:293] Top shape: 32 320 8 8 (655360)
I0603 04:24:33.728632   822 net.cpp:301] Memory required for data: 2262814088
I0603 04:24:33.728638   822 layer_factory.hpp:114] Creating layer inception_5a/5x5_reduce
I0603 04:24:33.728655   822 net.cpp:201] Creating Layer inception_5a/5x5_reduce
I0603 04:24:33.728662   822 net.cpp:902] inception_5a/5x5_reduce <- pool4/3x3_s2_pool4/3x3_s2_0_split_2
I0603 04:24:33.728672   822 net.cpp:876] inception_5a/5x5_reduce -> inception_5a/5x5_reduce
I0603 04:24:33.730232   822 net.cpp:286] Setting up inception_5a/5x5_reduce
I0603 04:24:33.730253   822 net.cpp:293] Top shape: 32 32 8 8 (65536)
I0603 04:24:33.730259   822 net.cpp:301] Memory required for data: 2263076232
I0603 04:24:33.730286   822 layer_factory.hpp:114] Creating layer inception_5a/relu_5x5_reduce
I0603 04:24:33.730319   822 net.cpp:201] Creating Layer inception_5a/relu_5x5_reduce
I0603 04:24:33.730326   822 net.cpp:902] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce
I0603 04:24:33.730334   822 net.cpp:863] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)
I0603 04:24:33.730355   822 net.cpp:286] Setting up inception_5a/relu_5x5_reduce
I0603 04:24:33.730362   822 net.cpp:293] Top shape: 32 32 8 8 (65536)
I0603 04:24:33.730367   822 net.cpp:301] Memory required for data: 2263338376
I0603 04:24:33.730372   822 layer_factory.hpp:114] Creating layer inception_5a/5x5
I0603 04:24:33.730391   822 net.cpp:201] Creating Layer inception_5a/5x5
I0603 04:24:33.730397   822 net.cpp:902] inception_5a/5x5 <- inception_5a/5x5_reduce
I0603 04:24:33.730406   822 net.cpp:876] inception_5a/5x5 -> inception_5a/5x5
I0603 04:24:33.732755   822 net.cpp:286] Setting up inception_5a/5x5
I0603 04:24:33.732776   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.732782   822 net.cpp:301] Memory required for data: 2264386952
I0603 04:24:33.732795   822 layer_factory.hpp:114] Creating layer inception_5a/relu_5x5
I0603 04:24:33.732808   822 net.cpp:201] Creating Layer inception_5a/relu_5x5
I0603 04:24:33.732815   822 net.cpp:902] inception_5a/relu_5x5 <- inception_5a/5x5
I0603 04:24:33.732828   822 net.cpp:863] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)
I0603 04:24:33.732854   822 net.cpp:286] Setting up inception_5a/relu_5x5
I0603 04:24:33.732861   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.732867   822 net.cpp:301] Memory required for data: 2265435528
I0603 04:24:33.732872   822 layer_factory.hpp:114] Creating layer inception_5a/pool
I0603 04:24:33.732885   822 net.cpp:201] Creating Layer inception_5a/pool
I0603 04:24:33.732892   822 net.cpp:902] inception_5a/pool <- pool4/3x3_s2_pool4/3x3_s2_0_split_3
I0603 04:24:33.732903   822 net.cpp:876] inception_5a/pool -> inception_5a/pool
I0603 04:24:33.732925   822 net.cpp:286] Setting up inception_5a/pool
I0603 04:24:33.732933   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.732938   822 net.cpp:301] Memory required for data: 2272251272
I0603 04:24:33.732942   822 layer_factory.hpp:114] Creating layer inception_5a/pool_proj
I0603 04:24:33.732965   822 net.cpp:201] Creating Layer inception_5a/pool_proj
I0603 04:24:33.732971   822 net.cpp:902] inception_5a/pool_proj <- inception_5a/pool
I0603 04:24:33.732980   822 net.cpp:876] inception_5a/pool_proj -> inception_5a/pool_proj
I0603 04:24:33.735815   822 net.cpp:286] Setting up inception_5a/pool_proj
I0603 04:24:33.735837   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.735843   822 net.cpp:301] Memory required for data: 2273299848
I0603 04:24:33.735855   822 layer_factory.hpp:114] Creating layer inception_5a/relu_pool_proj
I0603 04:24:33.735874   822 net.cpp:201] Creating Layer inception_5a/relu_pool_proj
I0603 04:24:33.735882   822 net.cpp:902] inception_5a/relu_pool_proj <- inception_5a/pool_proj
I0603 04:24:33.735890   822 net.cpp:863] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)
I0603 04:24:33.735916   822 net.cpp:286] Setting up inception_5a/relu_pool_proj
I0603 04:24:33.735924   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.735929   822 net.cpp:301] Memory required for data: 2274348424
I0603 04:24:33.735934   822 layer_factory.hpp:114] Creating layer inception_5a/output
I0603 04:24:33.735945   822 net.cpp:201] Creating Layer inception_5a/output
I0603 04:24:33.735951   822 net.cpp:902] inception_5a/output <- inception_5a/1x1
I0603 04:24:33.735958   822 net.cpp:902] inception_5a/output <- inception_5a/3x3
I0603 04:24:33.735965   822 net.cpp:902] inception_5a/output <- inception_5a/5x5
I0603 04:24:33.735970   822 net.cpp:902] inception_5a/output <- inception_5a/pool_proj
I0603 04:24:33.735980   822 net.cpp:876] inception_5a/output -> inception_5a/output
I0603 04:24:33.736027   822 net.cpp:286] Setting up inception_5a/output
I0603 04:24:33.736035   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.736055   822 net.cpp:301] Memory required for data: 2281164168
I0603 04:24:33.736062   822 layer_factory.hpp:114] Creating layer inception_5a/output_inception_5a/output_0_split
I0603 04:24:33.736074   822 net.cpp:201] Creating Layer inception_5a/output_inception_5a/output_0_split
I0603 04:24:33.736080   822 net.cpp:902] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0603 04:24:33.736088   822 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0603 04:24:33.736099   822 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0603 04:24:33.736107   822 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I0603 04:24:33.736115   822 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I0603 04:24:33.736142   822 net.cpp:286] Setting up inception_5a/output_inception_5a/output_0_split
I0603 04:24:33.736151   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.736158   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.736165   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.736171   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.736176   822 net.cpp:301] Memory required for data: 2308427144
I0603 04:24:33.736181   822 layer_factory.hpp:114] Creating layer inception_5b/1x1
I0603 04:24:33.736204   822 net.cpp:201] Creating Layer inception_5b/1x1
I0603 04:24:33.736210   822 net.cpp:902] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0603 04:24:33.736222   822 net.cpp:876] inception_5b/1x1 -> inception_5b/1x1
I0603 04:24:33.742866   822 net.cpp:286] Setting up inception_5b/1x1
I0603 04:24:33.742887   822 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:24:33.742893   822 net.cpp:301] Memory required for data: 2311572872
I0603 04:24:33.742905   822 layer_factory.hpp:114] Creating layer inception_5b/relu_1x1
I0603 04:24:33.742924   822 net.cpp:201] Creating Layer inception_5b/relu_1x1
I0603 04:24:33.742931   822 net.cpp:902] inception_5b/relu_1x1 <- inception_5b/1x1
I0603 04:24:33.742940   822 net.cpp:863] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)
I0603 04:24:33.742967   822 net.cpp:286] Setting up inception_5b/relu_1x1
I0603 04:24:33.742975   822 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:24:33.742980   822 net.cpp:301] Memory required for data: 2314718600
I0603 04:24:33.742986   822 layer_factory.hpp:114] Creating layer inception_5b/3x3_reduce
I0603 04:24:33.743008   822 net.cpp:201] Creating Layer inception_5b/3x3_reduce
I0603 04:24:33.743016   822 net.cpp:902] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I0603 04:24:33.743026   822 net.cpp:876] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I0603 04:24:33.746134   822 net.cpp:286] Setting up inception_5b/3x3_reduce
I0603 04:24:33.746165   822 net.cpp:293] Top shape: 32 192 8 8 (393216)
I0603 04:24:33.746173   822 net.cpp:301] Memory required for data: 2316291464
I0603 04:24:33.746186   822 layer_factory.hpp:114] Creating layer inception_5b/relu_3x3_reduce
I0603 04:24:33.746202   822 net.cpp:201] Creating Layer inception_5b/relu_3x3_reduce
I0603 04:24:33.746209   822 net.cpp:902] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce
I0603 04:24:33.746218   822 net.cpp:863] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)
I0603 04:24:33.746242   822 net.cpp:286] Setting up inception_5b/relu_3x3_reduce
I0603 04:24:33.746249   822 net.cpp:293] Top shape: 32 192 8 8 (393216)
I0603 04:24:33.746254   822 net.cpp:301] Memory required for data: 2317864328
I0603 04:24:33.746260   822 layer_factory.hpp:114] Creating layer inception_5b/3x3
I0603 04:24:33.746307   822 net.cpp:201] Creating Layer inception_5b/3x3
I0603 04:24:33.746315   822 net.cpp:902] inception_5b/3x3 <- inception_5b/3x3_reduce
I0603 04:24:33.746342   822 net.cpp:876] inception_5b/3x3 -> inception_5b/3x3
I0603 04:24:33.755676   822 net.cpp:286] Setting up inception_5b/3x3
I0603 04:24:33.755699   822 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:24:33.755705   822 net.cpp:301] Memory required for data: 2321010056
I0603 04:24:33.755717   822 layer_factory.hpp:114] Creating layer inception_5b/relu_3x3
I0603 04:24:33.755738   822 net.cpp:201] Creating Layer inception_5b/relu_3x3
I0603 04:24:33.755746   822 net.cpp:902] inception_5b/relu_3x3 <- inception_5b/3x3
I0603 04:24:33.755754   822 net.cpp:863] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)
I0603 04:24:33.755781   822 net.cpp:286] Setting up inception_5b/relu_3x3
I0603 04:24:33.755789   822 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:24:33.755794   822 net.cpp:301] Memory required for data: 2324155784
I0603 04:24:33.755800   822 layer_factory.hpp:114] Creating layer inception_5b/5x5_reduce
I0603 04:24:33.755821   822 net.cpp:201] Creating Layer inception_5b/5x5_reduce
I0603 04:24:33.755828   822 net.cpp:902] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2
I0603 04:24:33.755839   822 net.cpp:876] inception_5b/5x5_reduce -> inception_5b/5x5_reduce
I0603 04:24:33.757767   822 net.cpp:286] Setting up inception_5b/5x5_reduce
I0603 04:24:33.757791   822 net.cpp:293] Top shape: 32 48 8 8 (98304)
I0603 04:24:33.757797   822 net.cpp:301] Memory required for data: 2324549000
I0603 04:24:33.757809   822 layer_factory.hpp:114] Creating layer inception_5b/relu_5x5_reduce
I0603 04:24:33.757823   822 net.cpp:201] Creating Layer inception_5b/relu_5x5_reduce
I0603 04:24:33.757832   822 net.cpp:902] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce
I0603 04:24:33.757843   822 net.cpp:863] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)
I0603 04:24:33.757869   822 net.cpp:286] Setting up inception_5b/relu_5x5_reduce
I0603 04:24:33.757876   822 net.cpp:293] Top shape: 32 48 8 8 (98304)
I0603 04:24:33.757881   822 net.cpp:301] Memory required for data: 2324942216
I0603 04:24:33.757886   822 layer_factory.hpp:114] Creating layer inception_5b/5x5
I0603 04:24:33.757910   822 net.cpp:201] Creating Layer inception_5b/5x5
I0603 04:24:33.757916   822 net.cpp:902] inception_5b/5x5 <- inception_5b/5x5_reduce
I0603 04:24:33.757927   822 net.cpp:876] inception_5b/5x5 -> inception_5b/5x5
I0603 04:24:33.760993   822 net.cpp:286] Setting up inception_5b/5x5
I0603 04:24:33.761014   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.761021   822 net.cpp:301] Memory required for data: 2325990792
I0603 04:24:33.761032   822 layer_factory.hpp:114] Creating layer inception_5b/relu_5x5
I0603 04:24:33.761054   822 net.cpp:201] Creating Layer inception_5b/relu_5x5
I0603 04:24:33.761062   822 net.cpp:902] inception_5b/relu_5x5 <- inception_5b/5x5
I0603 04:24:33.761070   822 net.cpp:863] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)
I0603 04:24:33.761097   822 net.cpp:286] Setting up inception_5b/relu_5x5
I0603 04:24:33.761106   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.761111   822 net.cpp:301] Memory required for data: 2327039368
I0603 04:24:33.761116   822 layer_factory.hpp:114] Creating layer inception_5b/pool
I0603 04:24:33.761129   822 net.cpp:201] Creating Layer inception_5b/pool
I0603 04:24:33.761137   822 net.cpp:902] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I0603 04:24:33.761145   822 net.cpp:876] inception_5b/pool -> inception_5b/pool
I0603 04:24:33.761168   822 net.cpp:286] Setting up inception_5b/pool
I0603 04:24:33.761178   822 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:24:33.761183   822 net.cpp:301] Memory required for data: 2333855112
I0603 04:24:33.761188   822 layer_factory.hpp:114] Creating layer inception_5b/pool_proj
I0603 04:24:33.761209   822 net.cpp:201] Creating Layer inception_5b/pool_proj
I0603 04:24:33.761215   822 net.cpp:902] inception_5b/pool_proj <- inception_5b/pool
I0603 04:24:33.761226   822 net.cpp:876] inception_5b/pool_proj -> inception_5b/pool_proj
I0603 04:24:33.764055   822 net.cpp:286] Setting up inception_5b/pool_proj
I0603 04:24:33.764081   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.764086   822 net.cpp:301] Memory required for data: 2334903688
I0603 04:24:33.764098   822 layer_factory.hpp:114] Creating layer inception_5b/relu_pool_proj
I0603 04:24:33.764112   822 net.cpp:201] Creating Layer inception_5b/relu_pool_proj
I0603 04:24:33.764120   822 net.cpp:902] inception_5b/relu_pool_proj <- inception_5b/pool_proj
I0603 04:24:33.764132   822 net.cpp:863] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)
I0603 04:24:33.764161   822 net.cpp:286] Setting up inception_5b/relu_pool_proj
I0603 04:24:33.764169   822 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:24:33.764174   822 net.cpp:301] Memory required for data: 2335952264
I0603 04:24:33.764179   822 layer_factory.hpp:114] Creating layer inception_5b/output
I0603 04:24:33.764190   822 net.cpp:201] Creating Layer inception_5b/output
I0603 04:24:33.764196   822 net.cpp:902] inception_5b/output <- inception_5b/1x1
I0603 04:24:33.764204   822 net.cpp:902] inception_5b/output <- inception_5b/3x3
I0603 04:24:33.764209   822 net.cpp:902] inception_5b/output <- inception_5b/5x5
I0603 04:24:33.764215   822 net.cpp:902] inception_5b/output <- inception_5b/pool_proj
I0603 04:24:33.764225   822 net.cpp:876] inception_5b/output -> inception_5b/output
I0603 04:24:33.764272   822 net.cpp:286] Setting up inception_5b/output
I0603 04:24:33.764281   822 net.cpp:293] Top shape: 32 1024 8 8 (2097152)
I0603 04:24:33.764286   822 net.cpp:301] Memory required for data: 2344340872
I0603 04:24:33.764292   822 layer_factory.hpp:114] Creating layer pool5/7x7_s1
I0603 04:24:33.764303   822 net.cpp:201] Creating Layer pool5/7x7_s1
I0603 04:24:33.764309   822 net.cpp:902] pool5/7x7_s1 <- inception_5b/output
I0603 04:24:33.764319   822 net.cpp:876] pool5/7x7_s1 -> pool5/7x7_s1
I0603 04:24:33.764341   822 net.cpp:286] Setting up pool5/7x7_s1
I0603 04:24:33.764348   822 net.cpp:293] Top shape: 32 1024 2 2 (131072)
I0603 04:24:33.764353   822 net.cpp:301] Memory required for data: 2344865160
I0603 04:24:33.764358   822 layer_factory.hpp:114] Creating layer pool5/drop_7x7_s1
I0603 04:24:33.764370   822 net.cpp:201] Creating Layer pool5/drop_7x7_s1
I0603 04:24:33.764377   822 net.cpp:902] pool5/drop_7x7_s1 <- pool5/7x7_s1
I0603 04:24:33.764385   822 net.cpp:863] pool5/drop_7x7_s1 -> pool5/7x7_s1 (in-place)
I0603 04:24:33.764402   822 net.cpp:286] Setting up pool5/drop_7x7_s1
I0603 04:24:33.764410   822 net.cpp:293] Top shape: 32 1024 2 2 (131072)
I0603 04:24:33.764415   822 net.cpp:301] Memory required for data: 2345389448
I0603 04:24:33.764420   822 layer_factory.hpp:114] Creating layer loss3/classifier
I0603 04:24:33.764436   822 net.cpp:201] Creating Layer loss3/classifier
I0603 04:24:33.764441   822 net.cpp:902] loss3/classifier <- pool5/7x7_s1
I0603 04:24:33.764451   822 net.cpp:876] loss3/classifier -> loss3/classifier
I0603 04:24:33.764619   822 net.cpp:286] Setting up loss3/classifier
I0603 04:24:33.764628   822 net.cpp:293] Top shape: 32 3 (96)
I0603 04:24:33.764633   822 net.cpp:301] Memory required for data: 2345389832
I0603 04:24:33.764642   822 layer_factory.hpp:114] Creating layer loss3/classifier_loss3/classifier_0_split
I0603 04:24:33.764654   822 net.cpp:201] Creating Layer loss3/classifier_loss3/classifier_0_split
I0603 04:24:33.764660   822 net.cpp:902] loss3/classifier_loss3/classifier_0_split <- loss3/classifier
I0603 04:24:33.764669   822 net.cpp:876] loss3/classifier_loss3/classifier_0_split -> loss3/classifier_loss3/classifier_0_split_0
I0603 04:24:33.764678   822 net.cpp:876] loss3/classifier_loss3/classifier_0_split -> loss3/classifier_loss3/classifier_0_split_1
I0603 04:24:33.764700   822 net.cpp:286] Setting up loss3/classifier_loss3/classifier_0_split
I0603 04:24:33.764708   822 net.cpp:293] Top shape: 32 3 (96)
I0603 04:24:33.764714   822 net.cpp:293] Top shape: 32 3 (96)
I0603 04:24:33.764719   822 net.cpp:301] Memory required for data: 2345390600
I0603 04:24:33.764722   822 layer_factory.hpp:114] Creating layer loss3/loss
I0603 04:24:33.764751   822 net.cpp:201] Creating Layer loss3/loss
I0603 04:24:33.764758   822 net.cpp:902] loss3/loss <- loss3/classifier_loss3/classifier_0_split_0
I0603 04:24:33.764765   822 net.cpp:902] loss3/loss <- label_DataColor256_1_split_2
I0603 04:24:33.764775   822 net.cpp:876] loss3/loss -> loss
I0603 04:24:33.764787   822 layer_factory.hpp:114] Creating layer loss3/loss
I0603 04:24:33.764814   822 net.cpp:286] Setting up loss3/loss
I0603 04:24:33.764822   822 net.cpp:293] Top shape: (1)
I0603 04:24:33.764827   822 net.cpp:296]     with loss weight 1
I0603 04:24:33.764844   822 net.cpp:301] Memory required for data: 2345390604
I0603 04:24:33.764849   822 layer_factory.hpp:114] Creating layer accuracy
I0603 04:24:33.764858   822 net.cpp:201] Creating Layer accuracy
I0603 04:24:33.764863   822 net.cpp:902] accuracy <- loss3/classifier_loss3/classifier_0_split_1
I0603 04:24:33.764868   822 net.cpp:902] accuracy <- label_DataColor256_1_split_3
I0603 04:24:33.764878   822 net.cpp:876] accuracy -> accuracy
I0603 04:24:33.764891   822 net.cpp:286] Setting up accuracy
I0603 04:24:33.764899   822 net.cpp:293] Top shape: (1)
I0603 04:24:33.764904   822 net.cpp:301] Memory required for data: 2345390608
I0603 04:24:33.764909   822 net.cpp:365] accuracy does not need backward computation.
I0603 04:24:33.764914   822 net.cpp:363] loss3/loss needs backward computation.
I0603 04:24:33.764919   822 net.cpp:363] loss3/classifier_loss3/classifier_0_split needs backward computation.
I0603 04:24:33.764925   822 net.cpp:363] loss3/classifier needs backward computation.
I0603 04:24:33.764930   822 net.cpp:363] pool5/drop_7x7_s1 needs backward computation.
I0603 04:24:33.764933   822 net.cpp:363] pool5/7x7_s1 needs backward computation.
I0603 04:24:33.764938   822 net.cpp:363] inception_5b/output needs backward computation.
I0603 04:24:33.764945   822 net.cpp:363] inception_5b/relu_pool_proj needs backward computation.
I0603 04:24:33.764952   822 net.cpp:363] inception_5b/pool_proj needs backward computation.
I0603 04:24:33.764958   822 net.cpp:363] inception_5b/pool needs backward computation.
I0603 04:24:33.764963   822 net.cpp:363] inception_5b/relu_5x5 needs backward computation.
I0603 04:24:33.764968   822 net.cpp:363] inception_5b/5x5 needs backward computation.
I0603 04:24:33.764973   822 net.cpp:363] inception_5b/relu_5x5_reduce needs backward computation.
I0603 04:24:33.764978   822 net.cpp:363] inception_5b/5x5_reduce needs backward computation.
I0603 04:24:33.764983   822 net.cpp:363] inception_5b/relu_3x3 needs backward computation.
I0603 04:24:33.764988   822 net.cpp:363] inception_5b/3x3 needs backward computation.
I0603 04:24:33.764993   822 net.cpp:363] inception_5b/relu_3x3_reduce needs backward computation.
I0603 04:24:33.764998   822 net.cpp:363] inception_5b/3x3_reduce needs backward computation.
I0603 04:24:33.765003   822 net.cpp:363] inception_5b/relu_1x1 needs backward computation.
I0603 04:24:33.765008   822 net.cpp:363] inception_5b/1x1 needs backward computation.
I0603 04:24:33.765014   822 net.cpp:363] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0603 04:24:33.765019   822 net.cpp:363] inception_5a/output needs backward computation.
I0603 04:24:33.765027   822 net.cpp:363] inception_5a/relu_pool_proj needs backward computation.
I0603 04:24:33.765031   822 net.cpp:363] inception_5a/pool_proj needs backward computation.
I0603 04:24:33.765036   822 net.cpp:363] inception_5a/pool needs backward computation.
I0603 04:24:33.765041   822 net.cpp:363] inception_5a/relu_5x5 needs backward computation.
I0603 04:24:33.765046   822 net.cpp:363] inception_5a/5x5 needs backward computation.
I0603 04:24:33.765051   822 net.cpp:363] inception_5a/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765056   822 net.cpp:363] inception_5a/5x5_reduce needs backward computation.
I0603 04:24:33.765061   822 net.cpp:363] inception_5a/relu_3x3 needs backward computation.
I0603 04:24:33.765066   822 net.cpp:363] inception_5a/3x3 needs backward computation.
I0603 04:24:33.765089   822 net.cpp:363] inception_5a/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765094   822 net.cpp:363] inception_5a/3x3_reduce needs backward computation.
I0603 04:24:33.765099   822 net.cpp:363] inception_5a/relu_1x1 needs backward computation.
I0603 04:24:33.765103   822 net.cpp:363] inception_5a/1x1 needs backward computation.
I0603 04:24:33.765110   822 net.cpp:363] pool4/3x3_s2_pool4/3x3_s2_0_split needs backward computation.
I0603 04:24:33.765115   822 net.cpp:363] pool4/3x3_s2 needs backward computation.
I0603 04:24:33.765120   822 net.cpp:363] inception_4e/output needs backward computation.
I0603 04:24:33.765126   822 net.cpp:363] inception_4e/relu_pool_proj needs backward computation.
I0603 04:24:33.765131   822 net.cpp:363] inception_4e/pool_proj needs backward computation.
I0603 04:24:33.765136   822 net.cpp:363] inception_4e/pool needs backward computation.
I0603 04:24:33.765142   822 net.cpp:363] inception_4e/relu_5x5 needs backward computation.
I0603 04:24:33.765147   822 net.cpp:363] inception_4e/5x5 needs backward computation.
I0603 04:24:33.765152   822 net.cpp:363] inception_4e/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765157   822 net.cpp:363] inception_4e/5x5_reduce needs backward computation.
I0603 04:24:33.765163   822 net.cpp:363] inception_4e/relu_3x3 needs backward computation.
I0603 04:24:33.765168   822 net.cpp:363] inception_4e/3x3 needs backward computation.
I0603 04:24:33.765173   822 net.cpp:363] inception_4e/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765178   822 net.cpp:363] inception_4e/3x3_reduce needs backward computation.
I0603 04:24:33.765184   822 net.cpp:363] inception_4e/relu_1x1 needs backward computation.
I0603 04:24:33.765189   822 net.cpp:363] inception_4e/1x1 needs backward computation.
I0603 04:24:33.765194   822 net.cpp:363] loss2/loss needs backward computation.
I0603 04:24:33.765202   822 net.cpp:363] loss2/classifier needs backward computation.
I0603 04:24:33.765208   822 net.cpp:363] loss2/drop_fc needs backward computation.
I0603 04:24:33.765213   822 net.cpp:363] loss2/relu_fc needs backward computation.
I0603 04:24:33.765218   822 net.cpp:363] loss2/fc needs backward computation.
I0603 04:24:33.765223   822 net.cpp:363] loss2/relu_conv needs backward computation.
I0603 04:24:33.765228   822 net.cpp:363] loss2/conv needs backward computation.
I0603 04:24:33.765234   822 net.cpp:363] loss2/ave_pool needs backward computation.
I0603 04:24:33.765239   822 net.cpp:363] inception_4d/output_inception_4d/output_0_split needs backward computation.
I0603 04:24:33.765246   822 net.cpp:363] inception_4d/output needs backward computation.
I0603 04:24:33.765254   822 net.cpp:363] inception_4d/relu_pool_proj needs backward computation.
I0603 04:24:33.765259   822 net.cpp:363] inception_4d/pool_proj needs backward computation.
I0603 04:24:33.765264   822 net.cpp:363] inception_4d/pool needs backward computation.
I0603 04:24:33.765270   822 net.cpp:363] inception_4d/relu_5x5 needs backward computation.
I0603 04:24:33.765275   822 net.cpp:363] inception_4d/5x5 needs backward computation.
I0603 04:24:33.765282   822 net.cpp:363] inception_4d/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765287   822 net.cpp:363] inception_4d/5x5_reduce needs backward computation.
I0603 04:24:33.765293   822 net.cpp:363] inception_4d/relu_3x3 needs backward computation.
I0603 04:24:33.765298   822 net.cpp:363] inception_4d/3x3 needs backward computation.
I0603 04:24:33.765305   822 net.cpp:363] inception_4d/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765310   822 net.cpp:363] inception_4d/3x3_reduce needs backward computation.
I0603 04:24:33.765314   822 net.cpp:363] inception_4d/relu_1x1 needs backward computation.
I0603 04:24:33.765319   822 net.cpp:363] inception_4d/1x1 needs backward computation.
I0603 04:24:33.765327   822 net.cpp:363] inception_4c/output_inception_4c/output_0_split needs backward computation.
I0603 04:24:33.765333   822 net.cpp:363] inception_4c/output needs backward computation.
I0603 04:24:33.765348   822 net.cpp:363] inception_4c/relu_pool_proj needs backward computation.
I0603 04:24:33.765354   822 net.cpp:363] inception_4c/pool_proj needs backward computation.
I0603 04:24:33.765360   822 net.cpp:363] inception_4c/pool needs backward computation.
I0603 04:24:33.765367   822 net.cpp:363] inception_4c/relu_5x5 needs backward computation.
I0603 04:24:33.765372   822 net.cpp:363] inception_4c/5x5 needs backward computation.
I0603 04:24:33.765377   822 net.cpp:363] inception_4c/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765382   822 net.cpp:363] inception_4c/5x5_reduce needs backward computation.
I0603 04:24:33.765388   822 net.cpp:363] inception_4c/relu_3x3 needs backward computation.
I0603 04:24:33.765393   822 net.cpp:363] inception_4c/3x3 needs backward computation.
I0603 04:24:33.765398   822 net.cpp:363] inception_4c/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765403   822 net.cpp:363] inception_4c/3x3_reduce needs backward computation.
I0603 04:24:33.765408   822 net.cpp:363] inception_4c/relu_1x1 needs backward computation.
I0603 04:24:33.765414   822 net.cpp:363] inception_4c/1x1 needs backward computation.
I0603 04:24:33.765419   822 net.cpp:363] inception_4b/output_inception_4b/output_0_split needs backward computation.
I0603 04:24:33.765425   822 net.cpp:363] inception_4b/output needs backward computation.
I0603 04:24:33.765431   822 net.cpp:363] inception_4b/relu_pool_proj needs backward computation.
I0603 04:24:33.765437   822 net.cpp:363] inception_4b/pool_proj needs backward computation.
I0603 04:24:33.765442   822 net.cpp:363] inception_4b/pool needs backward computation.
I0603 04:24:33.765447   822 net.cpp:363] inception_4b/relu_5x5 needs backward computation.
I0603 04:24:33.765453   822 net.cpp:363] inception_4b/5x5 needs backward computation.
I0603 04:24:33.765458   822 net.cpp:363] inception_4b/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765465   822 net.cpp:363] inception_4b/5x5_reduce needs backward computation.
I0603 04:24:33.765470   822 net.cpp:363] inception_4b/relu_3x3 needs backward computation.
I0603 04:24:33.765475   822 net.cpp:363] inception_4b/3x3 needs backward computation.
I0603 04:24:33.765480   822 net.cpp:363] inception_4b/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765486   822 net.cpp:363] inception_4b/3x3_reduce needs backward computation.
I0603 04:24:33.765491   822 net.cpp:363] inception_4b/relu_1x1 needs backward computation.
I0603 04:24:33.765496   822 net.cpp:363] inception_4b/1x1 needs backward computation.
I0603 04:24:33.765502   822 net.cpp:363] loss1/loss needs backward computation.
I0603 04:24:33.765508   822 net.cpp:363] loss1/classifier needs backward computation.
I0603 04:24:33.765514   822 net.cpp:363] loss1/drop_fc needs backward computation.
I0603 04:24:33.765519   822 net.cpp:363] loss1/relu_fc needs backward computation.
I0603 04:24:33.765524   822 net.cpp:363] loss1/fc needs backward computation.
I0603 04:24:33.765530   822 net.cpp:363] loss1/relu_conv needs backward computation.
I0603 04:24:33.765535   822 net.cpp:363] loss1/conv needs backward computation.
I0603 04:24:33.765542   822 net.cpp:363] loss1/ave_pool needs backward computation.
I0603 04:24:33.765547   822 net.cpp:363] inception_4a/output_inception_4a/output_0_split needs backward computation.
I0603 04:24:33.765552   822 net.cpp:363] inception_4a/output needs backward computation.
I0603 04:24:33.765561   822 net.cpp:363] inception_4a/relu_pool_proj needs backward computation.
I0603 04:24:33.765568   822 net.cpp:363] inception_4a/pool_proj needs backward computation.
I0603 04:24:33.765573   822 net.cpp:363] inception_4a/pool needs backward computation.
I0603 04:24:33.765578   822 net.cpp:363] inception_4a/relu_5x5 needs backward computation.
I0603 04:24:33.765583   822 net.cpp:363] inception_4a/5x5 needs backward computation.
I0603 04:24:33.765589   822 net.cpp:363] inception_4a/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765595   822 net.cpp:363] inception_4a/5x5_reduce needs backward computation.
I0603 04:24:33.765610   822 net.cpp:363] inception_4a/relu_3x3 needs backward computation.
I0603 04:24:33.765615   822 net.cpp:363] inception_4a/3x3 needs backward computation.
I0603 04:24:33.765621   822 net.cpp:363] inception_4a/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765626   822 net.cpp:363] inception_4a/3x3_reduce needs backward computation.
I0603 04:24:33.765631   822 net.cpp:363] inception_4a/relu_1x1 needs backward computation.
I0603 04:24:33.765637   822 net.cpp:363] inception_4a/1x1 needs backward computation.
I0603 04:24:33.765643   822 net.cpp:363] pool3/3x3_s2_pool3/3x3_s2_0_split needs backward computation.
I0603 04:24:33.765648   822 net.cpp:363] pool3/3x3_s2 needs backward computation.
I0603 04:24:33.765655   822 net.cpp:363] inception_3b/output needs backward computation.
I0603 04:24:33.765661   822 net.cpp:363] inception_3b/relu_pool_proj needs backward computation.
I0603 04:24:33.765667   822 net.cpp:363] inception_3b/pool_proj needs backward computation.
I0603 04:24:33.765672   822 net.cpp:363] inception_3b/pool needs backward computation.
I0603 04:24:33.765678   822 net.cpp:363] inception_3b/relu_5x5 needs backward computation.
I0603 04:24:33.765683   822 net.cpp:363] inception_3b/5x5 needs backward computation.
I0603 04:24:33.765689   822 net.cpp:363] inception_3b/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765694   822 net.cpp:363] inception_3b/5x5_reduce needs backward computation.
I0603 04:24:33.765700   822 net.cpp:363] inception_3b/relu_3x3 needs backward computation.
I0603 04:24:33.765705   822 net.cpp:363] inception_3b/3x3 needs backward computation.
I0603 04:24:33.765712   822 net.cpp:363] inception_3b/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765717   822 net.cpp:363] inception_3b/3x3_reduce needs backward computation.
I0603 04:24:33.765722   822 net.cpp:363] inception_3b/relu_1x1 needs backward computation.
I0603 04:24:33.765727   822 net.cpp:363] inception_3b/1x1 needs backward computation.
I0603 04:24:33.765733   822 net.cpp:363] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0603 04:24:33.765739   822 net.cpp:363] inception_3a/output needs backward computation.
I0603 04:24:33.765746   822 net.cpp:363] inception_3a/relu_pool_proj needs backward computation.
I0603 04:24:33.765753   822 net.cpp:363] inception_3a/pool_proj needs backward computation.
I0603 04:24:33.765758   822 net.cpp:363] inception_3a/pool needs backward computation.
I0603 04:24:33.765763   822 net.cpp:363] inception_3a/relu_5x5 needs backward computation.
I0603 04:24:33.765769   822 net.cpp:363] inception_3a/5x5 needs backward computation.
I0603 04:24:33.765774   822 net.cpp:363] inception_3a/relu_5x5_reduce needs backward computation.
I0603 04:24:33.765780   822 net.cpp:363] inception_3a/5x5_reduce needs backward computation.
I0603 04:24:33.765785   822 net.cpp:363] inception_3a/relu_3x3 needs backward computation.
I0603 04:24:33.765791   822 net.cpp:363] inception_3a/3x3 needs backward computation.
I0603 04:24:33.765797   822 net.cpp:363] inception_3a/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765802   822 net.cpp:363] inception_3a/3x3_reduce needs backward computation.
I0603 04:24:33.765807   822 net.cpp:363] inception_3a/relu_1x1 needs backward computation.
I0603 04:24:33.765813   822 net.cpp:363] inception_3a/1x1 needs backward computation.
I0603 04:24:33.765818   822 net.cpp:363] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I0603 04:24:33.765825   822 net.cpp:363] pool2/3x3_s2 needs backward computation.
I0603 04:24:33.765830   822 net.cpp:363] conv2/norm2 needs backward computation.
I0603 04:24:33.765836   822 net.cpp:363] conv2/relu_3x3 needs backward computation.
I0603 04:24:33.765841   822 net.cpp:363] conv2/3x3 needs backward computation.
I0603 04:24:33.765846   822 net.cpp:363] conv2/relu_3x3_reduce needs backward computation.
I0603 04:24:33.765852   822 net.cpp:363] conv2/3x3_reduce needs backward computation.
I0603 04:24:33.765857   822 net.cpp:363] pool1/norm1 needs backward computation.
I0603 04:24:33.765871   822 net.cpp:363] pool1/3x3_s2 needs backward computation.
I0603 04:24:33.765877   822 net.cpp:363] conv1/relu_7x7 needs backward computation.
I0603 04:24:33.765882   822 net.cpp:363] conv1/7x7_s2 needs backward computation.
I0603 04:24:33.765889   822 net.cpp:365] label_DataColor256_1_split does not need backward computation.
I0603 04:24:33.765895   822 net.cpp:365] DataColor256 does not need backward computation.
I0603 04:24:33.765900   822 net.cpp:407] This network produces output accuracy
I0603 04:24:33.765907   822 net.cpp:407] This network produces output loss
I0603 04:24:33.765913   822 net.cpp:407] This network produces output loss1/loss
I0603 04:24:33.765918   822 net.cpp:407] This network produces output loss2/loss
Rank:0: Finalize:ComputeOp: DataColor256(0) - 0 in, 2 out, 0 wts, 32 localMB, 0 gMBOff
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
Rank:0: Finalize:ComputeOp: label_DataColor256_1_split(1) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 0: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 2: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 3: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:24:33.766355   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 1, bottom_id 0, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: conv1/7x7_s2(2) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.766372   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 2, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: conv1/relu_7x7(3) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.766386   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 3, bottom_id 0, calculated bottom_size 134217728, real bottom_size 134217728
Rank:0: Finalize:ComputeOp: pool1/3x3_s2(4) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.766396   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 4, bottom_id 0, calculated bottom_size 134217728, real bottom_size 134217728
Rank:0: Finalize:ComputeOp: pool1/norm1(5) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.766407   822 net.cpp:470] InitNet: check bottom sizes for layer LRN, layer_id 5, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/3x3_reduce(6) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:4096 LLen:4096 GOff:0 OLen: 4096 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.766419   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 6, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/relu_3x3_reduce(7) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.766430   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 7, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/3x3(8) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:24:33.766443   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 8, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/relu_3x3(9) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766453   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 9, bottom_id 0, calculated bottom_size 100663296, real bottom_size 100663296
Rank:0: Finalize:ComputeOp: conv2/norm2(10) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766463   822 net.cpp:470] InitNet: check bottom sizes for layer LRN, layer_id 10, bottom_id 0, calculated bottom_size 100663296, real bottom_size 100663296
Rank:0: Finalize:ComputeOp: pool2/3x3_s2(11) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766474   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 11, bottom_id 0, calculated bottom_size 100663296, real bottom_size 100663296
Rank:0: Finalize:ComputeOp: pool2/3x3_s2_pool2/3x3_s2_0_split(12) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 1: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 2: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 3: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766489   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 12, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/1x1(13) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.766500   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 13, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_1x1(14) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.766511   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 14, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_3a/3x3_reduce(15) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
WT 0: GLen:18432 LLen:18432 GOff:0 OLen: 18432 OOff:0 NeedComms:False 
WT 1: GLen:96 LLen:96 GOff:0 OLen: 96 OOff:0 NeedComms:False 
I0603 04:24:33.766525   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 15, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_3x3_reduce(16) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
I0603 04:24:33.766535   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 16, bottom_id 0, calculated bottom_size 12582912, real bottom_size 12582912
Rank:0: Finalize:ComputeOp: inception_3a/3x3(17) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.766547   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 17, bottom_id 0, calculated bottom_size 12582912, real bottom_size 12582912
Rank:0: Finalize:ComputeOp: inception_3a/relu_3x3(18) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.766558   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 18, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3a/5x5_reduce(19) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:16 LLen:16 GOff:0 OLen: 16 OOff:0 NeedComms:False 
I0603 04:24:33.766571   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 19, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_5x5_reduce(20) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
I0603 04:24:33.766582   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 20, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_3a/5x5(21) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:512 LLen:512 GOff:0 OLen: 512 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:24:33.766605   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 21, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_3a/relu_5x5(22) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:24:33.766616   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 22, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3a/pool(23) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766625   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 23, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/pool_proj(24) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:6144 LLen:6144 GOff:0 OLen: 6144 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:24:33.766639   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 24, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_pool_proj(25) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:24:33.766649   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 25, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3a/output(27) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 1: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 2: GLen:32 LLen:32 GOff:0 NeedComms:False
IFM 3: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:24:33.766662   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
I0603 04:24:33.766667   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 1, calculated bottom_size 16777216, real bottom_size 16777216
I0603 04:24:33.766671   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 2, calculated bottom_size 4194304, real bottom_size 4194304
I0603 04:24:33.766676   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 3, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3a/output_inception_3a/output_0_split(28) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 1: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 2: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 3: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:24:33.766688   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 27, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/1x1(29) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.766700   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 28, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_1x1(30) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.766710   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 29, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3b/3x3_reduce(31) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.766723   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 30, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_3x3_reduce(32) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.766736   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 31, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3b/3x3(33) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:24576 LLen:24576 GOff:0 OLen: 24576 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:24:33.766748   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 32, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3b/relu_3x3(34) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766759   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 33, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3b/5x5_reduce(35) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:8192 LLen:8192 GOff:0 OLen: 8192 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:24:33.766772   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 34, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_5x5_reduce(36) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:24:33.766783   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 35, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3b/5x5(37) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:96 LLen:96 GOff:0 OLen: 96 OOff:0 NeedComms:False 
I0603 04:24:33.766796   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 36, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3b/relu_5x5(38) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
I0603 04:24:33.766806   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 37, bottom_id 0, calculated bottom_size 12582912, real bottom_size 12582912
Rank:0: Finalize:ComputeOp: inception_3b/pool(39) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:24:33.766816   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 38, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/pool_proj(40) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:16384 LLen:16384 GOff:0 OLen: 16384 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.766829   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 39, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_pool_proj(41) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.766839   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 40, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_3b/output(43) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 1: GLen:192 LLen:192 GOff:0 NeedComms:False
IFM 2: GLen:96 LLen:96 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:24:33.766860   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
I0603 04:24:33.766865   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 1, calculated bottom_size 25165824, real bottom_size 25165824
I0603 04:24:33.766870   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 2, calculated bottom_size 12582912, real bottom_size 12582912
I0603 04:24:33.766875   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 3, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: pool3/3x3_s2(44) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:24:33.766885   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 42, bottom_id 0, calculated bottom_size 62914560, real bottom_size 62914560
Rank:0: Finalize:ComputeOp: pool3/3x3_s2_pool3/3x3_s2_0_split(45) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 1: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 2: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 3: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:24:33.766896   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 43, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/1x1(46) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:92160 LLen:92160 GOff:0 OLen: 92160 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:24:33.766908   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 44, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_1x1(47) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.766919   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 45, bottom_id 0, calculated bottom_size 6291456, real bottom_size 6291456
Rank:0: Finalize:ComputeOp: inception_4a/3x3_reduce(48) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
WT 0: GLen:46080 LLen:46080 GOff:0 OLen: 46080 OOff:0 NeedComms:False 
WT 1: GLen:96 LLen:96 GOff:0 OLen: 96 OOff:0 NeedComms:False 
I0603 04:24:33.766932   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 46, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_3x3_reduce(49) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
I0603 04:24:33.766943   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 47, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_4a/3x3(50) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:208 LLen:208 GOff:0 NeedComms:False
WT 0: GLen:19968 LLen:19968 GOff:0 OLen: 19968 OOff:0 NeedComms:False 
WT 1: GLen:208 LLen:208 GOff:0 OLen: 208 OOff:0 NeedComms:False 
I0603 04:24:33.766955   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 48, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_4a/relu_3x3(51) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:208 LLen:208 GOff:0 NeedComms:False
OFM 0: GLen:208 LLen:208 GOff:0 NeedComms:False
I0603 04:24:33.766966   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 49, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_4a/5x5_reduce(52) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
WT 0: GLen:7680 LLen:7680 GOff:0 OLen: 7680 OOff:0 NeedComms:False 
WT 1: GLen:16 LLen:16 GOff:0 OLen: 16 OOff:0 NeedComms:False 
I0603 04:24:33.766978   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 50, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_5x5_reduce(53) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
I0603 04:24:33.766989   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 51, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: inception_4a/5x5(54) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
WT 0: GLen:768 LLen:768 GOff:0 OLen: 768 OOff:0 NeedComms:False 
WT 1: GLen:48 LLen:48 GOff:0 OLen: 48 OOff:0 NeedComms:False 
I0603 04:24:33.767001   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 52, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: inception_4a/relu_5x5(55) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
I0603 04:24:33.767011   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 53, bottom_id 0, calculated bottom_size 1572864, real bottom_size 1572864
Rank:0: Finalize:ComputeOp: inception_4a/pool(56) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:24:33.767021   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 54, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/pool_proj(57) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:30720 LLen:30720 GOff:0 OLen: 30720 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767035   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 55, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_pool_proj(58) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767045   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 56, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4a/output(60) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
IFM 1: GLen:208 LLen:208 GOff:0 NeedComms:False
IFM 2: GLen:48 LLen:48 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767058   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 0, calculated bottom_size 6291456, real bottom_size 6291456
I0603 04:24:33.767063   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 1, calculated bottom_size 6815744, real bottom_size 6815744
I0603 04:24:33.767068   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 2, calculated bottom_size 1572864, real bottom_size 1572864
I0603 04:24:33.767073   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4a/output_inception_4a/output_0_split(61) - 1 in, 5 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 1: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 2: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 3: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 4: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767086   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 58, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: loss1/ave_pool(62) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767103   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 59, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: loss1/conv(63) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:65536 LLen:65536 GOff:0 OLen: 65536 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.767117   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 60, bottom_id 0, calculated bottom_size 1638400, real bottom_size 1638400
Rank:0: Finalize:ComputeOp: loss1/relu_conv(64) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.767127   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 61, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss1/fc(65) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
WT 0: GLen:3276800 LLen:3276800 GOff:0 OLen: 3276800 OOff:0 NeedComms:False 
WT 1: GLen:1024 LLen:1024 GOff:0 OLen: 1024 OOff:0 NeedComms:False 
I0603 04:24:33.767139   822 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 62, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss1/relu_fc(66) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.767150   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 63, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss1/drop_fc(67) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.767161   822 net.cpp:470] InitNet: check bottom sizes for layer Dropout, layer_id 64, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss1/classifier(68) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:3 LLen:3 GOff:0 OLen: 3 OOff:0 NeedComms:False 
I0603 04:24:33.767174   822 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 65, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss1/loss(69) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:24:33.767184   822 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 66, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:24:33.767189   822 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 66, bottom_id 1, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: inception_4b/1x1(70) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
WT 0: GLen:81920 LLen:81920 GOff:0 OLen: 81920 OOff:0 NeedComms:False 
WT 1: GLen:160 LLen:160 GOff:0 OLen: 160 OOff:0 NeedComms:False 
I0603 04:24:33.767202   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 67, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_1x1(71) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
I0603 04:24:33.767212   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 68, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
Rank:0: Finalize:ComputeOp: inception_4b/3x3_reduce(72) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
WT 0: GLen:57344 LLen:57344 GOff:0 OLen: 57344 OOff:0 NeedComms:False 
WT 1: GLen:112 LLen:112 GOff:0 OLen: 112 OOff:0 NeedComms:False 
I0603 04:24:33.767225   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 69, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_3x3_reduce(73) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
I0603 04:24:33.767235   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 70, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
Rank:0: Finalize:ComputeOp: inception_4b/3x3(74) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
OFM 0: GLen:224 LLen:224 GOff:0 NeedComms:False
WT 0: GLen:25088 LLen:25088 GOff:0 OLen: 25088 OOff:0 NeedComms:False 
WT 1: GLen:224 LLen:224 GOff:0 OLen: 224 OOff:0 NeedComms:False 
I0603 04:24:33.767247   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 71, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
Rank:0: Finalize:ComputeOp: inception_4b/relu_3x3(75) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:224 LLen:224 GOff:0 NeedComms:False
OFM 0: GLen:224 LLen:224 GOff:0 NeedComms:False
I0603 04:24:33.767257   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 72, bottom_id 0, calculated bottom_size 7340032, real bottom_size 7340032
Rank:0: Finalize:ComputeOp: inception_4b/5x5_reduce(76) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:24 LLen:24 GOff:0 OLen: 24 OOff:0 NeedComms:False 
I0603 04:24:33.767271   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 73, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_5x5_reduce(77) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
I0603 04:24:33.767282   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 74, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4b/5x5(78) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:1536 LLen:1536 GOff:0 OLen: 1536 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767293   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 75, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4b/relu_5x5(79) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767304   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 76, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4b/pool(80) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767313   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 77, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/pool_proj(81) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767325   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 78, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_pool_proj(82) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767335   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 79, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4b/output(84) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
IFM 1: GLen:224 LLen:224 GOff:0 NeedComms:False
IFM 2: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767349   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
I0603 04:24:33.767354   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 1, calculated bottom_size 7340032, real bottom_size 7340032
I0603 04:24:33.767366   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 2, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:24:33.767371   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4b/output_inception_4b/output_0_split(85) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 1: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 2: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 3: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767385   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 81, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/1x1(86) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:65536 LLen:65536 GOff:0 OLen: 65536 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.767396   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 82, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_1x1(87) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.767407   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 83, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4c/3x3_reduce(88) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:65536 LLen:65536 GOff:0 OLen: 65536 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.767421   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 84, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_3x3_reduce(89) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.767431   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 85, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4c/3x3(90) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:256 LLen:256 GOff:0 OLen: 256 OOff:0 NeedComms:False 
I0603 04:24:33.767442   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 86, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4c/relu_3x3(91) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:24:33.767453   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 87, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_4c/5x5_reduce(92) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:24 LLen:24 GOff:0 OLen: 24 OOff:0 NeedComms:False 
I0603 04:24:33.767465   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 88, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_5x5_reduce(93) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
I0603 04:24:33.767477   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 89, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4c/5x5(94) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:1536 LLen:1536 GOff:0 OLen: 1536 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767488   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 90, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4c/relu_5x5(95) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767501   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 91, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4c/pool(96) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767511   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 92, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/pool_proj(97) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767524   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 93, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_pool_proj(98) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767535   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 94, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4c/output(100) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 1: GLen:256 LLen:256 GOff:0 NeedComms:False
IFM 2: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767549   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
I0603 04:24:33.767552   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 1, calculated bottom_size 8388608, real bottom_size 8388608
I0603 04:24:33.767557   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 2, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:24:33.767562   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4c/output_inception_4c/output_0_split(101) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 1: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 2: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 3: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767575   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 96, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/1x1(102) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
WT 0: GLen:57344 LLen:57344 GOff:0 OLen: 57344 OOff:0 NeedComms:False 
WT 1: GLen:112 LLen:112 GOff:0 OLen: 112 OOff:0 NeedComms:False 
I0603 04:24:33.767587   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 97, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_1x1(103) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
I0603 04:24:33.767598   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 98, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
Rank:0: Finalize:ComputeOp: inception_4d/3x3_reduce(104) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
WT 0: GLen:73728 LLen:73728 GOff:0 OLen: 73728 OOff:0 NeedComms:False 
WT 1: GLen:144 LLen:144 GOff:0 OLen: 144 OOff:0 NeedComms:False 
I0603 04:24:33.767611   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 99, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_3x3_reduce(105) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
OFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
I0603 04:24:33.767629   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 100, bottom_id 0, calculated bottom_size 4718592, real bottom_size 4718592
Rank:0: Finalize:ComputeOp: inception_4d/3x3(106) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
OFM 0: GLen:288 LLen:288 GOff:0 NeedComms:False
WT 0: GLen:41472 LLen:41472 GOff:0 OLen: 41472 OOff:0 NeedComms:False 
WT 1: GLen:288 LLen:288 GOff:0 OLen: 288 OOff:0 NeedComms:False 
I0603 04:24:33.767642   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 101, bottom_id 0, calculated bottom_size 4718592, real bottom_size 4718592
Rank:0: Finalize:ComputeOp: inception_4d/relu_3x3(107) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:288 LLen:288 GOff:0 NeedComms:False
OFM 0: GLen:288 LLen:288 GOff:0 NeedComms:False
I0603 04:24:33.767652   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 102, bottom_id 0, calculated bottom_size 9437184, real bottom_size 9437184
Rank:0: Finalize:ComputeOp: inception_4d/5x5_reduce(108) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:16384 LLen:16384 GOff:0 OLen: 16384 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:24:33.767664   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 103, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_5x5_reduce(109) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:24:33.767675   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 104, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4d/5x5(110) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:2048 LLen:2048 GOff:0 OLen: 2048 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767688   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 105, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4d/relu_5x5(111) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767699   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 106, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4d/pool(112) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:24:33.767709   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 107, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/pool_proj(113) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:24:33.767721   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 108, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_pool_proj(114) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:24:33.767732   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 109, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4d/output(116) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
IFM 1: GLen:288 LLen:288 GOff:0 NeedComms:False
IFM 2: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:24:33.767745   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
I0603 04:24:33.767750   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 1, calculated bottom_size 9437184, real bottom_size 9437184
I0603 04:24:33.767755   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 2, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:24:33.767760   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4d/output_inception_4d/output_0_split(117) - 1 in, 5 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 1: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 2: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 3: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 4: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:24:33.767773   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 111, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: loss2/ave_pool(118) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:24:33.767783   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 112, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: loss2/conv(119) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:67584 LLen:67584 GOff:0 OLen: 67584 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.767796   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 113, bottom_id 0, calculated bottom_size 1689600, real bottom_size 1689600
Rank:0: Finalize:ComputeOp: loss2/relu_conv(120) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.767805   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 114, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss2/fc(121) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
WT 0: GLen:3276800 LLen:3276800 GOff:0 OLen: 3276800 OOff:0 NeedComms:False 
WT 1: GLen:1024 LLen:1024 GOff:0 OLen: 1024 OOff:0 NeedComms:False 
I0603 04:24:33.772637   822 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 115, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss2/relu_fc(122) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.772655   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 116, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss2/drop_fc(123) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.772665   822 net.cpp:470] InitNet: check bottom sizes for layer Dropout, layer_id 117, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss2/classifier(124) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:3 LLen:3 GOff:0 OLen: 3 OOff:0 NeedComms:False 
I0603 04:24:33.772676   822 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 118, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss2/loss(125) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:24:33.772686   822 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 119, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:24:33.772702   822 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 119, bottom_id 1, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: inception_4e/1x1(126) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
WT 0: GLen:135168 LLen:135168 GOff:0 OLen: 135168 OOff:0 NeedComms:False 
WT 1: GLen:256 LLen:256 GOff:0 OLen: 256 OOff:0 NeedComms:False 
I0603 04:24:33.772714   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 120, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_1x1(127) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:24:33.772725   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 121, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_4e/3x3_reduce(128) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
WT 0: GLen:84480 LLen:84480 GOff:0 OLen: 84480 OOff:0 NeedComms:False 
WT 1: GLen:160 LLen:160 GOff:0 OLen: 160 OOff:0 NeedComms:False 
I0603 04:24:33.772737   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 122, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_3x3_reduce(129) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
I0603 04:24:33.772747   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 123, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
Rank:0: Finalize:ComputeOp: inception_4e/3x3(130) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
WT 0: GLen:51200 LLen:51200 GOff:0 OLen: 51200 OOff:0 NeedComms:False 
WT 1: GLen:320 LLen:320 GOff:0 OLen: 320 OOff:0 NeedComms:False 
I0603 04:24:33.772760   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 124, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
Rank:0: Finalize:ComputeOp: inception_4e/relu_3x3(131) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
I0603 04:24:33.772770   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 125, bottom_id 0, calculated bottom_size 10485760, real bottom_size 10485760
Rank:0: Finalize:ComputeOp: inception_4e/5x5_reduce(132) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:16896 LLen:16896 GOff:0 OLen: 16896 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:24:33.772783   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 126, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_5x5_reduce(133) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:24:33.772794   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 127, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4e/5x5(134) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:4096 LLen:4096 GOff:0 OLen: 4096 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.772805   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 128, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4e/relu_5x5(135) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.772816   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 129, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4e/pool(136) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:24:33.772826   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 130, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/pool_proj(137) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:67584 LLen:67584 GOff:0 OLen: 67584 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.772840   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 131, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_pool_proj(138) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.772850   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 132, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4e/output(140) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
IFM 1: GLen:320 LLen:320 GOff:0 NeedComms:False
IFM 2: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 3: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.778445   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
I0603 04:24:33.778452   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 1, calculated bottom_size 10485760, real bottom_size 10485760
I0603 04:24:33.778457   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 2, calculated bottom_size 4194304, real bottom_size 4194304
I0603 04:24:33.778462   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 3, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: pool4/3x3_s2(141) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.778473   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 134, bottom_id 0, calculated bottom_size 27262976, real bottom_size 27262976
Rank:0: Finalize:ComputeOp: pool4/3x3_s2_pool4/3x3_s2_0_split(142) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 1: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 2: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 3: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.778486   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 135, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/1x1(143) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
WT 0: GLen:212992 LLen:212992 GOff:0 OLen: 212992 OOff:0 NeedComms:False 
WT 1: GLen:256 LLen:256 GOff:0 OLen: 256 OOff:0 NeedComms:False 
I0603 04:24:33.778498   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 136, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_1x1(144) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:24:33.778508   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 137, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_5a/3x3_reduce(145) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
WT 0: GLen:133120 LLen:133120 GOff:0 OLen: 133120 OOff:0 NeedComms:False 
WT 1: GLen:160 LLen:160 GOff:0 OLen: 160 OOff:0 NeedComms:False 
I0603 04:24:33.778520   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 138, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_3x3_reduce(146) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
I0603 04:24:33.778530   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 139, bottom_id 0, calculated bottom_size 1310720, real bottom_size 1310720
Rank:0: Finalize:ComputeOp: inception_5a/3x3(147) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
WT 0: GLen:51200 LLen:51200 GOff:0 OLen: 51200 OOff:0 NeedComms:False 
WT 1: GLen:320 LLen:320 GOff:0 OLen: 320 OOff:0 NeedComms:False 
I0603 04:24:33.778555   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 140, bottom_id 0, calculated bottom_size 1310720, real bottom_size 1310720
Rank:0: Finalize:ComputeOp: inception_5a/relu_3x3(148) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
I0603 04:24:33.778566   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 141, bottom_id 0, calculated bottom_size 2621440, real bottom_size 2621440
Rank:0: Finalize:ComputeOp: inception_5a/5x5_reduce(149) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:26624 LLen:26624 GOff:0 OLen: 26624 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:24:33.778578   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 142, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_5x5_reduce(150) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:24:33.778589   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 143, bottom_id 0, calculated bottom_size 262144, real bottom_size 262144
Rank:0: Finalize:ComputeOp: inception_5a/5x5(151) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:4096 LLen:4096 GOff:0 OLen: 4096 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.778601   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 144, bottom_id 0, calculated bottom_size 262144, real bottom_size 262144
Rank:0: Finalize:ComputeOp: inception_5a/relu_5x5(152) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.778612   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 145, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5a/pool(153) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.778621   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 146, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/pool_proj(154) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:106496 LLen:106496 GOff:0 OLen: 106496 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.778633   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 147, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_pool_proj(155) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.778645   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 148, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5a/output(157) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
IFM 1: GLen:320 LLen:320 GOff:0 NeedComms:False
IFM 2: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 3: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.778656   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:24:33.778661   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 1, calculated bottom_size 2621440, real bottom_size 2621440
I0603 04:24:33.783334   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 2, calculated bottom_size 1048576, real bottom_size 1048576
I0603 04:24:33.783344   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 3, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5a/output_inception_5a/output_0_split(158) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 1: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 2: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 3: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.783360   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 150, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/1x1(159) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
WT 0: GLen:319488 LLen:319488 GOff:0 OLen: 319488 OOff:0 NeedComms:False 
WT 1: GLen:384 LLen:384 GOff:0 OLen: 384 OOff:0 NeedComms:False 
I0603 04:24:33.783372   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 151, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_1x1(160) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
I0603 04:24:33.783383   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 152, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_5b/3x3_reduce(161) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:159744 LLen:159744 GOff:0 OLen: 159744 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:24:33.783394   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 153, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_3x3_reduce(162) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:24:33.783404   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 154, bottom_id 0, calculated bottom_size 1572864, real bottom_size 1572864
Rank:0: Finalize:ComputeOp: inception_5b/3x3(163) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
WT 0: GLen:73728 LLen:73728 GOff:0 OLen: 73728 OOff:0 NeedComms:False 
WT 1: GLen:384 LLen:384 GOff:0 OLen: 384 OOff:0 NeedComms:False 
I0603 04:24:33.783416   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 155, bottom_id 0, calculated bottom_size 1572864, real bottom_size 1572864
Rank:0: Finalize:ComputeOp: inception_5b/relu_3x3(164) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
I0603 04:24:33.783427   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 156, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_5b/5x5_reduce(165) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
WT 0: GLen:39936 LLen:39936 GOff:0 OLen: 39936 OOff:0 NeedComms:False 
WT 1: GLen:48 LLen:48 GOff:0 OLen: 48 OOff:0 NeedComms:False 
I0603 04:24:33.783437   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 157, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_5x5_reduce(166) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
I0603 04:24:33.783448   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 158, bottom_id 0, calculated bottom_size 393216, real bottom_size 393216
Rank:0: Finalize:ComputeOp: inception_5b/5x5(167) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:6144 LLen:6144 GOff:0 OLen: 6144 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.783462   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 159, bottom_id 0, calculated bottom_size 393216, real bottom_size 393216
Rank:0: Finalize:ComputeOp: inception_5b/relu_5x5(168) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.783471   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 160, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5b/pool(169) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:24:33.783493   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 161, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/pool_proj(170) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:106496 LLen:106496 GOff:0 OLen: 106496 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:24:33.783505   822 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 162, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_pool_proj(171) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:24:33.783516   822 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 163, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5b/output(173) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
IFM 1: GLen:384 LLen:384 GOff:0 NeedComms:False
IFM 2: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 3: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.783529   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
I0603 04:24:33.783535   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 1, calculated bottom_size 3145728, real bottom_size 3145728
I0603 04:24:33.783540   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 2, calculated bottom_size 1048576, real bottom_size 1048576
I0603 04:24:33.783543   822 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 3, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: pool5/7x7_s1(174) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.783553   822 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 165, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: pool5/drop_7x7_s1(175) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:24:33.788637   822 net.cpp:470] InitNet: check bottom sizes for layer Dropout, layer_id 166, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: loss3/classifier(176) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:3 LLen:3 GOff:0 OLen: 3 OOff:0 NeedComms:False 
I0603 04:24:33.788655   822 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 167, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: loss3/classifier_loss3/classifier_0_split(177) - 1 in, 2 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 1: GLen:3 LLen:3 GOff:0 NeedComms:False
I0603 04:24:33.788666   822 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 168, bottom_id 0, calculated bottom_size 384, real bottom_size 384
Rank:0: Finalize:ComputeOp: loss3/loss(178) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:24:33.788676   822 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 169, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:24:33.788681   822 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 169, bottom_id 1, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: accuracy(179) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:24:33.788691   822 net.cpp:470] InitNet: check bottom sizes for layer Accuracy, layer_id 170, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:24:33.788696   822 net.cpp:470] InitNet: check bottom sizes for layer Accuracy, layer_id 170, bottom_id 1, calculated bottom_size 128, real bottom_size 128
I0603 04:24:33.788700   822 net.cpp:500] Network initialization done.
I0603 04:24:33.789665   822 solver.cpp:122] Solver scaffolding done.
I0603 04:24:33.789942   822 caffe.cpp:329] Starting Optimization
I0603 04:24:33.789949   822 solver.cpp:495] Solving Model4.256
I0603 04:24:33.789953   822 solver.cpp:496] Learning Rate Policy: poly
I0603 04:24:38.500432   822 solver.cpp:316] Iteration 0, loss = 3.10825
I0603 04:24:38.500485   822 solver.cpp:332]     Train net output #0: accuracy = 0.28125
I0603 04:24:38.500499   822 solver.cpp:332]     Train net output #1: loss = 1.28882 (* 1 = 1.28882 loss)
I0603 04:24:38.500506   822 solver.cpp:332]     Train net output #2: loss1/loss = 4.33379 (* 0.3 = 1.30014 loss)
I0603 04:24:38.500512   822 solver.cpp:332]     Train net output #3: loss2/loss = 1.731 (* 0.3 = 0.5193 loss)
I0603 04:24:38.500524   822 sgd_solver.cpp:176] Iteration 0, lr = 0.01
I0603 04:24:46.222429   822 solver.cpp:316] Iteration 2, loss = 9.3
I0603 04:24:46.222481   822 solver.cpp:332]     Train net output #0: accuracy = 0.28125
I0603 04:24:46.222494   822 solver.cpp:332]     Train net output #1: loss = 4.5939 (* 1 = 4.5939 loss)
I0603 04:24:46.222501   822 solver.cpp:332]     Train net output #2: loss1/loss = 14.2663 (* 0.3 = 4.2799 loss)
I0603 04:24:46.222508   822 solver.cpp:332]     Train net output #3: loss2/loss = 1.42067 (* 0.3 = 0.426202 loss)
I0603 04:24:46.222519   822 sgd_solver.cpp:176] Iteration 2, lr = 0.00998958
I0603 04:24:53.890450   822 solver.cpp:316] Iteration 4, loss = 3.44099
I0603 04:24:53.890506   822 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:24:53.890524   822 solver.cpp:332]     Train net output #1: loss = 2.36572 (* 1 = 2.36572 loss)
I0603 04:24:53.890535   822 solver.cpp:332]     Train net output #2: loss1/loss = 2.35763 (* 0.3 = 0.707288 loss)
I0603 04:24:53.890544   822 solver.cpp:332]     Train net output #3: loss2/loss = 1.22662 (* 0.3 = 0.367985 loss)
I0603 04:24:53.890560   822 sgd_solver.cpp:176] Iteration 4, lr = 0.00997914
I0603 04:25:01.592429   822 solver.cpp:316] Iteration 6, loss = 2.52209
I0603 04:25:01.592488   822 solver.cpp:332]     Train net output #0: accuracy = 0.15625
I0603 04:25:01.592505   822 solver.cpp:332]     Train net output #1: loss = 1.71262 (* 1 = 1.71262 loss)
I0603 04:25:01.592516   822 solver.cpp:332]     Train net output #2: loss1/loss = 1.45253 (* 0.3 = 0.435758 loss)
I0603 04:25:01.592527   822 solver.cpp:332]     Train net output #3: loss2/loss = 1.24571 (* 0.3 = 0.373712 loss)
I0603 04:25:01.592542   822 sgd_solver.cpp:176] Iteration 6, lr = 0.0099687
I0603 04:25:09.253783   822 solver.cpp:316] Iteration 8, loss = 1.98817
I0603 04:25:09.253906   822 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:25:09.253926   822 solver.cpp:332]     Train net output #1: loss = 1.28692 (* 1 = 1.28692 loss)
I0603 04:25:09.253935   822 solver.cpp:332]     Train net output #2: loss1/loss = 1.1542 (* 0.3 = 0.34626 loss)
I0603 04:25:09.253945   822 solver.cpp:332]     Train net output #3: loss2/loss = 1.18329 (* 0.3 = 0.354987 loss)
I0603 04:25:09.253960   822 sgd_solver.cpp:176] Iteration 8, lr = 0.00995825
I0603 04:25:13.086175   822 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_10.caffemodel
I0603 04:25:13.254429   822 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_10.solverstate
I0603 04:25:13.325070   822 solver.cpp:519] Optimization stopped early.
I0603 04:25:13.325103   822 caffe.cpp:332] Optimization Done.
I0603 04:26:21.918258   861 caffe.cpp:279] Use CPU.
I0603 04:26:21.918767   861 solver.cpp:108] Initializing solver from parameters: 
base_lr: 0.01
display: 2
max_iter: 960
lr_policy: "poly"
power: 0.5
momentum: 0.9
weight_decay: 0.0002
snapshot: 32
snapshot_prefix: "/workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot"
solver_mode: CPU
net: "/workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
regularization_type: "L2"
clip_gradients: -1
type: "SGD"
engine: "MKL2017"
I0603 04:26:21.918781   861 solver.cpp:157] Creating training net from net file: /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/train_val.prototxt
I0603 04:26:21.926357   861 cpu_info.cpp:452] Processor speed [MHz]: 2300
I0603 04:26:21.926378   861 cpu_info.cpp:455] Total number of sockets: 1
I0603 04:26:21.926380   861 cpu_info.cpp:458] Total number of CPU cores: 2
I0603 04:26:21.926383   861 cpu_info.cpp:461] Total number of processors: 4
I0603 04:26:21.926385   861 cpu_info.cpp:464] GPU is used: no
I0603 04:26:21.926388   861 cpu_info.cpp:467] OpenMP environmental variables are specified: no
I0603 04:26:21.926390   861 cpu_info.cpp:470] OpenMP thread bind allowed: yes
I0603 04:26:21.926393   861 cpu_info.cpp:473] Number of OpenMP threads: 2
I0603 04:26:21.926694   861 net.cpp:790] The NetState phase (0) differed from the phase (1) specified by a rule in layer DataColor256
I0603 04:26:21.926738   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/ave_pool
I0603 04:26:21.926743   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/conv
I0603 04:26:21.926746   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/relu_conv
I0603 04:26:21.926750   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/fc
I0603 04:26:21.926754   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/relu_fc
I0603 04:26:21.926758   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/drop_fc
I0603 04:26:21.926760   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/classifier
I0603 04:26:21.926764   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss1/loss
I0603 04:26:21.926769   861 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss1/top-1
I0603 04:26:21.926770   861 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss1/top-5
I0603 04:26:21.926795   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/ave_pool
I0603 04:26:21.926798   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/conv
I0603 04:26:21.926802   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/relu_conv
I0603 04:26:21.926805   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/fc
I0603 04:26:21.926810   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/relu_fc
I0603 04:26:21.926812   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/drop_fc
I0603 04:26:21.926815   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/classifier
I0603 04:26:21.926820   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss2/loss
I0603 04:26:21.926823   861 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss2/top-1
I0603 04:26:21.926826   861 net.cpp:826] The NetState did not contain stage 'val' specified by a rule in layer loss2/top-5
I0603 04:26:21.926851   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer loss3/loss
I0603 04:26:21.926859   861 net.cpp:790] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I0603 04:26:21.926880   861 net.cpp:826] The NetState did not contain stage 'deploy' specified by a rule in layer softmax
I0603 04:26:21.928737   861 net.cpp:156] Initializing net from parameters: 
I0603 04:26:21.928755   861 net.cpp:157] 
name: "Model4.256"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "DataColor256"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    mean_file: "/workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/mean.binaryproto"
  }
  data_param {
    source: "/workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/train.txt_LMDB"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "label_DataColor256_1_split"
  type: "Split"
  bottom: "label"
  top: "label_DataColor256_1_split_0"
  top: "label_DataColor256_1_split_1"
  top: "label_DataColor256_1_split_2"
  top: "label_DataColor256_1_split_3"
}
layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "data"
  top: "conv1/7x7_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu_7x7"
  type: "ReLU"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/7x7_s2"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1/norm1"
  type: "LRN"
  bottom: "pool1/3x3_s2"
  top: "pool1/norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2/3x3_reduce"
  type: "Convolution"
  bottom: "pool1/norm1"
  top: "conv2/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu_3x3_reduce"
  type: "ReLU"
  bottom: "conv2/3x3_reduce"
  top: "conv2/3x3_reduce"
}
layer {
  name: "conv2/3x3"
  type: "Convolution"
  bottom: "conv2/3x3_reduce"
  top: "conv2/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu_3x3"
  type: "ReLU"
  bottom: "conv2/3x3"
  top: "conv2/3x3"
}
layer {
  name: "conv2/norm2"
  type: "LRN"
  bottom: "conv2/3x3"
  top: "conv2/norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2/3x3_s2"
  type: "Pooling"
  bottom: "conv2/norm2"
  top: "pool2/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2/3x3_s2_pool2/3x3_s2_0_split"
  type: "Split"
  bottom: "pool2/3x3_s2"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_0"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_1"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_2"
  top: "pool2/3x3_s2_pool2/3x3_s2_0_split_3"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_0"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_1"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/5x5_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_2"
  top: "inception_3a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_3a/5x5_reduce"
  top: "inception_3a/5x5_reduce"
}
layer {
  name: "inception_3a/5x5"
  type: "Convolution"
  bottom: "inception_3a/5x5_reduce"
  top: "inception_3a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_5x5"
  type: "ReLU"
  bottom: "inception_3a/5x5"
  top: "inception_3a/5x5"
}
layer {
  name: "inception_3a/pool"
  type: "Pooling"
  bottom: "pool2/3x3_s2_pool2/3x3_s2_0_split_3"
  top: "inception_3a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3a/pool_proj"
  type: "Convolution"
  bottom: "inception_3a/pool"
  top: "inception_3a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/pool_proj"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  bottom: "inception_3a/5x5"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/output"
}
layer {
  name: "inception_3a/output_inception_3a/output_0_split"
  type: "Split"
  bottom: "inception_3a/output"
  top: "inception_3a/output_inception_3a/output_0_split_0"
  top: "inception_3a/output_inception_3a/output_0_split_1"
  top: "inception_3a/output_inception_3a/output_0_split_2"
  top: "inception_3a/output_inception_3a/output_0_split_3"
}
layer {
  name: "inception_3b/1x1"
  type: "Convolution"
  bottom: "inception_3a/output_inception_3a/output_0_split_0"
  top: "inception_3b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_1x1"
  type: "ReLU"
  bottom: "inception_3b/1x1"
  top: "inception_3b/1x1"
}
layer {
  name: "inception_3b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3a/output_inception_3a/output_0_split_1"
  top: "inception_3b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3b/3x3_reduce"
  top: "inception_3b/3x3_reduce"
}
layer {
  name: "inception_3b/3x3"
  type: "Convolution"
  bottom: "inception_3b/3x3_reduce"
  top: "inception_3b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_3x3"
  type: "ReLU"
  bottom: "inception_3b/3x3"
  top: "inception_3b/3x3"
}
layer {
  name: "inception_3b/5x5_reduce"
  type: "Convolution"
  bottom: "inception_3a/output_inception_3a/output_0_split_2"
  top: "inception_3b/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_3b/5x5_reduce"
  top: "inception_3b/5x5_reduce"
}
layer {
  name: "inception_3b/5x5"
  type: "Convolution"
  bottom: "inception_3b/5x5_reduce"
  top: "inception_3b/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_5x5"
  type: "ReLU"
  bottom: "inception_3b/5x5"
  top: "inception_3b/5x5"
}
layer {
  name: "inception_3b/pool"
  type: "Pooling"
  bottom: "inception_3a/output_inception_3a/output_0_split_3"
  top: "inception_3b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3b/pool_proj"
  type: "Convolution"
  bottom: "inception_3b/pool"
  top: "inception_3b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3b/pool_proj"
  top: "inception_3b/pool_proj"
}
layer {
  name: "inception_3b/output"
  type: "Concat"
  bottom: "inception_3b/1x1"
  bottom: "inception_3b/3x3"
  bottom: "inception_3b/5x5"
  bottom: "inception_3b/pool_proj"
  top: "inception_3b/output"
}
layer {
  name: "pool3/3x3_s2"
  type: "Pooling"
  bottom: "inception_3b/output"
  top: "pool3/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool3/3x3_s2_pool3/3x3_s2_0_split"
  type: "Split"
  bottom: "pool3/3x3_s2"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_0"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_1"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_2"
  top: "pool3/3x3_s2_pool3/3x3_s2_0_split_3"
}
layer {
  name: "inception_4a/1x1"
  type: "Convolution"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_0"
  top: "inception_4a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_1x1"
  type: "ReLU"
  bottom: "inception_4a/1x1"
  top: "inception_4a/1x1"
}
layer {
  name: "inception_4a/3x3_reduce"
  type: "Convolution"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_1"
  top: "inception_4a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4a/3x3_reduce"
  top: "inception_4a/3x3_reduce"
}
layer {
  name: "inception_4a/3x3"
  type: "Convolution"
  bottom: "inception_4a/3x3_reduce"
  top: "inception_4a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 208
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_3x3"
  type: "ReLU"
  bottom: "inception_4a/3x3"
  top: "inception_4a/3x3"
}
layer {
  name: "inception_4a/5x5_reduce"
  type: "Convolution"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_2"
  top: "inception_4a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4a/5x5_reduce"
  top: "inception_4a/5x5_reduce"
}
layer {
  name: "inception_4a/5x5"
  type: "Convolution"
  bottom: "inception_4a/5x5_reduce"
  top: "inception_4a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_5x5"
  type: "ReLU"
  bottom: "inception_4a/5x5"
  top: "inception_4a/5x5"
}
layer {
  name: "inception_4a/pool"
  type: "Pooling"
  bottom: "pool3/3x3_s2_pool3/3x3_s2_0_split_3"
  top: "inception_4a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4a/pool_proj"
  type: "Convolution"
  bottom: "inception_4a/pool"
  top: "inception_4a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4a/pool_proj"
  top: "inception_4a/pool_proj"
}
layer {
  name: "inception_4a/output"
  type: "Concat"
  bottom: "inception_4a/1x1"
  bottom: "inception_4a/3x3"
  bottom: "inception_4a/5x5"
  bottom: "inception_4a/pool_proj"
  top: "inception_4a/output"
}
layer {
  name: "inception_4a/output_inception_4a/output_0_split"
  type: "Split"
  bottom: "inception_4a/output"
  top: "inception_4a/output_inception_4a/output_0_split_0"
  top: "inception_4a/output_inception_4a/output_0_split_1"
  top: "inception_4a/output_inception_4a/output_0_split_2"
  top: "inception_4a/output_inception_4a/output_0_split_3"
  top: "inception_4a/output_inception_4a/output_0_split_4"
}
layer {
  name: "loss1/ave_pool"
  type: "Pooling"
  bottom: "inception_4a/output_inception_4a/output_0_split_0"
  top: "loss1/ave_pool"
  exclude {
    stage: "deploy"
  }
  pooling_param {
    pool: AVE
    kernel_size: 5
    stride: 3
  }
}
layer {
  name: "loss1/conv"
  type: "Convolution"
  bottom: "loss1/ave_pool"
  top: "loss1/conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss1/relu_conv"
  type: "ReLU"
  bottom: "loss1/conv"
  top: "loss1/conv"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss1/fc"
  type: "InnerProduct"
  bottom: "loss1/conv"
  top: "loss1/fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
      std: 0.02
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss1/relu_fc"
  type: "ReLU"
  bottom: "loss1/fc"
  top: "loss1/fc"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss1/drop_fc"
  type: "Dropout"
  bottom: "loss1/fc"
  top: "loss1/fc"
  exclude {
    stage: "deploy"
  }
  dropout_param {
    dropout_ratio: 0.7
  }
}
layer {
  name: "loss1/classifier"
  type: "InnerProduct"
  bottom: "loss1/fc"
  top: "loss1/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
      std: 0.0009765625
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss1/loss"
  type: "SoftmaxWithLoss"
  bottom: "loss1/classifier"
  bottom: "label_DataColor256_1_split_0"
  top: "loss1/loss"
  loss_weight: 0.3
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "inception_4b/1x1"
  type: "Convolution"
  bottom: "inception_4a/output_inception_4a/output_0_split_1"
  top: "inception_4b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_1x1"
  type: "ReLU"
  bottom: "inception_4b/1x1"
  top: "inception_4b/1x1"
}
layer {
  name: "inception_4b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4a/output_inception_4a/output_0_split_2"
  top: "inception_4b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4b/3x3_reduce"
  top: "inception_4b/3x3_reduce"
}
layer {
  name: "inception_4b/3x3"
  type: "Convolution"
  bottom: "inception_4b/3x3_reduce"
  top: "inception_4b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 224
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_3x3"
  type: "ReLU"
  bottom: "inception_4b/3x3"
  top: "inception_4b/3x3"
}
layer {
  name: "inception_4b/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4a/output_inception_4a/output_0_split_3"
  top: "inception_4b/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4b/5x5_reduce"
  top: "inception_4b/5x5_reduce"
}
layer {
  name: "inception_4b/5x5"
  type: "Convolution"
  bottom: "inception_4b/5x5_reduce"
  top: "inception_4b/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_5x5"
  type: "ReLU"
  bottom: "inception_4b/5x5"
  top: "inception_4b/5x5"
}
layer {
  name: "inception_4b/pool"
  type: "Pooling"
  bottom: "inception_4a/output_inception_4a/output_0_split_4"
  top: "inception_4b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4b/pool_proj"
  type: "Convolution"
  bottom: "inception_4b/pool"
  top: "inception_4b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4b/pool_proj"
  top: "inception_4b/pool_proj"
}
layer {
  name: "inception_4b/output"
  type: "Concat"
  bottom: "inception_4b/1x1"
  bottom: "inception_4b/3x3"
  bottom: "inception_4b/5x5"
  bottom: "inception_4b/pool_proj"
  top: "inception_4b/output"
}
layer {
  name: "inception_4b/output_inception_4b/output_0_split"
  type: "Split"
  bottom: "inception_4b/output"
  top: "inception_4b/output_inception_4b/output_0_split_0"
  top: "inception_4b/output_inception_4b/output_0_split_1"
  top: "inception_4b/output_inception_4b/output_0_split_2"
  top: "inception_4b/output_inception_4b/output_0_split_3"
}
layer {
  name: "inception_4c/1x1"
  type: "Convolution"
  bottom: "inception_4b/output_inception_4b/output_0_split_0"
  top: "inception_4c/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_1x1"
  type: "ReLU"
  bottom: "inception_4c/1x1"
  top: "inception_4c/1x1"
}
layer {
  name: "inception_4c/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4b/output_inception_4b/output_0_split_1"
  top: "inception_4c/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4c/3x3_reduce"
  top: "inception_4c/3x3_reduce"
}
layer {
  name: "inception_4c/3x3"
  type: "Convolution"
  bottom: "inception_4c/3x3_reduce"
  top: "inception_4c/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_3x3"
  type: "ReLU"
  bottom: "inception_4c/3x3"
  top: "inception_4c/3x3"
}
layer {
  name: "inception_4c/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4b/output_inception_4b/output_0_split_2"
  top: "inception_4c/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4c/5x5_reduce"
  top: "inception_4c/5x5_reduce"
}
layer {
  name: "inception_4c/5x5"
  type: "Convolution"
  bottom: "inception_4c/5x5_reduce"
  top: "inception_4c/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_5x5"
  type: "ReLU"
  bottom: "inception_4c/5x5"
  top: "inception_4c/5x5"
}
layer {
  name: "inception_4c/pool"
  type: "Pooling"
  bottom: "inception_4b/output_inception_4b/output_0_split_3"
  top: "inception_4c/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4c/pool_proj"
  type: "Convolution"
  bottom: "inception_4c/pool"
  top: "inception_4c/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4c/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4c/pool_proj"
  top: "inception_4c/pool_proj"
}
layer {
  name: "inception_4c/output"
  type: "Concat"
  bottom: "inception_4c/1x1"
  bottom: "inception_4c/3x3"
  bottom: "inception_4c/5x5"
  bottom: "inception_4c/pool_proj"
  top: "inception_4c/output"
}
layer {
  name: "inception_4c/output_inception_4c/output_0_split"
  type: "Split"
  bottom: "inception_4c/output"
  top: "inception_4c/output_inception_4c/output_0_split_0"
  top: "inception_4c/output_inception_4c/output_0_split_1"
  top: "inception_4c/output_inception_4c/output_0_split_2"
  top: "inception_4c/output_inception_4c/output_0_split_3"
}
layer {
  name: "inception_4d/1x1"
  type: "Convolution"
  bottom: "inception_4c/output_inception_4c/output_0_split_0"
  top: "inception_4d/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_1x1"
  type: "ReLU"
  bottom: "inception_4d/1x1"
  top: "inception_4d/1x1"
}
layer {
  name: "inception_4d/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4c/output_inception_4c/output_0_split_1"
  top: "inception_4d/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4d/3x3_reduce"
  top: "inception_4d/3x3_reduce"
}
layer {
  name: "inception_4d/3x3"
  type: "Convolution"
  bottom: "inception_4d/3x3_reduce"
  top: "inception_4d/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 288
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_3x3"
  type: "ReLU"
  bottom: "inception_4d/3x3"
  top: "inception_4d/3x3"
}
layer {
  name: "inception_4d/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4c/output_inception_4c/output_0_split_2"
  top: "inception_4d/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4d/5x5_reduce"
  top: "inception_4d/5x5_reduce"
}
layer {
  name: "inception_4d/5x5"
  type: "Convolution"
  bottom: "inception_4d/5x5_reduce"
  top: "inception_4d/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_5x5"
  type: "ReLU"
  bottom: "inception_4d/5x5"
  top: "inception_4d/5x5"
}
layer {
  name: "inception_4d/pool"
  type: "Pooling"
  bottom: "inception_4c/output_inception_4c/output_0_split_3"
  top: "inception_4d/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4d/pool_proj"
  type: "Convolution"
  bottom: "inception_4d/pool"
  top: "inception_4d/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4d/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4d/pool_proj"
  top: "inception_4d/pool_proj"
}
layer {
  name: "inception_4d/output"
  type: "Concat"
  bottom: "inception_4d/1x1"
  bottom: "inception_4d/3x3"
  bottom: "inception_4d/5x5"
  bottom: "inception_4d/pool_proj"
  top: "inception_4d/output"
}
layer {
  name: "inception_4d/output_inception_4d/output_0_split"
  type: "Split"
  bottom: "inception_4d/output"
  top: "inception_4d/output_inception_4d/output_0_split_0"
  top: "inception_4d/output_inception_4d/output_0_split_1"
  top: "inception_4d/output_inception_4d/output_0_split_2"
  top: "inception_4d/output_inception_4d/output_0_split_3"
  top: "inception_4d/output_inception_4d/output_0_split_4"
}
layer {
  name: "loss2/ave_pool"
  type: "Pooling"
  bottom: "inception_4d/output_inception_4d/output_0_split_0"
  top: "loss2/ave_pool"
  exclude {
    stage: "deploy"
  }
  pooling_param {
    pool: AVE
    kernel_size: 5
    stride: 3
  }
}
layer {
  name: "loss2/conv"
  type: "Convolution"
  bottom: "loss2/ave_pool"
  top: "loss2/conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss2/relu_conv"
  type: "ReLU"
  bottom: "loss2/conv"
  top: "loss2/conv"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss2/fc"
  type: "InnerProduct"
  bottom: "loss2/conv"
  top: "loss2/fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
      std: 0.02
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "loss2/relu_fc"
  type: "ReLU"
  bottom: "loss2/fc"
  top: "loss2/fc"
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "loss2/drop_fc"
  type: "Dropout"
  bottom: "loss2/fc"
  top: "loss2/fc"
  exclude {
    stage: "deploy"
  }
  dropout_param {
    dropout_ratio: 0.7
  }
}
layer {
  name: "loss2/classifier"
  type: "InnerProduct"
  bottom: "loss2/fc"
  top: "loss2/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  exclude {
    stage: "deploy"
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
      std: 0.0009765625
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss2/loss"
  type: "SoftmaxWithLoss"
  bottom: "loss2/classifier"
  bottom: "label_DataColor256_1_split_1"
  top: "loss2/loss"
  loss_weight: 0.3
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "inception_4e/1x1"
  type: "Convolution"
  bottom: "inception_4d/output_inception_4d/output_0_split_1"
  top: "inception_4e/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_1x1"
  type: "ReLU"
  bottom: "inception_4e/1x1"
  top: "inception_4e/1x1"
}
layer {
  name: "inception_4e/3x3_reduce"
  type: "Convolution"
  bottom: "inception_4d/output_inception_4d/output_0_split_2"
  top: "inception_4e/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4e/3x3_reduce"
  top: "inception_4e/3x3_reduce"
}
layer {
  name: "inception_4e/3x3"
  type: "Convolution"
  bottom: "inception_4e/3x3_reduce"
  top: "inception_4e/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_3x3"
  type: "ReLU"
  bottom: "inception_4e/3x3"
  top: "inception_4e/3x3"
}
layer {
  name: "inception_4e/5x5_reduce"
  type: "Convolution"
  bottom: "inception_4d/output_inception_4d/output_0_split_3"
  top: "inception_4e/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_4e/5x5_reduce"
  top: "inception_4e/5x5_reduce"
}
layer {
  name: "inception_4e/5x5"
  type: "Convolution"
  bottom: "inception_4e/5x5_reduce"
  top: "inception_4e/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_5x5"
  type: "ReLU"
  bottom: "inception_4e/5x5"
  top: "inception_4e/5x5"
}
layer {
  name: "inception_4e/pool"
  type: "Pooling"
  bottom: "inception_4d/output_inception_4d/output_0_split_4"
  top: "inception_4e/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4e/pool_proj"
  type: "Convolution"
  bottom: "inception_4e/pool"
  top: "inception_4e/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4e/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4e/pool_proj"
  top: "inception_4e/pool_proj"
}
layer {
  name: "inception_4e/output"
  type: "Concat"
  bottom: "inception_4e/1x1"
  bottom: "inception_4e/3x3"
  bottom: "inception_4e/5x5"
  bottom: "inception_4e/pool_proj"
  top: "inception_4e/output"
}
layer {
  name: "pool4/3x3_s2"
  type: "Pooling"
  bottom: "inception_4e/output"
  top: "pool4/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool4/3x3_s2_pool4/3x3_s2_0_split"
  type: "Split"
  bottom: "pool4/3x3_s2"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_0"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_1"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_2"
  top: "pool4/3x3_s2_pool4/3x3_s2_0_split_3"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_0"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_1x1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3_reduce"
  type: "Convolution"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_1"
  top: "inception_5a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_5a/3x3_reduce"
  top: "inception_5a/3x3_reduce"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "inception_5a/3x3_reduce"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_3x3"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/5x5_reduce"
  type: "Convolution"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_2"
  top: "inception_5a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_5a/5x5_reduce"
  top: "inception_5a/5x5_reduce"
}
layer {
  name: "inception_5a/5x5"
  type: "Convolution"
  bottom: "inception_5a/5x5_reduce"
  top: "inception_5a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_5x5"
  type: "ReLU"
  bottom: "inception_5a/5x5"
  top: "inception_5a/5x5"
}
layer {
  name: "inception_5a/pool"
  type: "Pooling"
  bottom: "pool4/3x3_s2_pool4/3x3_s2_0_split_3"
  top: "inception_5a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_5a/pool_proj"
  type: "Convolution"
  bottom: "inception_5a/pool"
  top: "inception_5a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_5a/pool_proj"
  top: "inception_5a/pool_proj"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  bottom: "inception_5a/5x5"
  bottom: "inception_5a/pool_proj"
  top: "inception_5a/output"
}
layer {
  name: "inception_5a/output_inception_5a/output_0_split"
  type: "Split"
  bottom: "inception_5a/output"
  top: "inception_5a/output_inception_5a/output_0_split_0"
  top: "inception_5a/output_inception_5a/output_0_split_1"
  top: "inception_5a/output_inception_5a/output_0_split_2"
  top: "inception_5a/output_inception_5a/output_0_split_3"
}
layer {
  name: "inception_5b/1x1"
  type: "Convolution"
  bottom: "inception_5a/output_inception_5a/output_0_split_0"
  top: "inception_5b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_1x1"
  type: "ReLU"
  bottom: "inception_5b/1x1"
  top: "inception_5b/1x1"
}
layer {
  name: "inception_5b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_5a/output_inception_5a/output_0_split_1"
  top: "inception_5b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_5b/3x3_reduce"
  top: "inception_5b/3x3_reduce"
}
layer {
  name: "inception_5b/3x3"
  type: "Convolution"
  bottom: "inception_5b/3x3_reduce"
  top: "inception_5b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_3x3"
  type: "ReLU"
  bottom: "inception_5b/3x3"
  top: "inception_5b/3x3"
}
layer {
  name: "inception_5b/5x5_reduce"
  type: "Convolution"
  bottom: "inception_5a/output_inception_5a/output_0_split_2"
  top: "inception_5b/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_5b/5x5_reduce"
  top: "inception_5b/5x5_reduce"
}
layer {
  name: "inception_5b/5x5"
  type: "Convolution"
  bottom: "inception_5b/5x5_reduce"
  top: "inception_5b/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_5x5"
  type: "ReLU"
  bottom: "inception_5b/5x5"
  top: "inception_5b/5x5"
}
layer {
  name: "inception_5b/pool"
  type: "Pooling"
  bottom: "inception_5a/output_inception_5a/output_0_split_3"
  top: "inception_5b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_5b/pool_proj"
  type: "Convolution"
  bottom: "inception_5b/pool"
  top: "inception_5b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_5b/pool_proj"
  top: "inception_5b/pool_proj"
}
layer {
  name: "inception_5b/output"
  type: "Concat"
  bottom: "inception_5b/1x1"
  bottom: "inception_5b/3x3"
  bottom: "inception_5b/5x5"
  bottom: "inception_5b/pool_proj"
  top: "inception_5b/output"
}
layer {
  name: "pool5/7x7_s1"
  type: "Pooling"
  bottom: "inception_5b/output"
  top: "pool5/7x7_s1"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "pool5/drop_7x7_s1"
  type: "Dropout"
  bottom: "pool5/7x7_s1"
  top: "pool5/7x7_s1"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "loss3/classifier"
  type: "InnerProduct"
  bottom: "pool5/7x7_s1"
  top: "loss3/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss3/classifier_loss3/classifier_0_split"
  type: "Split"
  bottom: "loss3/classifier"
  top: "loss3/classifier_loss3/classifier_0_split_0"
  top: "loss3/classifier_loss3/classifier_0_split_1"
}
layer {
  name: "loss3/loss"
  type: "SoftmaxWithLoss"
  bottom: "loss3/classifier_loss3/classifier_0_split_0"
  bottom: "label_DataColor256_1_split_2"
  top: "loss"
  loss_weight: 1
  exclude {
    stage: "deploy"
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss3/classifier_loss3/classifier_0_split_1"
  bottom: "label_DataColor256_1_split_3"
  top: "accuracy"
}
I0603 04:26:21.929666   861 layer_factory.hpp:114] Creating layer DataColor256
I0603 04:26:21.930107   861 net.cpp:201] Creating Layer DataColor256
I0603 04:26:21.930119   861 net.cpp:876] DataColor256 -> data
I0603 04:26:21.930137   861 net.cpp:876] DataColor256 -> label
W0603 04:26:21.930143   861 net.cpp:265] SetMinibatchSize 32
I0603 04:26:21.930361   861 data_transformer.cpp:63] Loading mean file from: /workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/mean.binaryproto
I0603 04:26:21.932385   863 db_lmdb.cpp:72] Opened lmdb /workspace/dlsdk/jobs/caffe/datasets/d2e5486e-416d-488e-a668-8eeacdf819b5/train.txt_LMDB
I0603 04:26:21.932593   861 data_layer.cpp:80] output data size: 32,3,256,256
I0603 04:26:21.954470   861 net.cpp:286] Setting up DataColor256
I0603 04:26:21.954520   861 net.cpp:293] Top shape: 32 3 256 256 (6291456)
I0603 04:26:21.954529   861 net.cpp:293] Top shape: 32 (32)
I0603 04:26:21.954532   861 net.cpp:301] Memory required for data: 25165952
I0603 04:26:21.954545   861 layer_factory.hpp:114] Creating layer label_DataColor256_1_split
I0603 04:26:21.954576   861 net.cpp:201] Creating Layer label_DataColor256_1_split
I0603 04:26:21.954582   861 net.cpp:902] label_DataColor256_1_split <- label
I0603 04:26:21.954594   861 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_0
I0603 04:26:21.954609   861 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_1
I0603 04:26:21.954618   861 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_2
I0603 04:26:21.954627   861 net.cpp:876] label_DataColor256_1_split -> label_DataColor256_1_split_3
I0603 04:26:21.955509   861 net.cpp:286] Setting up label_DataColor256_1_split
I0603 04:26:21.955528   861 net.cpp:293] Top shape: 32 (32)
I0603 04:26:21.955534   861 net.cpp:293] Top shape: 32 (32)
I0603 04:26:21.955540   861 net.cpp:293] Top shape: 32 (32)
I0603 04:26:21.955546   861 net.cpp:293] Top shape: 32 (32)
I0603 04:26:21.955551   861 net.cpp:301] Memory required for data: 25166464
I0603 04:26:21.955557   861 layer_factory.hpp:114] Creating layer conv1/7x7_s2
I0603 04:26:21.955592   861 net.cpp:201] Creating Layer conv1/7x7_s2
I0603 04:26:21.955600   861 net.cpp:902] conv1/7x7_s2 <- data
I0603 04:26:21.955610   861 net.cpp:876] conv1/7x7_s2 -> conv1/7x7_s2
I0603 04:26:21.977099   861 net.cpp:286] Setting up conv1/7x7_s2
I0603 04:26:21.977147   861 net.cpp:293] Top shape: 32 64 128 128 (33554432)
I0603 04:26:21.977154   861 net.cpp:301] Memory required for data: 159384192
I0603 04:26:21.977181   861 layer_factory.hpp:114] Creating layer conv1/relu_7x7
I0603 04:26:21.977212   861 net.cpp:201] Creating Layer conv1/relu_7x7
I0603 04:26:21.977219   861 net.cpp:902] conv1/relu_7x7 <- conv1/7x7_s2
I0603 04:26:21.977231   861 net.cpp:863] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)
I0603 04:26:21.977280   861 net.cpp:286] Setting up conv1/relu_7x7
I0603 04:26:21.977289   861 net.cpp:293] Top shape: 32 64 128 128 (33554432)
I0603 04:26:21.977295   861 net.cpp:301] Memory required for data: 293601920
I0603 04:26:21.977301   861 layer_factory.hpp:114] Creating layer pool1/3x3_s2
I0603 04:26:21.977319   861 net.cpp:201] Creating Layer pool1/3x3_s2
I0603 04:26:21.977324   861 net.cpp:902] pool1/3x3_s2 <- conv1/7x7_s2
I0603 04:26:21.977332   861 net.cpp:876] pool1/3x3_s2 -> pool1/3x3_s2
I0603 04:26:21.977358   861 net.cpp:286] Setting up pool1/3x3_s2
I0603 04:26:21.977366   861 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:26:21.977371   861 net.cpp:301] Memory required for data: 327156352
I0603 04:26:21.977376   861 layer_factory.hpp:114] Creating layer pool1/norm1
I0603 04:26:21.977390   861 net.cpp:201] Creating Layer pool1/norm1
I0603 04:26:21.977396   861 net.cpp:902] pool1/norm1 <- pool1/3x3_s2
I0603 04:26:21.977402   861 net.cpp:876] pool1/norm1 -> pool1/norm1
I0603 04:26:21.977422   861 net.cpp:286] Setting up pool1/norm1
I0603 04:26:21.977432   861 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:26:21.977435   861 net.cpp:301] Memory required for data: 360710784
I0603 04:26:21.977442   861 layer_factory.hpp:114] Creating layer conv2/3x3_reduce
I0603 04:26:21.977500   861 net.cpp:201] Creating Layer conv2/3x3_reduce
I0603 04:26:21.977506   861 net.cpp:902] conv2/3x3_reduce <- pool1/norm1
I0603 04:26:21.977515   861 net.cpp:876] conv2/3x3_reduce -> conv2/3x3_reduce
I0603 04:26:21.979820   861 net.cpp:286] Setting up conv2/3x3_reduce
I0603 04:26:21.979843   861 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:26:21.979849   861 net.cpp:301] Memory required for data: 394265216
I0603 04:26:21.979864   861 layer_factory.hpp:114] Creating layer conv2/relu_3x3_reduce
I0603 04:26:21.979882   861 net.cpp:201] Creating Layer conv2/relu_3x3_reduce
I0603 04:26:21.979889   861 net.cpp:902] conv2/relu_3x3_reduce <- conv2/3x3_reduce
I0603 04:26:21.979897   861 net.cpp:863] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)
I0603 04:26:21.979919   861 net.cpp:286] Setting up conv2/relu_3x3_reduce
I0603 04:26:21.979928   861 net.cpp:293] Top shape: 32 64 64 64 (8388608)
I0603 04:26:21.979933   861 net.cpp:301] Memory required for data: 427819648
I0603 04:26:21.979938   861 layer_factory.hpp:114] Creating layer conv2/3x3
I0603 04:26:21.979961   861 net.cpp:201] Creating Layer conv2/3x3
I0603 04:26:21.979967   861 net.cpp:902] conv2/3x3 <- conv2/3x3_reduce
I0603 04:26:21.979975   861 net.cpp:876] conv2/3x3 -> conv2/3x3
I0603 04:26:21.988214   861 net.cpp:286] Setting up conv2/3x3
I0603 04:26:21.988251   861 net.cpp:293] Top shape: 32 192 64 64 (25165824)
I0603 04:26:21.988257   861 net.cpp:301] Memory required for data: 528482944
I0603 04:26:21.988279   861 layer_factory.hpp:114] Creating layer conv2/relu_3x3
I0603 04:26:21.988301   861 net.cpp:201] Creating Layer conv2/relu_3x3
I0603 04:26:21.988307   861 net.cpp:902] conv2/relu_3x3 <- conv2/3x3
I0603 04:26:21.988317   861 net.cpp:863] conv2/relu_3x3 -> conv2/3x3 (in-place)
I0603 04:26:21.988343   861 net.cpp:286] Setting up conv2/relu_3x3
I0603 04:26:21.988350   861 net.cpp:293] Top shape: 32 192 64 64 (25165824)
I0603 04:26:21.988355   861 net.cpp:301] Memory required for data: 629146240
I0603 04:26:21.988361   861 layer_factory.hpp:114] Creating layer conv2/norm2
I0603 04:26:21.988374   861 net.cpp:201] Creating Layer conv2/norm2
I0603 04:26:21.988380   861 net.cpp:902] conv2/norm2 <- conv2/3x3
I0603 04:26:21.988387   861 net.cpp:876] conv2/norm2 -> conv2/norm2
I0603 04:26:21.988406   861 net.cpp:286] Setting up conv2/norm2
I0603 04:26:21.988415   861 net.cpp:293] Top shape: 32 192 64 64 (25165824)
I0603 04:26:21.988420   861 net.cpp:301] Memory required for data: 729809536
I0603 04:26:21.988425   861 layer_factory.hpp:114] Creating layer pool2/3x3_s2
I0603 04:26:21.988436   861 net.cpp:201] Creating Layer pool2/3x3_s2
I0603 04:26:21.988441   861 net.cpp:902] pool2/3x3_s2 <- conv2/norm2
I0603 04:26:21.988448   861 net.cpp:876] pool2/3x3_s2 -> pool2/3x3_s2
I0603 04:26:21.988471   861 net.cpp:286] Setting up pool2/3x3_s2
I0603 04:26:21.988478   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:21.988482   861 net.cpp:301] Memory required for data: 754975360
I0603 04:26:21.988488   861 layer_factory.hpp:114] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0603 04:26:21.988499   861 net.cpp:201] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0603 04:26:21.988504   861 net.cpp:902] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I0603 04:26:21.988512   861 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0603 04:26:21.988520   861 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0603 04:26:21.988529   861 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0603 04:26:21.988538   861 net.cpp:876] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0603 04:26:21.988562   861 net.cpp:286] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I0603 04:26:21.988570   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:21.988577   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:21.988584   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:21.988616   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:21.988622   861 net.cpp:301] Memory required for data: 855638656
I0603 04:26:21.988627   861 layer_factory.hpp:114] Creating layer inception_3a/1x1
I0603 04:26:21.988649   861 net.cpp:201] Creating Layer inception_3a/1x1
I0603 04:26:21.988656   861 net.cpp:902] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0603 04:26:21.988664   861 net.cpp:876] inception_3a/1x1 -> inception_3a/1x1
I0603 04:26:21.990797   861 net.cpp:286] Setting up inception_3a/1x1
I0603 04:26:21.990813   861 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:26:21.990819   861 net.cpp:301] Memory required for data: 864027264
I0603 04:26:21.990831   861 layer_factory.hpp:114] Creating layer inception_3a/relu_1x1
I0603 04:26:21.990844   861 net.cpp:201] Creating Layer inception_3a/relu_1x1
I0603 04:26:21.990850   861 net.cpp:902] inception_3a/relu_1x1 <- inception_3a/1x1
I0603 04:26:21.990859   861 net.cpp:863] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)
I0603 04:26:21.990880   861 net.cpp:286] Setting up inception_3a/relu_1x1
I0603 04:26:21.990887   861 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:26:21.990892   861 net.cpp:301] Memory required for data: 872415872
I0603 04:26:21.990897   861 layer_factory.hpp:114] Creating layer inception_3a/3x3_reduce
I0603 04:26:21.990916   861 net.cpp:201] Creating Layer inception_3a/3x3_reduce
I0603 04:26:21.990921   861 net.cpp:902] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0603 04:26:21.990933   861 net.cpp:876] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0603 04:26:21.993208   861 net.cpp:286] Setting up inception_3a/3x3_reduce
I0603 04:26:21.993226   861 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:26:21.993230   861 net.cpp:301] Memory required for data: 884998784
I0603 04:26:21.993247   861 layer_factory.hpp:114] Creating layer inception_3a/relu_3x3_reduce
I0603 04:26:21.993263   861 net.cpp:201] Creating Layer inception_3a/relu_3x3_reduce
I0603 04:26:21.993278   861 net.cpp:902] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce
I0603 04:26:21.993286   861 net.cpp:863] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)
I0603 04:26:21.993309   861 net.cpp:286] Setting up inception_3a/relu_3x3_reduce
I0603 04:26:21.993319   861 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:26:21.993324   861 net.cpp:301] Memory required for data: 897581696
I0603 04:26:21.993329   861 layer_factory.hpp:114] Creating layer inception_3a/3x3
I0603 04:26:21.993350   861 net.cpp:201] Creating Layer inception_3a/3x3
I0603 04:26:21.993356   861 net.cpp:902] inception_3a/3x3 <- inception_3a/3x3_reduce
I0603 04:26:21.993365   861 net.cpp:876] inception_3a/3x3 -> inception_3a/3x3
I0603 04:26:21.998136   861 net.cpp:286] Setting up inception_3a/3x3
I0603 04:26:21.998164   861 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:26:21.998170   861 net.cpp:301] Memory required for data: 914358912
I0603 04:26:21.998183   861 layer_factory.hpp:114] Creating layer inception_3a/relu_3x3
I0603 04:26:21.998199   861 net.cpp:201] Creating Layer inception_3a/relu_3x3
I0603 04:26:21.998206   861 net.cpp:902] inception_3a/relu_3x3 <- inception_3a/3x3
I0603 04:26:21.998214   861 net.cpp:863] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)
I0603 04:26:21.998236   861 net.cpp:286] Setting up inception_3a/relu_3x3
I0603 04:26:21.998245   861 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:26:21.998250   861 net.cpp:301] Memory required for data: 931136128
I0603 04:26:21.998255   861 layer_factory.hpp:114] Creating layer inception_3a/5x5_reduce
I0603 04:26:21.998292   861 net.cpp:201] Creating Layer inception_3a/5x5_reduce
I0603 04:26:21.998301   861 net.cpp:902] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0603 04:26:21.998311   861 net.cpp:876] inception_3a/5x5_reduce -> inception_3a/5x5_reduce
I0603 04:26:22.000087   861 net.cpp:286] Setting up inception_3a/5x5_reduce
I0603 04:26:22.000109   861 net.cpp:293] Top shape: 32 16 32 32 (524288)
I0603 04:26:22.000144   861 net.cpp:301] Memory required for data: 933233280
I0603 04:26:22.000157   861 layer_factory.hpp:114] Creating layer inception_3a/relu_5x5_reduce
I0603 04:26:22.000169   861 net.cpp:201] Creating Layer inception_3a/relu_5x5_reduce
I0603 04:26:22.000176   861 net.cpp:902] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce
I0603 04:26:22.000185   861 net.cpp:863] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)
I0603 04:26:22.000203   861 net.cpp:286] Setting up inception_3a/relu_5x5_reduce
I0603 04:26:22.000211   861 net.cpp:293] Top shape: 32 16 32 32 (524288)
I0603 04:26:22.000216   861 net.cpp:301] Memory required for data: 935330432
I0603 04:26:22.000222   861 layer_factory.hpp:114] Creating layer inception_3a/5x5
I0603 04:26:22.000246   861 net.cpp:201] Creating Layer inception_3a/5x5
I0603 04:26:22.000252   861 net.cpp:902] inception_3a/5x5 <- inception_3a/5x5_reduce
I0603 04:26:22.000264   861 net.cpp:876] inception_3a/5x5 -> inception_3a/5x5
I0603 04:26:22.002925   861 net.cpp:286] Setting up inception_3a/5x5
I0603 04:26:22.002946   861 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:26:22.002952   861 net.cpp:301] Memory required for data: 939524736
I0603 04:26:22.002964   861 layer_factory.hpp:114] Creating layer inception_3a/relu_5x5
I0603 04:26:22.002979   861 net.cpp:201] Creating Layer inception_3a/relu_5x5
I0603 04:26:22.002985   861 net.cpp:902] inception_3a/relu_5x5 <- inception_3a/5x5
I0603 04:26:22.002993   861 net.cpp:863] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)
I0603 04:26:22.003013   861 net.cpp:286] Setting up inception_3a/relu_5x5
I0603 04:26:22.003021   861 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:26:22.003026   861 net.cpp:301] Memory required for data: 943719040
I0603 04:26:22.003032   861 layer_factory.hpp:114] Creating layer inception_3a/pool
I0603 04:26:22.003046   861 net.cpp:201] Creating Layer inception_3a/pool
I0603 04:26:22.003051   861 net.cpp:902] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0603 04:26:22.003059   861 net.cpp:876] inception_3a/pool -> inception_3a/pool
I0603 04:26:22.003092   861 net.cpp:286] Setting up inception_3a/pool
I0603 04:26:22.003099   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:22.003104   861 net.cpp:301] Memory required for data: 968884864
I0603 04:26:22.003110   861 layer_factory.hpp:114] Creating layer inception_3a/pool_proj
I0603 04:26:22.003127   861 net.cpp:201] Creating Layer inception_3a/pool_proj
I0603 04:26:22.003134   861 net.cpp:902] inception_3a/pool_proj <- inception_3a/pool
I0603 04:26:22.003142   861 net.cpp:876] inception_3a/pool_proj -> inception_3a/pool_proj
I0603 04:26:22.005110   861 net.cpp:286] Setting up inception_3a/pool_proj
I0603 04:26:22.005131   861 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:26:22.005137   861 net.cpp:301] Memory required for data: 973079168
I0603 04:26:22.005156   861 layer_factory.hpp:114] Creating layer inception_3a/relu_pool_proj
I0603 04:26:22.005169   861 net.cpp:201] Creating Layer inception_3a/relu_pool_proj
I0603 04:26:22.005175   861 net.cpp:902] inception_3a/relu_pool_proj <- inception_3a/pool_proj
I0603 04:26:22.005183   861 net.cpp:863] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)
I0603 04:26:22.005203   861 net.cpp:286] Setting up inception_3a/relu_pool_proj
I0603 04:26:22.005210   861 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:26:22.005215   861 net.cpp:301] Memory required for data: 977273472
I0603 04:26:22.005220   861 layer_factory.hpp:114] Creating layer inception_3a/output
I0603 04:26:22.005231   861 net.cpp:201] Creating Layer inception_3a/output
I0603 04:26:22.005236   861 net.cpp:902] inception_3a/output <- inception_3a/1x1
I0603 04:26:22.005242   861 net.cpp:902] inception_3a/output <- inception_3a/3x3
I0603 04:26:22.005249   861 net.cpp:902] inception_3a/output <- inception_3a/5x5
I0603 04:26:22.005254   861 net.cpp:902] inception_3a/output <- inception_3a/pool_proj
I0603 04:26:22.005261   861 net.cpp:876] inception_3a/output -> inception_3a/output
I0603 04:26:22.005329   861 net.cpp:286] Setting up inception_3a/output
I0603 04:26:22.005339   861 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:26:22.005343   861 net.cpp:301] Memory required for data: 1010827904
I0603 04:26:22.005349   861 layer_factory.hpp:114] Creating layer inception_3a/output_inception_3a/output_0_split
I0603 04:26:22.005362   861 net.cpp:201] Creating Layer inception_3a/output_inception_3a/output_0_split
I0603 04:26:22.005367   861 net.cpp:902] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0603 04:26:22.005374   861 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0603 04:26:22.005383   861 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0603 04:26:22.005391   861 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0603 04:26:22.005399   861 net.cpp:876] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I0603 04:26:22.005426   861 net.cpp:286] Setting up inception_3a/output_inception_3a/output_0_split
I0603 04:26:22.005436   861 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:26:22.005442   861 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:26:22.005450   861 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:26:22.005455   861 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:26:22.005460   861 net.cpp:301] Memory required for data: 1145045632
I0603 04:26:22.005465   861 layer_factory.hpp:114] Creating layer inception_3b/1x1
I0603 04:26:22.005488   861 net.cpp:201] Creating Layer inception_3b/1x1
I0603 04:26:22.005494   861 net.cpp:902] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I0603 04:26:22.005506   861 net.cpp:876] inception_3b/1x1 -> inception_3b/1x1
I0603 04:26:22.008431   861 net.cpp:286] Setting up inception_3b/1x1
I0603 04:26:22.008450   861 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:26:22.008455   861 net.cpp:301] Memory required for data: 1161822848
I0603 04:26:22.008466   861 layer_factory.hpp:114] Creating layer inception_3b/relu_1x1
I0603 04:26:22.008481   861 net.cpp:201] Creating Layer inception_3b/relu_1x1
I0603 04:26:22.008488   861 net.cpp:902] inception_3b/relu_1x1 <- inception_3b/1x1
I0603 04:26:22.008496   861 net.cpp:863] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)
I0603 04:26:22.008522   861 net.cpp:286] Setting up inception_3b/relu_1x1
I0603 04:26:22.008528   861 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:26:22.008533   861 net.cpp:301] Memory required for data: 1178600064
I0603 04:26:22.008538   861 layer_factory.hpp:114] Creating layer inception_3b/3x3_reduce
I0603 04:26:22.008559   861 net.cpp:201] Creating Layer inception_3b/3x3_reduce
I0603 04:26:22.008566   861 net.cpp:902] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0603 04:26:22.008577   861 net.cpp:876] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0603 04:26:22.011322   861 net.cpp:286] Setting up inception_3b/3x3_reduce
I0603 04:26:22.011339   861 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:26:22.011345   861 net.cpp:301] Memory required for data: 1195377280
I0603 04:26:22.011358   861 layer_factory.hpp:114] Creating layer inception_3b/relu_3x3_reduce
I0603 04:26:22.011373   861 net.cpp:201] Creating Layer inception_3b/relu_3x3_reduce
I0603 04:26:22.011380   861 net.cpp:902] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce
I0603 04:26:22.011389   861 net.cpp:863] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)
I0603 04:26:22.011415   861 net.cpp:286] Setting up inception_3b/relu_3x3_reduce
I0603 04:26:22.011425   861 net.cpp:293] Top shape: 32 128 32 32 (4194304)
I0603 04:26:22.011430   861 net.cpp:301] Memory required for data: 1212154496
I0603 04:26:22.011435   861 layer_factory.hpp:114] Creating layer inception_3b/3x3
I0603 04:26:22.011476   861 net.cpp:201] Creating Layer inception_3b/3x3
I0603 04:26:22.011483   861 net.cpp:902] inception_3b/3x3 <- inception_3b/3x3_reduce
I0603 04:26:22.011492   861 net.cpp:876] inception_3b/3x3 -> inception_3b/3x3
I0603 04:26:22.018803   861 net.cpp:286] Setting up inception_3b/3x3
I0603 04:26:22.018826   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:22.018832   861 net.cpp:301] Memory required for data: 1237320320
I0603 04:26:22.018844   861 layer_factory.hpp:114] Creating layer inception_3b/relu_3x3
I0603 04:26:22.018859   861 net.cpp:201] Creating Layer inception_3b/relu_3x3
I0603 04:26:22.018867   861 net.cpp:902] inception_3b/relu_3x3 <- inception_3b/3x3
I0603 04:26:22.018874   861 net.cpp:863] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)
I0603 04:26:22.018894   861 net.cpp:286] Setting up inception_3b/relu_3x3
I0603 04:26:22.018903   861 net.cpp:293] Top shape: 32 192 32 32 (6291456)
I0603 04:26:22.018908   861 net.cpp:301] Memory required for data: 1262486144
I0603 04:26:22.018913   861 layer_factory.hpp:114] Creating layer inception_3b/5x5_reduce
I0603 04:26:22.018930   861 net.cpp:201] Creating Layer inception_3b/5x5_reduce
I0603 04:26:22.018937   861 net.cpp:902] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2
I0603 04:26:22.018946   861 net.cpp:876] inception_3b/5x5_reduce -> inception_3b/5x5_reduce
I0603 04:26:22.020972   861 net.cpp:286] Setting up inception_3b/5x5_reduce
I0603 04:26:22.020994   861 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:26:22.021000   861 net.cpp:301] Memory required for data: 1266680448
I0603 04:26:22.021013   861 layer_factory.hpp:114] Creating layer inception_3b/relu_5x5_reduce
I0603 04:26:22.021026   861 net.cpp:201] Creating Layer inception_3b/relu_5x5_reduce
I0603 04:26:22.021034   861 net.cpp:902] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce
I0603 04:26:22.021042   861 net.cpp:863] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)
I0603 04:26:22.021062   861 net.cpp:286] Setting up inception_3b/relu_5x5_reduce
I0603 04:26:22.021070   861 net.cpp:293] Top shape: 32 32 32 32 (1048576)
I0603 04:26:22.021075   861 net.cpp:301] Memory required for data: 1270874752
I0603 04:26:22.021080   861 layer_factory.hpp:114] Creating layer inception_3b/5x5
I0603 04:26:22.021097   861 net.cpp:201] Creating Layer inception_3b/5x5
I0603 04:26:22.021103   861 net.cpp:902] inception_3b/5x5 <- inception_3b/5x5_reduce
I0603 04:26:22.021111   861 net.cpp:876] inception_3b/5x5 -> inception_3b/5x5
I0603 04:26:22.025454   861 net.cpp:286] Setting up inception_3b/5x5
I0603 04:26:22.025477   861 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:26:22.025483   861 net.cpp:301] Memory required for data: 1283457664
I0603 04:26:22.025496   861 layer_factory.hpp:114] Creating layer inception_3b/relu_5x5
I0603 04:26:22.025509   861 net.cpp:201] Creating Layer inception_3b/relu_5x5
I0603 04:26:22.025516   861 net.cpp:902] inception_3b/relu_5x5 <- inception_3b/5x5
I0603 04:26:22.025526   861 net.cpp:863] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)
I0603 04:26:22.025547   861 net.cpp:286] Setting up inception_3b/relu_5x5
I0603 04:26:22.025553   861 net.cpp:293] Top shape: 32 96 32 32 (3145728)
I0603 04:26:22.025558   861 net.cpp:301] Memory required for data: 1296040576
I0603 04:26:22.025564   861 layer_factory.hpp:114] Creating layer inception_3b/pool
I0603 04:26:22.025576   861 net.cpp:201] Creating Layer inception_3b/pool
I0603 04:26:22.025583   861 net.cpp:902] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I0603 04:26:22.025591   861 net.cpp:876] inception_3b/pool -> inception_3b/pool
I0603 04:26:22.025612   861 net.cpp:286] Setting up inception_3b/pool
I0603 04:26:22.025620   861 net.cpp:293] Top shape: 32 256 32 32 (8388608)
I0603 04:26:22.025625   861 net.cpp:301] Memory required for data: 1329595008
I0603 04:26:22.025630   861 layer_factory.hpp:114] Creating layer inception_3b/pool_proj
I0603 04:26:22.025647   861 net.cpp:201] Creating Layer inception_3b/pool_proj
I0603 04:26:22.025671   861 net.cpp:902] inception_3b/pool_proj <- inception_3b/pool
I0603 04:26:22.025681   861 net.cpp:876] inception_3b/pool_proj -> inception_3b/pool_proj
I0603 04:26:22.028002   861 net.cpp:286] Setting up inception_3b/pool_proj
I0603 04:26:22.028024   861 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:26:22.028029   861 net.cpp:301] Memory required for data: 1337983616
I0603 04:26:22.028041   861 layer_factory.hpp:114] Creating layer inception_3b/relu_pool_proj
I0603 04:26:22.028059   861 net.cpp:201] Creating Layer inception_3b/relu_pool_proj
I0603 04:26:22.028065   861 net.cpp:902] inception_3b/relu_pool_proj <- inception_3b/pool_proj
I0603 04:26:22.028074   861 net.cpp:863] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)
I0603 04:26:22.028098   861 net.cpp:286] Setting up inception_3b/relu_pool_proj
I0603 04:26:22.028108   861 net.cpp:293] Top shape: 32 64 32 32 (2097152)
I0603 04:26:22.028113   861 net.cpp:301] Memory required for data: 1346372224
I0603 04:26:22.028120   861 layer_factory.hpp:114] Creating layer inception_3b/output
I0603 04:26:22.028129   861 net.cpp:201] Creating Layer inception_3b/output
I0603 04:26:22.028136   861 net.cpp:902] inception_3b/output <- inception_3b/1x1
I0603 04:26:22.028142   861 net.cpp:902] inception_3b/output <- inception_3b/3x3
I0603 04:26:22.028148   861 net.cpp:902] inception_3b/output <- inception_3b/5x5
I0603 04:26:22.028154   861 net.cpp:902] inception_3b/output <- inception_3b/pool_proj
I0603 04:26:22.028162   861 net.cpp:876] inception_3b/output -> inception_3b/output
I0603 04:26:22.028208   861 net.cpp:286] Setting up inception_3b/output
I0603 04:26:22.028215   861 net.cpp:293] Top shape: 32 480 32 32 (15728640)
I0603 04:26:22.028220   861 net.cpp:301] Memory required for data: 1409286784
I0603 04:26:22.028226   861 layer_factory.hpp:114] Creating layer pool3/3x3_s2
I0603 04:26:22.028241   861 net.cpp:201] Creating Layer pool3/3x3_s2
I0603 04:26:22.028247   861 net.cpp:902] pool3/3x3_s2 <- inception_3b/output
I0603 04:26:22.028259   861 net.cpp:876] pool3/3x3_s2 -> pool3/3x3_s2
I0603 04:26:22.028277   861 net.cpp:286] Setting up pool3/3x3_s2
I0603 04:26:22.028285   861 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:26:22.028290   861 net.cpp:301] Memory required for data: 1425015424
I0603 04:26:22.028295   861 layer_factory.hpp:114] Creating layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0603 04:26:22.028306   861 net.cpp:201] Creating Layer pool3/3x3_s2_pool3/3x3_s2_0_split
I0603 04:26:22.028311   861 net.cpp:902] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2
I0603 04:26:22.028321   861 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0603 04:26:22.028331   861 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0603 04:26:22.028340   861 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0603 04:26:22.028348   861 net.cpp:876] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0603 04:26:22.028370   861 net.cpp:286] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split
I0603 04:26:22.028378   861 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:26:22.028384   861 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:26:22.028390   861 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:26:22.028396   861 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:26:22.028401   861 net.cpp:301] Memory required for data: 1487929984
I0603 04:26:22.028408   861 layer_factory.hpp:114] Creating layer inception_4a/1x1
I0603 04:26:22.028424   861 net.cpp:201] Creating Layer inception_4a/1x1
I0603 04:26:22.028430   861 net.cpp:902] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0
I0603 04:26:22.028439   861 net.cpp:876] inception_4a/1x1 -> inception_4a/1x1
I0603 04:26:22.031848   861 net.cpp:286] Setting up inception_4a/1x1
I0603 04:26:22.031865   861 net.cpp:293] Top shape: 32 192 16 16 (1572864)
I0603 04:26:22.031870   861 net.cpp:301] Memory required for data: 1494221440
I0603 04:26:22.031898   861 layer_factory.hpp:114] Creating layer inception_4a/relu_1x1
I0603 04:26:22.031913   861 net.cpp:201] Creating Layer inception_4a/relu_1x1
I0603 04:26:22.031920   861 net.cpp:902] inception_4a/relu_1x1 <- inception_4a/1x1
I0603 04:26:22.031929   861 net.cpp:863] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)
I0603 04:26:22.031951   861 net.cpp:286] Setting up inception_4a/relu_1x1
I0603 04:26:22.031962   861 net.cpp:293] Top shape: 32 192 16 16 (1572864)
I0603 04:26:22.031967   861 net.cpp:301] Memory required for data: 1500512896
I0603 04:26:22.031972   861 layer_factory.hpp:114] Creating layer inception_4a/3x3_reduce
I0603 04:26:22.031994   861 net.cpp:201] Creating Layer inception_4a/3x3_reduce
I0603 04:26:22.032001   861 net.cpp:902] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1
I0603 04:26:22.032011   861 net.cpp:876] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I0603 04:26:22.034324   861 net.cpp:286] Setting up inception_4a/3x3_reduce
I0603 04:26:22.034344   861 net.cpp:293] Top shape: 32 96 16 16 (786432)
I0603 04:26:22.034350   861 net.cpp:301] Memory required for data: 1503658624
I0603 04:26:22.034371   861 layer_factory.hpp:114] Creating layer inception_4a/relu_3x3_reduce
I0603 04:26:22.034387   861 net.cpp:201] Creating Layer inception_4a/relu_3x3_reduce
I0603 04:26:22.034394   861 net.cpp:902] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce
I0603 04:26:22.034410   861 net.cpp:863] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)
I0603 04:26:22.034435   861 net.cpp:286] Setting up inception_4a/relu_3x3_reduce
I0603 04:26:22.034443   861 net.cpp:293] Top shape: 32 96 16 16 (786432)
I0603 04:26:22.034448   861 net.cpp:301] Memory required for data: 1506804352
I0603 04:26:22.034453   861 layer_factory.hpp:114] Creating layer inception_4a/3x3
I0603 04:26:22.034477   861 net.cpp:201] Creating Layer inception_4a/3x3
I0603 04:26:22.034483   861 net.cpp:902] inception_4a/3x3 <- inception_4a/3x3_reduce
I0603 04:26:22.034492   861 net.cpp:876] inception_4a/3x3 -> inception_4a/3x3
I0603 04:26:22.038800   861 net.cpp:286] Setting up inception_4a/3x3
I0603 04:26:22.038822   861 net.cpp:293] Top shape: 32 208 16 16 (1703936)
I0603 04:26:22.038828   861 net.cpp:301] Memory required for data: 1513620096
I0603 04:26:22.038841   861 layer_factory.hpp:114] Creating layer inception_4a/relu_3x3
I0603 04:26:22.038854   861 net.cpp:201] Creating Layer inception_4a/relu_3x3
I0603 04:26:22.038862   861 net.cpp:902] inception_4a/relu_3x3 <- inception_4a/3x3
I0603 04:26:22.038871   861 net.cpp:863] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)
I0603 04:26:22.038892   861 net.cpp:286] Setting up inception_4a/relu_3x3
I0603 04:26:22.038898   861 net.cpp:293] Top shape: 32 208 16 16 (1703936)
I0603 04:26:22.038903   861 net.cpp:301] Memory required for data: 1520435840
I0603 04:26:22.038909   861 layer_factory.hpp:114] Creating layer inception_4a/5x5_reduce
I0603 04:26:22.038926   861 net.cpp:201] Creating Layer inception_4a/5x5_reduce
I0603 04:26:22.038933   861 net.cpp:902] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2
I0603 04:26:22.038942   861 net.cpp:876] inception_4a/5x5_reduce -> inception_4a/5x5_reduce
I0603 04:26:22.040485   861 net.cpp:286] Setting up inception_4a/5x5_reduce
I0603 04:26:22.040508   861 net.cpp:293] Top shape: 32 16 16 16 (131072)
I0603 04:26:22.040513   861 net.cpp:301] Memory required for data: 1520960128
I0603 04:26:22.040525   861 layer_factory.hpp:114] Creating layer inception_4a/relu_5x5_reduce
I0603 04:26:22.040540   861 net.cpp:201] Creating Layer inception_4a/relu_5x5_reduce
I0603 04:26:22.040549   861 net.cpp:902] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce
I0603 04:26:22.040556   861 net.cpp:863] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)
I0603 04:26:22.040576   861 net.cpp:286] Setting up inception_4a/relu_5x5_reduce
I0603 04:26:22.040585   861 net.cpp:293] Top shape: 32 16 16 16 (131072)
I0603 04:26:22.040590   861 net.cpp:301] Memory required for data: 1521484416
I0603 04:26:22.040611   861 layer_factory.hpp:114] Creating layer inception_4a/5x5
I0603 04:26:22.040632   861 net.cpp:201] Creating Layer inception_4a/5x5
I0603 04:26:22.040637   861 net.cpp:902] inception_4a/5x5 <- inception_4a/5x5_reduce
I0603 04:26:22.040647   861 net.cpp:876] inception_4a/5x5 -> inception_4a/5x5
I0603 04:26:22.042421   861 net.cpp:286] Setting up inception_4a/5x5
I0603 04:26:22.042443   861 net.cpp:293] Top shape: 32 48 16 16 (393216)
I0603 04:26:22.042448   861 net.cpp:301] Memory required for data: 1523057280
I0603 04:26:22.042460   861 layer_factory.hpp:114] Creating layer inception_4a/relu_5x5
I0603 04:26:22.042474   861 net.cpp:201] Creating Layer inception_4a/relu_5x5
I0603 04:26:22.042481   861 net.cpp:902] inception_4a/relu_5x5 <- inception_4a/5x5
I0603 04:26:22.042490   861 net.cpp:863] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)
I0603 04:26:22.042510   861 net.cpp:286] Setting up inception_4a/relu_5x5
I0603 04:26:22.042517   861 net.cpp:293] Top shape: 32 48 16 16 (393216)
I0603 04:26:22.042522   861 net.cpp:301] Memory required for data: 1524630144
I0603 04:26:22.042527   861 layer_factory.hpp:114] Creating layer inception_4a/pool
I0603 04:26:22.042538   861 net.cpp:201] Creating Layer inception_4a/pool
I0603 04:26:22.042544   861 net.cpp:902] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3
I0603 04:26:22.042552   861 net.cpp:876] inception_4a/pool -> inception_4a/pool
I0603 04:26:22.042575   861 net.cpp:286] Setting up inception_4a/pool
I0603 04:26:22.042583   861 net.cpp:293] Top shape: 32 480 16 16 (3932160)
I0603 04:26:22.042588   861 net.cpp:301] Memory required for data: 1540358784
I0603 04:26:22.042593   861 layer_factory.hpp:114] Creating layer inception_4a/pool_proj
I0603 04:26:22.042611   861 net.cpp:201] Creating Layer inception_4a/pool_proj
I0603 04:26:22.042618   861 net.cpp:902] inception_4a/pool_proj <- inception_4a/pool
I0603 04:26:22.042625   861 net.cpp:876] inception_4a/pool_proj -> inception_4a/pool_proj
I0603 04:26:22.044792   861 net.cpp:286] Setting up inception_4a/pool_proj
I0603 04:26:22.044811   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.044816   861 net.cpp:301] Memory required for data: 1542455936
I0603 04:26:22.044827   861 layer_factory.hpp:114] Creating layer inception_4a/relu_pool_proj
I0603 04:26:22.044843   861 net.cpp:201] Creating Layer inception_4a/relu_pool_proj
I0603 04:26:22.044850   861 net.cpp:902] inception_4a/relu_pool_proj <- inception_4a/pool_proj
I0603 04:26:22.044858   861 net.cpp:863] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)
I0603 04:26:22.044883   861 net.cpp:286] Setting up inception_4a/relu_pool_proj
I0603 04:26:22.044893   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.044898   861 net.cpp:301] Memory required for data: 1544553088
I0603 04:26:22.044903   861 layer_factory.hpp:114] Creating layer inception_4a/output
I0603 04:26:22.044915   861 net.cpp:201] Creating Layer inception_4a/output
I0603 04:26:22.044921   861 net.cpp:902] inception_4a/output <- inception_4a/1x1
I0603 04:26:22.044927   861 net.cpp:902] inception_4a/output <- inception_4a/3x3
I0603 04:26:22.044934   861 net.cpp:902] inception_4a/output <- inception_4a/5x5
I0603 04:26:22.044939   861 net.cpp:902] inception_4a/output <- inception_4a/pool_proj
I0603 04:26:22.044947   861 net.cpp:876] inception_4a/output -> inception_4a/output
I0603 04:26:22.044991   861 net.cpp:286] Setting up inception_4a/output
I0603 04:26:22.044999   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.045006   861 net.cpp:301] Memory required for data: 1561330304
I0603 04:26:22.045011   861 layer_factory.hpp:114] Creating layer inception_4a/output_inception_4a/output_0_split
I0603 04:26:22.045023   861 net.cpp:201] Creating Layer inception_4a/output_inception_4a/output_0_split
I0603 04:26:22.045029   861 net.cpp:902] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I0603 04:26:22.045037   861 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I0603 04:26:22.045063   861 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I0603 04:26:22.045073   861 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I0603 04:26:22.045083   861 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I0603 04:26:22.045090   861 net.cpp:876] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_4
I0603 04:26:22.045119   861 net.cpp:286] Setting up inception_4a/output_inception_4a/output_0_split
I0603 04:26:22.045126   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.045133   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.045140   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.045145   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.045151   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.045156   861 net.cpp:301] Memory required for data: 1645216384
I0603 04:26:22.045162   861 layer_factory.hpp:114] Creating layer loss1/ave_pool
I0603 04:26:22.045176   861 net.cpp:201] Creating Layer loss1/ave_pool
I0603 04:26:22.045182   861 net.cpp:902] loss1/ave_pool <- inception_4a/output_inception_4a/output_0_split_0
I0603 04:26:22.045192   861 net.cpp:876] loss1/ave_pool -> loss1/ave_pool
I0603 04:26:22.045214   861 net.cpp:286] Setting up loss1/ave_pool
I0603 04:26:22.045223   861 net.cpp:293] Top shape: 32 512 5 5 (409600)
I0603 04:26:22.045228   861 net.cpp:301] Memory required for data: 1646854784
I0603 04:26:22.045233   861 layer_factory.hpp:114] Creating layer loss1/conv
I0603 04:26:22.045253   861 net.cpp:201] Creating Layer loss1/conv
I0603 04:26:22.045258   861 net.cpp:902] loss1/conv <- loss1/ave_pool
I0603 04:26:22.045267   861 net.cpp:876] loss1/conv -> loss1/conv
I0603 04:26:22.047633   861 net.cpp:286] Setting up loss1/conv
I0603 04:26:22.047650   861 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:26:22.047657   861 net.cpp:301] Memory required for data: 1647264384
I0603 04:26:22.047667   861 layer_factory.hpp:114] Creating layer loss1/relu_conv
I0603 04:26:22.047682   861 net.cpp:201] Creating Layer loss1/relu_conv
I0603 04:26:22.047688   861 net.cpp:902] loss1/relu_conv <- loss1/conv
I0603 04:26:22.047698   861 net.cpp:863] loss1/relu_conv -> loss1/conv (in-place)
I0603 04:26:22.047724   861 net.cpp:286] Setting up loss1/relu_conv
I0603 04:26:22.047731   861 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:26:22.047736   861 net.cpp:301] Memory required for data: 1647673984
I0603 04:26:22.047741   861 layer_factory.hpp:114] Creating layer loss1/fc
I0603 04:26:22.047758   861 net.cpp:201] Creating Layer loss1/fc
I0603 04:26:22.047763   861 net.cpp:902] loss1/fc <- loss1/conv
I0603 04:26:22.047775   861 net.cpp:876] loss1/fc -> loss1/fc
I0603 04:26:22.074342   861 net.cpp:286] Setting up loss1/fc
I0603 04:26:22.074383   861 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:26:22.074389   861 net.cpp:301] Memory required for data: 1647805056
I0603 04:26:22.074404   861 layer_factory.hpp:114] Creating layer loss1/relu_fc
I0603 04:26:22.074434   861 net.cpp:201] Creating Layer loss1/relu_fc
I0603 04:26:22.074443   861 net.cpp:902] loss1/relu_fc <- loss1/fc
I0603 04:26:22.074453   861 net.cpp:863] loss1/relu_fc -> loss1/fc (in-place)
I0603 04:26:22.074488   861 net.cpp:286] Setting up loss1/relu_fc
I0603 04:26:22.074496   861 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:26:22.074501   861 net.cpp:301] Memory required for data: 1647936128
I0603 04:26:22.074506   861 layer_factory.hpp:114] Creating layer loss1/drop_fc
I0603 04:26:22.074529   861 net.cpp:201] Creating Layer loss1/drop_fc
I0603 04:26:22.074535   861 net.cpp:902] loss1/drop_fc <- loss1/fc
I0603 04:26:22.074544   861 net.cpp:863] loss1/drop_fc -> loss1/fc (in-place)
I0603 04:26:22.074558   861 net.cpp:286] Setting up loss1/drop_fc
I0603 04:26:22.074566   861 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:26:22.074595   861 net.cpp:301] Memory required for data: 1648067200
I0603 04:26:22.074601   861 layer_factory.hpp:114] Creating layer loss1/classifier
I0603 04:26:22.074618   861 net.cpp:201] Creating Layer loss1/classifier
I0603 04:26:22.074625   861 net.cpp:902] loss1/classifier <- loss1/fc
I0603 04:26:22.074633   861 net.cpp:876] loss1/classifier -> loss1/classifier
I0603 04:26:22.074697   861 net.cpp:286] Setting up loss1/classifier
I0603 04:26:22.074707   861 net.cpp:293] Top shape: 32 3 (96)
I0603 04:26:22.074712   861 net.cpp:301] Memory required for data: 1648067584
I0603 04:26:22.074720   861 layer_factory.hpp:114] Creating layer loss1/loss
I0603 04:26:22.074740   861 net.cpp:201] Creating Layer loss1/loss
I0603 04:26:22.074746   861 net.cpp:902] loss1/loss <- loss1/classifier
I0603 04:26:22.074755   861 net.cpp:902] loss1/loss <- label_DataColor256_1_split_0
I0603 04:26:22.074766   861 net.cpp:876] loss1/loss -> loss1/loss
I0603 04:26:22.074786   861 layer_factory.hpp:114] Creating layer loss1/loss
I0603 04:26:22.074815   861 net.cpp:286] Setting up loss1/loss
I0603 04:26:22.074823   861 net.cpp:293] Top shape: (1)
I0603 04:26:22.074827   861 net.cpp:296]     with loss weight 0.3
I0603 04:26:22.074863   861 net.cpp:301] Memory required for data: 1648067588
I0603 04:26:22.074868   861 layer_factory.hpp:114] Creating layer inception_4b/1x1
I0603 04:26:22.074892   861 net.cpp:201] Creating Layer inception_4b/1x1
I0603 04:26:22.074899   861 net.cpp:902] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_1
I0603 04:26:22.074910   861 net.cpp:876] inception_4b/1x1 -> inception_4b/1x1
I0603 04:26:22.078074   861 net.cpp:286] Setting up inception_4b/1x1
I0603 04:26:22.078099   861 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:26:22.078105   861 net.cpp:301] Memory required for data: 1653310468
I0603 04:26:22.078117   861 layer_factory.hpp:114] Creating layer inception_4b/relu_1x1
I0603 04:26:22.078135   861 net.cpp:201] Creating Layer inception_4b/relu_1x1
I0603 04:26:22.078143   861 net.cpp:902] inception_4b/relu_1x1 <- inception_4b/1x1
I0603 04:26:22.078153   861 net.cpp:863] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)
I0603 04:26:22.078181   861 net.cpp:286] Setting up inception_4b/relu_1x1
I0603 04:26:22.078188   861 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:26:22.078193   861 net.cpp:301] Memory required for data: 1658553348
I0603 04:26:22.078199   861 layer_factory.hpp:114] Creating layer inception_4b/3x3_reduce
I0603 04:26:22.078227   861 net.cpp:201] Creating Layer inception_4b/3x3_reduce
I0603 04:26:22.078235   861 net.cpp:902] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_2
I0603 04:26:22.078244   861 net.cpp:876] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I0603 04:26:22.080576   861 net.cpp:286] Setting up inception_4b/3x3_reduce
I0603 04:26:22.080598   861 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:26:22.080605   861 net.cpp:301] Memory required for data: 1662223364
I0603 04:26:22.080616   861 layer_factory.hpp:114] Creating layer inception_4b/relu_3x3_reduce
I0603 04:26:22.080633   861 net.cpp:201] Creating Layer inception_4b/relu_3x3_reduce
I0603 04:26:22.080641   861 net.cpp:902] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce
I0603 04:26:22.080649   861 net.cpp:863] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)
I0603 04:26:22.080673   861 net.cpp:286] Setting up inception_4b/relu_3x3_reduce
I0603 04:26:22.080683   861 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:26:22.080688   861 net.cpp:301] Memory required for data: 1665893380
I0603 04:26:22.080693   861 layer_factory.hpp:114] Creating layer inception_4b/3x3
I0603 04:26:22.080715   861 net.cpp:201] Creating Layer inception_4b/3x3
I0603 04:26:22.080723   861 net.cpp:902] inception_4b/3x3 <- inception_4b/3x3_reduce
I0603 04:26:22.080734   861 net.cpp:876] inception_4b/3x3 -> inception_4b/3x3
I0603 04:26:22.085546   861 net.cpp:286] Setting up inception_4b/3x3
I0603 04:26:22.085569   861 net.cpp:293] Top shape: 32 224 16 16 (1835008)
I0603 04:26:22.085595   861 net.cpp:301] Memory required for data: 1673233412
I0603 04:26:22.085609   861 layer_factory.hpp:114] Creating layer inception_4b/relu_3x3
I0603 04:26:22.085623   861 net.cpp:201] Creating Layer inception_4b/relu_3x3
I0603 04:26:22.085629   861 net.cpp:902] inception_4b/relu_3x3 <- inception_4b/3x3
I0603 04:26:22.085638   861 net.cpp:863] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)
I0603 04:26:22.085659   861 net.cpp:286] Setting up inception_4b/relu_3x3
I0603 04:26:22.085666   861 net.cpp:293] Top shape: 32 224 16 16 (1835008)
I0603 04:26:22.085672   861 net.cpp:301] Memory required for data: 1680573444
I0603 04:26:22.085678   861 layer_factory.hpp:114] Creating layer inception_4b/5x5_reduce
I0603 04:26:22.085697   861 net.cpp:201] Creating Layer inception_4b/5x5_reduce
I0603 04:26:22.085705   861 net.cpp:902] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_3
I0603 04:26:22.085713   861 net.cpp:876] inception_4b/5x5_reduce -> inception_4b/5x5_reduce
I0603 04:26:22.088692   861 net.cpp:286] Setting up inception_4b/5x5_reduce
I0603 04:26:22.088716   861 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:26:22.088722   861 net.cpp:301] Memory required for data: 1681359876
I0603 04:26:22.088732   861 layer_factory.hpp:114] Creating layer inception_4b/relu_5x5_reduce
I0603 04:26:22.088743   861 net.cpp:201] Creating Layer inception_4b/relu_5x5_reduce
I0603 04:26:22.088747   861 net.cpp:902] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce
I0603 04:26:22.088753   861 net.cpp:863] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)
I0603 04:26:22.088768   861 net.cpp:286] Setting up inception_4b/relu_5x5_reduce
I0603 04:26:22.088773   861 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:26:22.088775   861 net.cpp:301] Memory required for data: 1682146308
I0603 04:26:22.088778   861 layer_factory.hpp:114] Creating layer inception_4b/5x5
I0603 04:26:22.088790   861 net.cpp:201] Creating Layer inception_4b/5x5
I0603 04:26:22.088793   861 net.cpp:902] inception_4b/5x5 <- inception_4b/5x5_reduce
I0603 04:26:22.088799   861 net.cpp:876] inception_4b/5x5 -> inception_4b/5x5
I0603 04:26:22.090456   861 net.cpp:286] Setting up inception_4b/5x5
I0603 04:26:22.090481   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.090487   861 net.cpp:301] Memory required for data: 1684243460
I0603 04:26:22.090494   861 layer_factory.hpp:114] Creating layer inception_4b/relu_5x5
I0603 04:26:22.090503   861 net.cpp:201] Creating Layer inception_4b/relu_5x5
I0603 04:26:22.090508   861 net.cpp:902] inception_4b/relu_5x5 <- inception_4b/5x5
I0603 04:26:22.090513   861 net.cpp:863] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)
I0603 04:26:22.090528   861 net.cpp:286] Setting up inception_4b/relu_5x5
I0603 04:26:22.090533   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.090535   861 net.cpp:301] Memory required for data: 1686340612
I0603 04:26:22.090538   861 layer_factory.hpp:114] Creating layer inception_4b/pool
I0603 04:26:22.090548   861 net.cpp:201] Creating Layer inception_4b/pool
I0603 04:26:22.090550   861 net.cpp:902] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_4
I0603 04:26:22.090555   861 net.cpp:876] inception_4b/pool -> inception_4b/pool
I0603 04:26:22.090570   861 net.cpp:286] Setting up inception_4b/pool
I0603 04:26:22.090574   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.090577   861 net.cpp:301] Memory required for data: 1703117828
I0603 04:26:22.090580   861 layer_factory.hpp:114] Creating layer inception_4b/pool_proj
I0603 04:26:22.090591   861 net.cpp:201] Creating Layer inception_4b/pool_proj
I0603 04:26:22.090595   861 net.cpp:902] inception_4b/pool_proj <- inception_4b/pool
I0603 04:26:22.090600   861 net.cpp:876] inception_4b/pool_proj -> inception_4b/pool_proj
I0603 04:26:22.092181   861 net.cpp:286] Setting up inception_4b/pool_proj
I0603 04:26:22.092197   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.092219   861 net.cpp:301] Memory required for data: 1705214980
I0603 04:26:22.092231   861 layer_factory.hpp:114] Creating layer inception_4b/relu_pool_proj
I0603 04:26:22.092243   861 net.cpp:201] Creating Layer inception_4b/relu_pool_proj
I0603 04:26:22.092250   861 net.cpp:902] inception_4b/relu_pool_proj <- inception_4b/pool_proj
I0603 04:26:22.092262   861 net.cpp:863] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)
I0603 04:26:22.092286   861 net.cpp:286] Setting up inception_4b/relu_pool_proj
I0603 04:26:22.092294   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.092299   861 net.cpp:301] Memory required for data: 1707312132
I0603 04:26:22.092304   861 layer_factory.hpp:114] Creating layer inception_4b/output
I0603 04:26:22.092317   861 net.cpp:201] Creating Layer inception_4b/output
I0603 04:26:22.092324   861 net.cpp:902] inception_4b/output <- inception_4b/1x1
I0603 04:26:22.092330   861 net.cpp:902] inception_4b/output <- inception_4b/3x3
I0603 04:26:22.092336   861 net.cpp:902] inception_4b/output <- inception_4b/5x5
I0603 04:26:22.092341   861 net.cpp:902] inception_4b/output <- inception_4b/pool_proj
I0603 04:26:22.092351   861 net.cpp:876] inception_4b/output -> inception_4b/output
I0603 04:26:22.092401   861 net.cpp:286] Setting up inception_4b/output
I0603 04:26:22.092411   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.092417   861 net.cpp:301] Memory required for data: 1724089348
I0603 04:26:22.092422   861 layer_factory.hpp:114] Creating layer inception_4b/output_inception_4b/output_0_split
I0603 04:26:22.092433   861 net.cpp:201] Creating Layer inception_4b/output_inception_4b/output_0_split
I0603 04:26:22.092438   861 net.cpp:902] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I0603 04:26:22.092447   861 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I0603 04:26:22.092455   861 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I0603 04:26:22.092463   861 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I0603 04:26:22.092470   861 net.cpp:876] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I0603 04:26:22.092496   861 net.cpp:286] Setting up inception_4b/output_inception_4b/output_0_split
I0603 04:26:22.092504   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.092509   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.092515   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.092520   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.092525   861 net.cpp:301] Memory required for data: 1791198212
I0603 04:26:22.092530   861 layer_factory.hpp:114] Creating layer inception_4c/1x1
I0603 04:26:22.092550   861 net.cpp:201] Creating Layer inception_4c/1x1
I0603 04:26:22.092556   861 net.cpp:902] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I0603 04:26:22.092567   861 net.cpp:876] inception_4c/1x1 -> inception_4c/1x1
I0603 04:26:22.095335   861 net.cpp:286] Setting up inception_4c/1x1
I0603 04:26:22.095353   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.095360   861 net.cpp:301] Memory required for data: 1795392516
I0603 04:26:22.095371   861 layer_factory.hpp:114] Creating layer inception_4c/relu_1x1
I0603 04:26:22.095386   861 net.cpp:201] Creating Layer inception_4c/relu_1x1
I0603 04:26:22.095393   861 net.cpp:902] inception_4c/relu_1x1 <- inception_4c/1x1
I0603 04:26:22.095402   861 net.cpp:863] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)
I0603 04:26:22.095434   861 net.cpp:286] Setting up inception_4c/relu_1x1
I0603 04:26:22.095444   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.095449   861 net.cpp:301] Memory required for data: 1799586820
I0603 04:26:22.095454   861 layer_factory.hpp:114] Creating layer inception_4c/3x3_reduce
I0603 04:26:22.095495   861 net.cpp:201] Creating Layer inception_4c/3x3_reduce
I0603 04:26:22.095501   861 net.cpp:902] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I0603 04:26:22.095508   861 net.cpp:876] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I0603 04:26:22.098170   861 net.cpp:286] Setting up inception_4c/3x3_reduce
I0603 04:26:22.098198   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.098204   861 net.cpp:301] Memory required for data: 1803781124
I0603 04:26:22.098217   861 layer_factory.hpp:114] Creating layer inception_4c/relu_3x3_reduce
I0603 04:26:22.098232   861 net.cpp:201] Creating Layer inception_4c/relu_3x3_reduce
I0603 04:26:22.098242   861 net.cpp:902] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce
I0603 04:26:22.098260   861 net.cpp:863] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)
I0603 04:26:22.098323   861 net.cpp:286] Setting up inception_4c/relu_3x3_reduce
I0603 04:26:22.098338   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.098346   861 net.cpp:301] Memory required for data: 1807975428
I0603 04:26:22.098354   861 layer_factory.hpp:114] Creating layer inception_4c/3x3
I0603 04:26:22.098381   861 net.cpp:201] Creating Layer inception_4c/3x3
I0603 04:26:22.098387   861 net.cpp:902] inception_4c/3x3 <- inception_4c/3x3_reduce
I0603 04:26:22.098397   861 net.cpp:876] inception_4c/3x3 -> inception_4c/3x3
I0603 04:26:22.104933   861 net.cpp:286] Setting up inception_4c/3x3
I0603 04:26:22.104957   861 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:26:22.104961   861 net.cpp:301] Memory required for data: 1816364036
I0603 04:26:22.104981   861 layer_factory.hpp:114] Creating layer inception_4c/relu_3x3
I0603 04:26:22.104991   861 net.cpp:201] Creating Layer inception_4c/relu_3x3
I0603 04:26:22.104996   861 net.cpp:902] inception_4c/relu_3x3 <- inception_4c/3x3
I0603 04:26:22.105003   861 net.cpp:863] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)
I0603 04:26:22.105020   861 net.cpp:286] Setting up inception_4c/relu_3x3
I0603 04:26:22.105026   861 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:26:22.105028   861 net.cpp:301] Memory required for data: 1824752644
I0603 04:26:22.105031   861 layer_factory.hpp:114] Creating layer inception_4c/5x5_reduce
I0603 04:26:22.105046   861 net.cpp:201] Creating Layer inception_4c/5x5_reduce
I0603 04:26:22.105051   861 net.cpp:902] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2
I0603 04:26:22.105057   861 net.cpp:876] inception_4c/5x5_reduce -> inception_4c/5x5_reduce
I0603 04:26:22.109535   861 net.cpp:286] Setting up inception_4c/5x5_reduce
I0603 04:26:22.109686   861 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:26:22.109773   861 net.cpp:301] Memory required for data: 1825539076
I0603 04:26:22.109796   861 layer_factory.hpp:114] Creating layer inception_4c/relu_5x5_reduce
I0603 04:26:22.109812   861 net.cpp:201] Creating Layer inception_4c/relu_5x5_reduce
I0603 04:26:22.109820   861 net.cpp:902] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce
I0603 04:26:22.109829   861 net.cpp:863] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)
I0603 04:26:22.109853   861 net.cpp:286] Setting up inception_4c/relu_5x5_reduce
I0603 04:26:22.109860   861 net.cpp:293] Top shape: 32 24 16 16 (196608)
I0603 04:26:22.109865   861 net.cpp:301] Memory required for data: 1826325508
I0603 04:26:22.109870   861 layer_factory.hpp:114] Creating layer inception_4c/5x5
I0603 04:26:22.109889   861 net.cpp:201] Creating Layer inception_4c/5x5
I0603 04:26:22.109894   861 net.cpp:902] inception_4c/5x5 <- inception_4c/5x5_reduce
I0603 04:26:22.109904   861 net.cpp:876] inception_4c/5x5 -> inception_4c/5x5
I0603 04:26:22.112848   861 net.cpp:286] Setting up inception_4c/5x5
I0603 04:26:22.112870   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.112876   861 net.cpp:301] Memory required for data: 1828422660
I0603 04:26:22.112887   861 layer_factory.hpp:114] Creating layer inception_4c/relu_5x5
I0603 04:26:22.112922   861 net.cpp:201] Creating Layer inception_4c/relu_5x5
I0603 04:26:22.112931   861 net.cpp:902] inception_4c/relu_5x5 <- inception_4c/5x5
I0603 04:26:22.112938   861 net.cpp:863] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)
I0603 04:26:22.112959   861 net.cpp:286] Setting up inception_4c/relu_5x5
I0603 04:26:22.112967   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.112972   861 net.cpp:301] Memory required for data: 1830519812
I0603 04:26:22.112977   861 layer_factory.hpp:114] Creating layer inception_4c/pool
I0603 04:26:22.112989   861 net.cpp:201] Creating Layer inception_4c/pool
I0603 04:26:22.112995   861 net.cpp:902] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I0603 04:26:22.113004   861 net.cpp:876] inception_4c/pool -> inception_4c/pool
I0603 04:26:22.113025   861 net.cpp:286] Setting up inception_4c/pool
I0603 04:26:22.113034   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.113037   861 net.cpp:301] Memory required for data: 1847297028
I0603 04:26:22.113044   861 layer_factory.hpp:114] Creating layer inception_4c/pool_proj
I0603 04:26:22.113061   861 net.cpp:201] Creating Layer inception_4c/pool_proj
I0603 04:26:22.113067   861 net.cpp:902] inception_4c/pool_proj <- inception_4c/pool
I0603 04:26:22.113076   861 net.cpp:876] inception_4c/pool_proj -> inception_4c/pool_proj
I0603 04:26:22.115406   861 net.cpp:286] Setting up inception_4c/pool_proj
I0603 04:26:22.115428   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.115434   861 net.cpp:301] Memory required for data: 1849394180
I0603 04:26:22.115447   861 layer_factory.hpp:114] Creating layer inception_4c/relu_pool_proj
I0603 04:26:22.115468   861 net.cpp:201] Creating Layer inception_4c/relu_pool_proj
I0603 04:26:22.115476   861 net.cpp:902] inception_4c/relu_pool_proj <- inception_4c/pool_proj
I0603 04:26:22.115485   861 net.cpp:863] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)
I0603 04:26:22.115511   861 net.cpp:286] Setting up inception_4c/relu_pool_proj
I0603 04:26:22.115519   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.115523   861 net.cpp:301] Memory required for data: 1851491332
I0603 04:26:22.115530   861 layer_factory.hpp:114] Creating layer inception_4c/output
I0603 04:26:22.115542   861 net.cpp:201] Creating Layer inception_4c/output
I0603 04:26:22.115548   861 net.cpp:902] inception_4c/output <- inception_4c/1x1
I0603 04:26:22.115556   861 net.cpp:902] inception_4c/output <- inception_4c/3x3
I0603 04:26:22.115562   861 net.cpp:902] inception_4c/output <- inception_4c/5x5
I0603 04:26:22.115568   861 net.cpp:902] inception_4c/output <- inception_4c/pool_proj
I0603 04:26:22.115577   861 net.cpp:876] inception_4c/output -> inception_4c/output
I0603 04:26:22.115624   861 net.cpp:286] Setting up inception_4c/output
I0603 04:26:22.115633   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.115638   861 net.cpp:301] Memory required for data: 1868268548
I0603 04:26:22.115643   861 layer_factory.hpp:114] Creating layer inception_4c/output_inception_4c/output_0_split
I0603 04:26:22.115654   861 net.cpp:201] Creating Layer inception_4c/output_inception_4c/output_0_split
I0603 04:26:22.115660   861 net.cpp:902] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I0603 04:26:22.115669   861 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I0603 04:26:22.115677   861 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I0603 04:26:22.115686   861 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I0603 04:26:22.115694   861 net.cpp:876] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I0603 04:26:22.115718   861 net.cpp:286] Setting up inception_4c/output_inception_4c/output_0_split
I0603 04:26:22.115727   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.115751   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.115758   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.115764   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.115769   861 net.cpp:301] Memory required for data: 1935377412
I0603 04:26:22.115774   861 layer_factory.hpp:114] Creating layer inception_4d/1x1
I0603 04:26:22.115798   861 net.cpp:201] Creating Layer inception_4d/1x1
I0603 04:26:22.115804   861 net.cpp:902] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I0603 04:26:22.115813   861 net.cpp:876] inception_4d/1x1 -> inception_4d/1x1
I0603 04:26:22.119482   861 net.cpp:286] Setting up inception_4d/1x1
I0603 04:26:22.119498   861 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:26:22.119504   861 net.cpp:301] Memory required for data: 1939047428
I0603 04:26:22.119515   861 layer_factory.hpp:114] Creating layer inception_4d/relu_1x1
I0603 04:26:22.119530   861 net.cpp:201] Creating Layer inception_4d/relu_1x1
I0603 04:26:22.119536   861 net.cpp:902] inception_4d/relu_1x1 <- inception_4d/1x1
I0603 04:26:22.119544   861 net.cpp:863] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)
I0603 04:26:22.119568   861 net.cpp:286] Setting up inception_4d/relu_1x1
I0603 04:26:22.119577   861 net.cpp:293] Top shape: 32 112 16 16 (917504)
I0603 04:26:22.119582   861 net.cpp:301] Memory required for data: 1942717444
I0603 04:26:22.119588   861 layer_factory.hpp:114] Creating layer inception_4d/3x3_reduce
I0603 04:26:22.119609   861 net.cpp:201] Creating Layer inception_4d/3x3_reduce
I0603 04:26:22.119616   861 net.cpp:902] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I0603 04:26:22.119628   861 net.cpp:876] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I0603 04:26:22.122431   861 net.cpp:286] Setting up inception_4d/3x3_reduce
I0603 04:26:22.122453   861 net.cpp:293] Top shape: 32 144 16 16 (1179648)
I0603 04:26:22.122459   861 net.cpp:301] Memory required for data: 1947436036
I0603 04:26:22.122472   861 layer_factory.hpp:114] Creating layer inception_4d/relu_3x3_reduce
I0603 04:26:22.122485   861 net.cpp:201] Creating Layer inception_4d/relu_3x3_reduce
I0603 04:26:22.122493   861 net.cpp:902] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce
I0603 04:26:22.122501   861 net.cpp:863] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)
I0603 04:26:22.122527   861 net.cpp:286] Setting up inception_4d/relu_3x3_reduce
I0603 04:26:22.122535   861 net.cpp:293] Top shape: 32 144 16 16 (1179648)
I0603 04:26:22.122540   861 net.cpp:301] Memory required for data: 1952154628
I0603 04:26:22.122545   861 layer_factory.hpp:114] Creating layer inception_4d/3x3
I0603 04:26:22.122567   861 net.cpp:201] Creating Layer inception_4d/3x3
I0603 04:26:22.122573   861 net.cpp:902] inception_4d/3x3 <- inception_4d/3x3_reduce
I0603 04:26:22.122584   861 net.cpp:876] inception_4d/3x3 -> inception_4d/3x3
I0603 04:26:22.129220   861 net.cpp:286] Setting up inception_4d/3x3
I0603 04:26:22.129242   861 net.cpp:293] Top shape: 32 288 16 16 (2359296)
I0603 04:26:22.129248   861 net.cpp:301] Memory required for data: 1961591812
I0603 04:26:22.129259   861 layer_factory.hpp:114] Creating layer inception_4d/relu_3x3
I0603 04:26:22.129281   861 net.cpp:201] Creating Layer inception_4d/relu_3x3
I0603 04:26:22.129289   861 net.cpp:902] inception_4d/relu_3x3 <- inception_4d/3x3
I0603 04:26:22.129297   861 net.cpp:863] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)
I0603 04:26:22.129323   861 net.cpp:286] Setting up inception_4d/relu_3x3
I0603 04:26:22.129331   861 net.cpp:293] Top shape: 32 288 16 16 (2359296)
I0603 04:26:22.129335   861 net.cpp:301] Memory required for data: 1971028996
I0603 04:26:22.129340   861 layer_factory.hpp:114] Creating layer inception_4d/5x5_reduce
I0603 04:26:22.129364   861 net.cpp:201] Creating Layer inception_4d/5x5_reduce
I0603 04:26:22.129369   861 net.cpp:902] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2
I0603 04:26:22.129380   861 net.cpp:876] inception_4d/5x5_reduce -> inception_4d/5x5_reduce
I0603 04:26:22.131230   861 net.cpp:286] Setting up inception_4d/5x5_reduce
I0603 04:26:22.131253   861 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:26:22.131258   861 net.cpp:301] Memory required for data: 1972077572
I0603 04:26:22.131270   861 layer_factory.hpp:114] Creating layer inception_4d/relu_5x5_reduce
I0603 04:26:22.131284   861 net.cpp:201] Creating Layer inception_4d/relu_5x5_reduce
I0603 04:26:22.131292   861 net.cpp:902] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce
I0603 04:26:22.131300   861 net.cpp:863] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)
I0603 04:26:22.131320   861 net.cpp:286] Setting up inception_4d/relu_5x5_reduce
I0603 04:26:22.131328   861 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:26:22.131333   861 net.cpp:301] Memory required for data: 1973126148
I0603 04:26:22.131338   861 layer_factory.hpp:114] Creating layer inception_4d/5x5
I0603 04:26:22.131356   861 net.cpp:201] Creating Layer inception_4d/5x5
I0603 04:26:22.131361   861 net.cpp:902] inception_4d/5x5 <- inception_4d/5x5_reduce
I0603 04:26:22.131371   861 net.cpp:876] inception_4d/5x5 -> inception_4d/5x5
I0603 04:26:22.133873   861 net.cpp:286] Setting up inception_4d/5x5
I0603 04:26:22.133894   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.133900   861 net.cpp:301] Memory required for data: 1975223300
I0603 04:26:22.133913   861 layer_factory.hpp:114] Creating layer inception_4d/relu_5x5
I0603 04:26:22.133926   861 net.cpp:201] Creating Layer inception_4d/relu_5x5
I0603 04:26:22.133934   861 net.cpp:902] inception_4d/relu_5x5 <- inception_4d/5x5
I0603 04:26:22.133942   861 net.cpp:863] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)
I0603 04:26:22.133962   861 net.cpp:286] Setting up inception_4d/relu_5x5
I0603 04:26:22.133970   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.133975   861 net.cpp:301] Memory required for data: 1977320452
I0603 04:26:22.133980   861 layer_factory.hpp:114] Creating layer inception_4d/pool
I0603 04:26:22.133992   861 net.cpp:201] Creating Layer inception_4d/pool
I0603 04:26:22.133999   861 net.cpp:902] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I0603 04:26:22.134007   861 net.cpp:876] inception_4d/pool -> inception_4d/pool
I0603 04:26:22.134028   861 net.cpp:286] Setting up inception_4d/pool
I0603 04:26:22.134037   861 net.cpp:293] Top shape: 32 512 16 16 (4194304)
I0603 04:26:22.134042   861 net.cpp:301] Memory required for data: 1994097668
I0603 04:26:22.134047   861 layer_factory.hpp:114] Creating layer inception_4d/pool_proj
I0603 04:26:22.134064   861 net.cpp:201] Creating Layer inception_4d/pool_proj
I0603 04:26:22.134069   861 net.cpp:902] inception_4d/pool_proj <- inception_4d/pool
I0603 04:26:22.134078   861 net.cpp:876] inception_4d/pool_proj -> inception_4d/pool_proj
I0603 04:26:22.136214   861 net.cpp:286] Setting up inception_4d/pool_proj
I0603 04:26:22.136235   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.136241   861 net.cpp:301] Memory required for data: 1996194820
I0603 04:26:22.136253   861 layer_factory.hpp:114] Creating layer inception_4d/relu_pool_proj
I0603 04:26:22.136276   861 net.cpp:201] Creating Layer inception_4d/relu_pool_proj
I0603 04:26:22.136283   861 net.cpp:902] inception_4d/relu_pool_proj <- inception_4d/pool_proj
I0603 04:26:22.136291   861 net.cpp:863] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)
I0603 04:26:22.136315   861 net.cpp:286] Setting up inception_4d/relu_pool_proj
I0603 04:26:22.136325   861 net.cpp:293] Top shape: 32 64 16 16 (524288)
I0603 04:26:22.136330   861 net.cpp:301] Memory required for data: 1998291972
I0603 04:26:22.136337   861 layer_factory.hpp:114] Creating layer inception_4d/output
I0603 04:26:22.136346   861 net.cpp:201] Creating Layer inception_4d/output
I0603 04:26:22.136353   861 net.cpp:902] inception_4d/output <- inception_4d/1x1
I0603 04:26:22.136359   861 net.cpp:902] inception_4d/output <- inception_4d/3x3
I0603 04:26:22.136381   861 net.cpp:902] inception_4d/output <- inception_4d/5x5
I0603 04:26:22.136387   861 net.cpp:902] inception_4d/output <- inception_4d/pool_proj
I0603 04:26:22.136395   861 net.cpp:876] inception_4d/output -> inception_4d/output
I0603 04:26:22.136443   861 net.cpp:286] Setting up inception_4d/output
I0603 04:26:22.136452   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.136457   861 net.cpp:301] Memory required for data: 2015593476
I0603 04:26:22.136462   861 layer_factory.hpp:114] Creating layer inception_4d/output_inception_4d/output_0_split
I0603 04:26:22.136476   861 net.cpp:201] Creating Layer inception_4d/output_inception_4d/output_0_split
I0603 04:26:22.136482   861 net.cpp:902] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I0603 04:26:22.136490   861 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I0603 04:26:22.136499   861 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I0603 04:26:22.136509   861 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I0603 04:26:22.136518   861 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3
I0603 04:26:22.136528   861 net.cpp:876] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_4
I0603 04:26:22.136559   861 net.cpp:286] Setting up inception_4d/output_inception_4d/output_0_split
I0603 04:26:22.136569   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.136575   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.136581   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.136587   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.136593   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.136598   861 net.cpp:301] Memory required for data: 2102100996
I0603 04:26:22.136605   861 layer_factory.hpp:114] Creating layer loss2/ave_pool
I0603 04:26:22.136617   861 net.cpp:201] Creating Layer loss2/ave_pool
I0603 04:26:22.136623   861 net.cpp:902] loss2/ave_pool <- inception_4d/output_inception_4d/output_0_split_0
I0603 04:26:22.136631   861 net.cpp:876] loss2/ave_pool -> loss2/ave_pool
I0603 04:26:22.136652   861 net.cpp:286] Setting up loss2/ave_pool
I0603 04:26:22.136659   861 net.cpp:293] Top shape: 32 528 5 5 (422400)
I0603 04:26:22.136664   861 net.cpp:301] Memory required for data: 2103790596
I0603 04:26:22.136669   861 layer_factory.hpp:114] Creating layer loss2/conv
I0603 04:26:22.136688   861 net.cpp:201] Creating Layer loss2/conv
I0603 04:26:22.136694   861 net.cpp:902] loss2/conv <- loss2/ave_pool
I0603 04:26:22.136703   861 net.cpp:876] loss2/conv -> loss2/conv
I0603 04:26:22.139102   861 net.cpp:286] Setting up loss2/conv
I0603 04:26:22.139118   861 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:26:22.139124   861 net.cpp:301] Memory required for data: 2104200196
I0603 04:26:22.139135   861 layer_factory.hpp:114] Creating layer loss2/relu_conv
I0603 04:26:22.139153   861 net.cpp:201] Creating Layer loss2/relu_conv
I0603 04:26:22.139159   861 net.cpp:902] loss2/relu_conv <- loss2/conv
I0603 04:26:22.139168   861 net.cpp:863] loss2/relu_conv -> loss2/conv (in-place)
I0603 04:26:22.139191   861 net.cpp:286] Setting up loss2/relu_conv
I0603 04:26:22.139199   861 net.cpp:293] Top shape: 32 128 5 5 (102400)
I0603 04:26:22.139204   861 net.cpp:301] Memory required for data: 2104609796
I0603 04:26:22.139209   861 layer_factory.hpp:114] Creating layer loss2/fc
I0603 04:26:22.139226   861 net.cpp:201] Creating Layer loss2/fc
I0603 04:26:22.139231   861 net.cpp:902] loss2/fc <- loss2/conv
I0603 04:26:22.139242   861 net.cpp:876] loss2/fc -> loss2/fc
I0603 04:26:22.161700   861 net.cpp:286] Setting up loss2/fc
I0603 04:26:22.161721   861 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:26:22.161727   861 net.cpp:301] Memory required for data: 2104740868
I0603 04:26:22.161758   861 layer_factory.hpp:114] Creating layer loss2/relu_fc
I0603 04:26:22.161777   861 net.cpp:201] Creating Layer loss2/relu_fc
I0603 04:26:22.161783   861 net.cpp:902] loss2/relu_fc <- loss2/fc
I0603 04:26:22.161792   861 net.cpp:863] loss2/relu_fc -> loss2/fc (in-place)
I0603 04:26:22.161815   861 net.cpp:286] Setting up loss2/relu_fc
I0603 04:26:22.161824   861 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:26:22.161829   861 net.cpp:301] Memory required for data: 2104871940
I0603 04:26:22.161834   861 layer_factory.hpp:114] Creating layer loss2/drop_fc
I0603 04:26:22.161845   861 net.cpp:201] Creating Layer loss2/drop_fc
I0603 04:26:22.161851   861 net.cpp:902] loss2/drop_fc <- loss2/fc
I0603 04:26:22.161859   861 net.cpp:863] loss2/drop_fc -> loss2/fc (in-place)
I0603 04:26:22.161873   861 net.cpp:286] Setting up loss2/drop_fc
I0603 04:26:22.161880   861 net.cpp:293] Top shape: 32 1024 (32768)
I0603 04:26:22.161885   861 net.cpp:301] Memory required for data: 2105003012
I0603 04:26:22.161890   861 layer_factory.hpp:114] Creating layer loss2/classifier
I0603 04:26:22.161906   861 net.cpp:201] Creating Layer loss2/classifier
I0603 04:26:22.161911   861 net.cpp:902] loss2/classifier <- loss2/fc
I0603 04:26:22.161921   861 net.cpp:876] loss2/classifier -> loss2/classifier
I0603 04:26:22.161984   861 net.cpp:286] Setting up loss2/classifier
I0603 04:26:22.161994   861 net.cpp:293] Top shape: 32 3 (96)
I0603 04:26:22.161999   861 net.cpp:301] Memory required for data: 2105003396
I0603 04:26:22.162009   861 layer_factory.hpp:114] Creating layer loss2/loss
I0603 04:26:22.162021   861 net.cpp:201] Creating Layer loss2/loss
I0603 04:26:22.162027   861 net.cpp:902] loss2/loss <- loss2/classifier
I0603 04:26:22.162034   861 net.cpp:902] loss2/loss <- label_DataColor256_1_split_1
I0603 04:26:22.162042   861 net.cpp:876] loss2/loss -> loss2/loss
I0603 04:26:22.162055   861 layer_factory.hpp:114] Creating layer loss2/loss
I0603 04:26:22.162081   861 net.cpp:286] Setting up loss2/loss
I0603 04:26:22.162089   861 net.cpp:293] Top shape: (1)
I0603 04:26:22.162094   861 net.cpp:296]     with loss weight 0.3
I0603 04:26:22.162113   861 net.cpp:301] Memory required for data: 2105003400
I0603 04:26:22.162119   861 layer_factory.hpp:114] Creating layer inception_4e/1x1
I0603 04:26:22.162137   861 net.cpp:201] Creating Layer inception_4e/1x1
I0603 04:26:22.162142   861 net.cpp:902] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_1
I0603 04:26:22.162151   861 net.cpp:876] inception_4e/1x1 -> inception_4e/1x1
I0603 04:26:22.166363   861 net.cpp:286] Setting up inception_4e/1x1
I0603 04:26:22.166389   861 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:26:22.166395   861 net.cpp:301] Memory required for data: 2113392008
I0603 04:26:22.166409   861 layer_factory.hpp:114] Creating layer inception_4e/relu_1x1
I0603 04:26:22.166422   861 net.cpp:201] Creating Layer inception_4e/relu_1x1
I0603 04:26:22.166429   861 net.cpp:902] inception_4e/relu_1x1 <- inception_4e/1x1
I0603 04:26:22.166441   861 net.cpp:863] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)
I0603 04:26:22.166472   861 net.cpp:286] Setting up inception_4e/relu_1x1
I0603 04:26:22.166481   861 net.cpp:293] Top shape: 32 256 16 16 (2097152)
I0603 04:26:22.166486   861 net.cpp:301] Memory required for data: 2121780616
I0603 04:26:22.166491   861 layer_factory.hpp:114] Creating layer inception_4e/3x3_reduce
I0603 04:26:22.166513   861 net.cpp:201] Creating Layer inception_4e/3x3_reduce
I0603 04:26:22.166519   861 net.cpp:902] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_2
I0603 04:26:22.166532   861 net.cpp:876] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I0603 04:26:22.169214   861 net.cpp:286] Setting up inception_4e/3x3_reduce
I0603 04:26:22.169237   861 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:26:22.169242   861 net.cpp:301] Memory required for data: 2127023496
I0603 04:26:22.169255   861 layer_factory.hpp:114] Creating layer inception_4e/relu_3x3_reduce
I0603 04:26:22.169289   861 net.cpp:201] Creating Layer inception_4e/relu_3x3_reduce
I0603 04:26:22.169297   861 net.cpp:902] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce
I0603 04:26:22.169308   861 net.cpp:863] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)
I0603 04:26:22.169334   861 net.cpp:286] Setting up inception_4e/relu_3x3_reduce
I0603 04:26:22.169342   861 net.cpp:293] Top shape: 32 160 16 16 (1310720)
I0603 04:26:22.169348   861 net.cpp:301] Memory required for data: 2132266376
I0603 04:26:22.169353   861 layer_factory.hpp:114] Creating layer inception_4e/3x3
I0603 04:26:22.169375   861 net.cpp:201] Creating Layer inception_4e/3x3
I0603 04:26:22.169384   861 net.cpp:902] inception_4e/3x3 <- inception_4e/3x3_reduce
I0603 04:26:22.169394   861 net.cpp:876] inception_4e/3x3 -> inception_4e/3x3
I0603 04:26:22.177695   861 net.cpp:286] Setting up inception_4e/3x3
I0603 04:26:22.177721   861 net.cpp:293] Top shape: 32 320 16 16 (2621440)
I0603 04:26:22.177726   861 net.cpp:301] Memory required for data: 2142752136
I0603 04:26:22.177739   861 layer_factory.hpp:114] Creating layer inception_4e/relu_3x3
I0603 04:26:22.177754   861 net.cpp:201] Creating Layer inception_4e/relu_3x3
I0603 04:26:22.177762   861 net.cpp:902] inception_4e/relu_3x3 <- inception_4e/3x3
I0603 04:26:22.177773   861 net.cpp:863] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)
I0603 04:26:22.177798   861 net.cpp:286] Setting up inception_4e/relu_3x3
I0603 04:26:22.177805   861 net.cpp:293] Top shape: 32 320 16 16 (2621440)
I0603 04:26:22.177810   861 net.cpp:301] Memory required for data: 2153237896
I0603 04:26:22.177816   861 layer_factory.hpp:114] Creating layer inception_4e/5x5_reduce
I0603 04:26:22.177837   861 net.cpp:201] Creating Layer inception_4e/5x5_reduce
I0603 04:26:22.177844   861 net.cpp:902] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_3
I0603 04:26:22.177855   861 net.cpp:876] inception_4e/5x5_reduce -> inception_4e/5x5_reduce
I0603 04:26:22.179741   861 net.cpp:286] Setting up inception_4e/5x5_reduce
I0603 04:26:22.179764   861 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:26:22.179769   861 net.cpp:301] Memory required for data: 2154286472
I0603 04:26:22.179781   861 layer_factory.hpp:114] Creating layer inception_4e/relu_5x5_reduce
I0603 04:26:22.179796   861 net.cpp:201] Creating Layer inception_4e/relu_5x5_reduce
I0603 04:26:22.179803   861 net.cpp:902] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce
I0603 04:26:22.179812   861 net.cpp:863] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)
I0603 04:26:22.179833   861 net.cpp:286] Setting up inception_4e/relu_5x5_reduce
I0603 04:26:22.179841   861 net.cpp:293] Top shape: 32 32 16 16 (262144)
I0603 04:26:22.179846   861 net.cpp:301] Memory required for data: 2155335048
I0603 04:26:22.179852   861 layer_factory.hpp:114] Creating layer inception_4e/5x5
I0603 04:26:22.179873   861 net.cpp:201] Creating Layer inception_4e/5x5
I0603 04:26:22.179879   861 net.cpp:902] inception_4e/5x5 <- inception_4e/5x5_reduce
I0603 04:26:22.179889   861 net.cpp:876] inception_4e/5x5 -> inception_4e/5x5
I0603 04:26:22.183101   861 net.cpp:286] Setting up inception_4e/5x5
I0603 04:26:22.183125   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.183130   861 net.cpp:301] Memory required for data: 2159529352
I0603 04:26:22.183142   861 layer_factory.hpp:114] Creating layer inception_4e/relu_5x5
I0603 04:26:22.183156   861 net.cpp:201] Creating Layer inception_4e/relu_5x5
I0603 04:26:22.183164   861 net.cpp:902] inception_4e/relu_5x5 <- inception_4e/5x5
I0603 04:26:22.183172   861 net.cpp:863] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)
I0603 04:26:22.183193   861 net.cpp:286] Setting up inception_4e/relu_5x5
I0603 04:26:22.183202   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.183207   861 net.cpp:301] Memory required for data: 2163723656
I0603 04:26:22.183212   861 layer_factory.hpp:114] Creating layer inception_4e/pool
I0603 04:26:22.183223   861 net.cpp:201] Creating Layer inception_4e/pool
I0603 04:26:22.183248   861 net.cpp:902] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_4
I0603 04:26:22.183257   861 net.cpp:876] inception_4e/pool -> inception_4e/pool
I0603 04:26:22.183279   861 net.cpp:286] Setting up inception_4e/pool
I0603 04:26:22.183286   861 net.cpp:293] Top shape: 32 528 16 16 (4325376)
I0603 04:26:22.183290   861 net.cpp:301] Memory required for data: 2181025160
I0603 04:26:22.183296   861 layer_factory.hpp:114] Creating layer inception_4e/pool_proj
I0603 04:26:22.183315   861 net.cpp:201] Creating Layer inception_4e/pool_proj
I0603 04:26:22.183320   861 net.cpp:902] inception_4e/pool_proj <- inception_4e/pool
I0603 04:26:22.183329   861 net.cpp:876] inception_4e/pool_proj -> inception_4e/pool_proj
I0603 04:26:22.185962   861 net.cpp:286] Setting up inception_4e/pool_proj
I0603 04:26:22.185986   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.185992   861 net.cpp:301] Memory required for data: 2185219464
I0603 04:26:22.186002   861 layer_factory.hpp:114] Creating layer inception_4e/relu_pool_proj
I0603 04:26:22.186019   861 net.cpp:201] Creating Layer inception_4e/relu_pool_proj
I0603 04:26:22.186028   861 net.cpp:902] inception_4e/relu_pool_proj <- inception_4e/pool_proj
I0603 04:26:22.186036   861 net.cpp:863] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)
I0603 04:26:22.186063   861 net.cpp:286] Setting up inception_4e/relu_pool_proj
I0603 04:26:22.186070   861 net.cpp:293] Top shape: 32 128 16 16 (1048576)
I0603 04:26:22.186075   861 net.cpp:301] Memory required for data: 2189413768
I0603 04:26:22.186080   861 layer_factory.hpp:114] Creating layer inception_4e/output
I0603 04:26:22.186094   861 net.cpp:201] Creating Layer inception_4e/output
I0603 04:26:22.186100   861 net.cpp:902] inception_4e/output <- inception_4e/1x1
I0603 04:26:22.186107   861 net.cpp:902] inception_4e/output <- inception_4e/3x3
I0603 04:26:22.186113   861 net.cpp:902] inception_4e/output <- inception_4e/5x5
I0603 04:26:22.186120   861 net.cpp:902] inception_4e/output <- inception_4e/pool_proj
I0603 04:26:22.186130   861 net.cpp:876] inception_4e/output -> inception_4e/output
I0603 04:26:22.186174   861 net.cpp:286] Setting up inception_4e/output
I0603 04:26:22.186183   861 net.cpp:293] Top shape: 32 832 16 16 (6815744)
I0603 04:26:22.186188   861 net.cpp:301] Memory required for data: 2216676744
I0603 04:26:22.186193   861 layer_factory.hpp:114] Creating layer pool4/3x3_s2
I0603 04:26:22.186205   861 net.cpp:201] Creating Layer pool4/3x3_s2
I0603 04:26:22.186211   861 net.cpp:902] pool4/3x3_s2 <- inception_4e/output
I0603 04:26:22.186219   861 net.cpp:876] pool4/3x3_s2 -> pool4/3x3_s2
I0603 04:26:22.186238   861 net.cpp:286] Setting up pool4/3x3_s2
I0603 04:26:22.186244   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.186249   861 net.cpp:301] Memory required for data: 2223492488
I0603 04:26:22.186254   861 layer_factory.hpp:114] Creating layer pool4/3x3_s2_pool4/3x3_s2_0_split
I0603 04:26:22.186264   861 net.cpp:201] Creating Layer pool4/3x3_s2_pool4/3x3_s2_0_split
I0603 04:26:22.186292   861 net.cpp:902] pool4/3x3_s2_pool4/3x3_s2_0_split <- pool4/3x3_s2
I0603 04:26:22.186305   861 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_0
I0603 04:26:22.186314   861 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_1
I0603 04:26:22.186322   861 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_2
I0603 04:26:22.186331   861 net.cpp:876] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_3
I0603 04:26:22.186355   861 net.cpp:286] Setting up pool4/3x3_s2_pool4/3x3_s2_0_split
I0603 04:26:22.186365   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.186372   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.186378   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.186384   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.186389   861 net.cpp:301] Memory required for data: 2250755464
I0603 04:26:22.186414   861 layer_factory.hpp:114] Creating layer inception_5a/1x1
I0603 04:26:22.186434   861 net.cpp:201] Creating Layer inception_5a/1x1
I0603 04:26:22.186440   861 net.cpp:902] inception_5a/1x1 <- pool4/3x3_s2_pool4/3x3_s2_0_split_0
I0603 04:26:22.186450   861 net.cpp:876] inception_5a/1x1 -> inception_5a/1x1
I0603 04:26:22.191455   861 net.cpp:286] Setting up inception_5a/1x1
I0603 04:26:22.191478   861 net.cpp:293] Top shape: 32 256 8 8 (524288)
I0603 04:26:22.191484   861 net.cpp:301] Memory required for data: 2252852616
I0603 04:26:22.191496   861 layer_factory.hpp:114] Creating layer inception_5a/relu_1x1
I0603 04:26:22.191514   861 net.cpp:201] Creating Layer inception_5a/relu_1x1
I0603 04:26:22.191520   861 net.cpp:902] inception_5a/relu_1x1 <- inception_5a/1x1
I0603 04:26:22.191529   861 net.cpp:863] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)
I0603 04:26:22.191555   861 net.cpp:286] Setting up inception_5a/relu_1x1
I0603 04:26:22.191565   861 net.cpp:293] Top shape: 32 256 8 8 (524288)
I0603 04:26:22.191568   861 net.cpp:301] Memory required for data: 2254949768
I0603 04:26:22.191575   861 layer_factory.hpp:114] Creating layer inception_5a/3x3_reduce
I0603 04:26:22.191596   861 net.cpp:201] Creating Layer inception_5a/3x3_reduce
I0603 04:26:22.191602   861 net.cpp:902] inception_5a/3x3_reduce <- pool4/3x3_s2_pool4/3x3_s2_0_split_1
I0603 04:26:22.191614   861 net.cpp:876] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I0603 04:26:22.194536   861 net.cpp:286] Setting up inception_5a/3x3_reduce
I0603 04:26:22.194557   861 net.cpp:293] Top shape: 32 160 8 8 (327680)
I0603 04:26:22.194563   861 net.cpp:301] Memory required for data: 2256260488
I0603 04:26:22.194576   861 layer_factory.hpp:114] Creating layer inception_5a/relu_3x3_reduce
I0603 04:26:22.194589   861 net.cpp:201] Creating Layer inception_5a/relu_3x3_reduce
I0603 04:26:22.194597   861 net.cpp:902] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce
I0603 04:26:22.194605   861 net.cpp:863] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)
I0603 04:26:22.194627   861 net.cpp:286] Setting up inception_5a/relu_3x3_reduce
I0603 04:26:22.194634   861 net.cpp:293] Top shape: 32 160 8 8 (327680)
I0603 04:26:22.194639   861 net.cpp:301] Memory required for data: 2257571208
I0603 04:26:22.194644   861 layer_factory.hpp:114] Creating layer inception_5a/3x3
I0603 04:26:22.194664   861 net.cpp:201] Creating Layer inception_5a/3x3
I0603 04:26:22.194669   861 net.cpp:902] inception_5a/3x3 <- inception_5a/3x3_reduce
I0603 04:26:22.194679   861 net.cpp:876] inception_5a/3x3 -> inception_5a/3x3
I0603 04:26:22.201123   861 net.cpp:286] Setting up inception_5a/3x3
I0603 04:26:22.201146   861 net.cpp:293] Top shape: 32 320 8 8 (655360)
I0603 04:26:22.201153   861 net.cpp:301] Memory required for data: 2260192648
I0603 04:26:22.201164   861 layer_factory.hpp:114] Creating layer inception_5a/relu_3x3
I0603 04:26:22.201179   861 net.cpp:201] Creating Layer inception_5a/relu_3x3
I0603 04:26:22.201185   861 net.cpp:902] inception_5a/relu_3x3 <- inception_5a/3x3
I0603 04:26:22.201195   861 net.cpp:863] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)
I0603 04:26:22.201215   861 net.cpp:286] Setting up inception_5a/relu_3x3
I0603 04:26:22.201223   861 net.cpp:293] Top shape: 32 320 8 8 (655360)
I0603 04:26:22.201228   861 net.cpp:301] Memory required for data: 2262814088
I0603 04:26:22.201233   861 layer_factory.hpp:114] Creating layer inception_5a/5x5_reduce
I0603 04:26:22.201251   861 net.cpp:201] Creating Layer inception_5a/5x5_reduce
I0603 04:26:22.201257   861 net.cpp:902] inception_5a/5x5_reduce <- pool4/3x3_s2_pool4/3x3_s2_0_split_2
I0603 04:26:22.201267   861 net.cpp:876] inception_5a/5x5_reduce -> inception_5a/5x5_reduce
I0603 04:26:22.202827   861 net.cpp:286] Setting up inception_5a/5x5_reduce
I0603 04:26:22.202849   861 net.cpp:293] Top shape: 32 32 8 8 (65536)
I0603 04:26:22.202855   861 net.cpp:301] Memory required for data: 2263076232
I0603 04:26:22.202867   861 layer_factory.hpp:114] Creating layer inception_5a/relu_5x5_reduce
I0603 04:26:22.202898   861 net.cpp:201] Creating Layer inception_5a/relu_5x5_reduce
I0603 04:26:22.202906   861 net.cpp:902] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce
I0603 04:26:22.202915   861 net.cpp:863] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)
I0603 04:26:22.202935   861 net.cpp:286] Setting up inception_5a/relu_5x5_reduce
I0603 04:26:22.202944   861 net.cpp:293] Top shape: 32 32 8 8 (65536)
I0603 04:26:22.202947   861 net.cpp:301] Memory required for data: 2263338376
I0603 04:26:22.202953   861 layer_factory.hpp:114] Creating layer inception_5a/5x5
I0603 04:26:22.202972   861 net.cpp:201] Creating Layer inception_5a/5x5
I0603 04:26:22.202978   861 net.cpp:902] inception_5a/5x5 <- inception_5a/5x5_reduce
I0603 04:26:22.202987   861 net.cpp:876] inception_5a/5x5 -> inception_5a/5x5
I0603 04:26:22.205328   861 net.cpp:286] Setting up inception_5a/5x5
I0603 04:26:22.205349   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.205355   861 net.cpp:301] Memory required for data: 2264386952
I0603 04:26:22.205366   861 layer_factory.hpp:114] Creating layer inception_5a/relu_5x5
I0603 04:26:22.205381   861 net.cpp:201] Creating Layer inception_5a/relu_5x5
I0603 04:26:22.205389   861 net.cpp:902] inception_5a/relu_5x5 <- inception_5a/5x5
I0603 04:26:22.205401   861 net.cpp:863] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)
I0603 04:26:22.205436   861 net.cpp:286] Setting up inception_5a/relu_5x5
I0603 04:26:22.205445   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.205449   861 net.cpp:301] Memory required for data: 2265435528
I0603 04:26:22.205454   861 layer_factory.hpp:114] Creating layer inception_5a/pool
I0603 04:26:22.205468   861 net.cpp:201] Creating Layer inception_5a/pool
I0603 04:26:22.205474   861 net.cpp:902] inception_5a/pool <- pool4/3x3_s2_pool4/3x3_s2_0_split_3
I0603 04:26:22.205484   861 net.cpp:876] inception_5a/pool -> inception_5a/pool
I0603 04:26:22.205508   861 net.cpp:286] Setting up inception_5a/pool
I0603 04:26:22.205515   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.205520   861 net.cpp:301] Memory required for data: 2272251272
I0603 04:26:22.205525   861 layer_factory.hpp:114] Creating layer inception_5a/pool_proj
I0603 04:26:22.205549   861 net.cpp:201] Creating Layer inception_5a/pool_proj
I0603 04:26:22.205555   861 net.cpp:902] inception_5a/pool_proj <- inception_5a/pool
I0603 04:26:22.205566   861 net.cpp:876] inception_5a/pool_proj -> inception_5a/pool_proj
I0603 04:26:22.208587   861 net.cpp:286] Setting up inception_5a/pool_proj
I0603 04:26:22.208611   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.208616   861 net.cpp:301] Memory required for data: 2273299848
I0603 04:26:22.208628   861 layer_factory.hpp:114] Creating layer inception_5a/relu_pool_proj
I0603 04:26:22.208645   861 net.cpp:201] Creating Layer inception_5a/relu_pool_proj
I0603 04:26:22.208653   861 net.cpp:902] inception_5a/relu_pool_proj <- inception_5a/pool_proj
I0603 04:26:22.208662   861 net.cpp:863] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)
I0603 04:26:22.208689   861 net.cpp:286] Setting up inception_5a/relu_pool_proj
I0603 04:26:22.208698   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.208703   861 net.cpp:301] Memory required for data: 2274348424
I0603 04:26:22.208709   861 layer_factory.hpp:114] Creating layer inception_5a/output
I0603 04:26:22.208719   861 net.cpp:201] Creating Layer inception_5a/output
I0603 04:26:22.208725   861 net.cpp:902] inception_5a/output <- inception_5a/1x1
I0603 04:26:22.208732   861 net.cpp:902] inception_5a/output <- inception_5a/3x3
I0603 04:26:22.208739   861 net.cpp:902] inception_5a/output <- inception_5a/5x5
I0603 04:26:22.208745   861 net.cpp:902] inception_5a/output <- inception_5a/pool_proj
I0603 04:26:22.208755   861 net.cpp:876] inception_5a/output -> inception_5a/output
I0603 04:26:22.208809   861 net.cpp:286] Setting up inception_5a/output
I0603 04:26:22.208818   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.208842   861 net.cpp:301] Memory required for data: 2281164168
I0603 04:26:22.208848   861 layer_factory.hpp:114] Creating layer inception_5a/output_inception_5a/output_0_split
I0603 04:26:22.208863   861 net.cpp:201] Creating Layer inception_5a/output_inception_5a/output_0_split
I0603 04:26:22.208869   861 net.cpp:902] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0603 04:26:22.208878   861 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0603 04:26:22.208889   861 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0603 04:26:22.208897   861 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I0603 04:26:22.208906   861 net.cpp:876] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I0603 04:26:22.208933   861 net.cpp:286] Setting up inception_5a/output_inception_5a/output_0_split
I0603 04:26:22.208942   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.208948   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.208956   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.208961   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.208966   861 net.cpp:301] Memory required for data: 2308427144
I0603 04:26:22.208971   861 layer_factory.hpp:114] Creating layer inception_5b/1x1
I0603 04:26:22.208995   861 net.cpp:201] Creating Layer inception_5b/1x1
I0603 04:26:22.209002   861 net.cpp:902] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0603 04:26:22.209013   861 net.cpp:876] inception_5b/1x1 -> inception_5b/1x1
I0603 04:26:22.215709   861 net.cpp:286] Setting up inception_5b/1x1
I0603 04:26:22.215733   861 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:26:22.215739   861 net.cpp:301] Memory required for data: 2311572872
I0603 04:26:22.215750   861 layer_factory.hpp:114] Creating layer inception_5b/relu_1x1
I0603 04:26:22.215770   861 net.cpp:201] Creating Layer inception_5b/relu_1x1
I0603 04:26:22.215777   861 net.cpp:902] inception_5b/relu_1x1 <- inception_5b/1x1
I0603 04:26:22.215788   861 net.cpp:863] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)
I0603 04:26:22.215813   861 net.cpp:286] Setting up inception_5b/relu_1x1
I0603 04:26:22.215823   861 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:26:22.215828   861 net.cpp:301] Memory required for data: 2314718600
I0603 04:26:22.215833   861 layer_factory.hpp:114] Creating layer inception_5b/3x3_reduce
I0603 04:26:22.215857   861 net.cpp:201] Creating Layer inception_5b/3x3_reduce
I0603 04:26:22.215863   861 net.cpp:902] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I0603 04:26:22.215875   861 net.cpp:876] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I0603 04:26:22.219012   861 net.cpp:286] Setting up inception_5b/3x3_reduce
I0603 04:26:22.219039   861 net.cpp:293] Top shape: 32 192 8 8 (393216)
I0603 04:26:22.219046   861 net.cpp:301] Memory required for data: 2316291464
I0603 04:26:22.219058   861 layer_factory.hpp:114] Creating layer inception_5b/relu_3x3_reduce
I0603 04:26:22.219080   861 net.cpp:201] Creating Layer inception_5b/relu_3x3_reduce
I0603 04:26:22.219089   861 net.cpp:902] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce
I0603 04:26:22.219097   861 net.cpp:863] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)
I0603 04:26:22.219121   861 net.cpp:286] Setting up inception_5b/relu_3x3_reduce
I0603 04:26:22.219130   861 net.cpp:293] Top shape: 32 192 8 8 (393216)
I0603 04:26:22.219135   861 net.cpp:301] Memory required for data: 2317864328
I0603 04:26:22.219141   861 layer_factory.hpp:114] Creating layer inception_5b/3x3
I0603 04:26:22.219166   861 net.cpp:201] Creating Layer inception_5b/3x3
I0603 04:26:22.219172   861 net.cpp:902] inception_5b/3x3 <- inception_5b/3x3_reduce
I0603 04:26:22.219197   861 net.cpp:876] inception_5b/3x3 -> inception_5b/3x3
I0603 04:26:22.229079   861 net.cpp:286] Setting up inception_5b/3x3
I0603 04:26:22.229105   861 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:26:22.229111   861 net.cpp:301] Memory required for data: 2321010056
I0603 04:26:22.229123   861 layer_factory.hpp:114] Creating layer inception_5b/relu_3x3
I0603 04:26:22.229137   861 net.cpp:201] Creating Layer inception_5b/relu_3x3
I0603 04:26:22.229145   861 net.cpp:902] inception_5b/relu_3x3 <- inception_5b/3x3
I0603 04:26:22.229156   861 net.cpp:863] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)
I0603 04:26:22.229182   861 net.cpp:286] Setting up inception_5b/relu_3x3
I0603 04:26:22.229190   861 net.cpp:293] Top shape: 32 384 8 8 (786432)
I0603 04:26:22.229195   861 net.cpp:301] Memory required for data: 2324155784
I0603 04:26:22.229200   861 layer_factory.hpp:114] Creating layer inception_5b/5x5_reduce
I0603 04:26:22.229223   861 net.cpp:201] Creating Layer inception_5b/5x5_reduce
I0603 04:26:22.229229   861 net.cpp:902] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2
I0603 04:26:22.229241   861 net.cpp:876] inception_5b/5x5_reduce -> inception_5b/5x5_reduce
I0603 04:26:22.231165   861 net.cpp:286] Setting up inception_5b/5x5_reduce
I0603 04:26:22.231186   861 net.cpp:293] Top shape: 32 48 8 8 (98304)
I0603 04:26:22.231194   861 net.cpp:301] Memory required for data: 2324549000
I0603 04:26:22.231204   861 layer_factory.hpp:114] Creating layer inception_5b/relu_5x5_reduce
I0603 04:26:22.231220   861 net.cpp:201] Creating Layer inception_5b/relu_5x5_reduce
I0603 04:26:22.231227   861 net.cpp:902] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce
I0603 04:26:22.231238   861 net.cpp:863] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)
I0603 04:26:22.231264   861 net.cpp:286] Setting up inception_5b/relu_5x5_reduce
I0603 04:26:22.231272   861 net.cpp:293] Top shape: 32 48 8 8 (98304)
I0603 04:26:22.231277   861 net.cpp:301] Memory required for data: 2324942216
I0603 04:26:22.231283   861 layer_factory.hpp:114] Creating layer inception_5b/5x5
I0603 04:26:22.231305   861 net.cpp:201] Creating Layer inception_5b/5x5
I0603 04:26:22.231310   861 net.cpp:902] inception_5b/5x5 <- inception_5b/5x5_reduce
I0603 04:26:22.231323   861 net.cpp:876] inception_5b/5x5 -> inception_5b/5x5
I0603 04:26:22.234377   861 net.cpp:286] Setting up inception_5b/5x5
I0603 04:26:22.234397   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.234403   861 net.cpp:301] Memory required for data: 2325990792
I0603 04:26:22.234416   861 layer_factory.hpp:114] Creating layer inception_5b/relu_5x5
I0603 04:26:22.234432   861 net.cpp:201] Creating Layer inception_5b/relu_5x5
I0603 04:26:22.234441   861 net.cpp:902] inception_5b/relu_5x5 <- inception_5b/5x5
I0603 04:26:22.234448   861 net.cpp:863] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)
I0603 04:26:22.234474   861 net.cpp:286] Setting up inception_5b/relu_5x5
I0603 04:26:22.234483   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.234488   861 net.cpp:301] Memory required for data: 2327039368
I0603 04:26:22.234493   861 layer_factory.hpp:114] Creating layer inception_5b/pool
I0603 04:26:22.234508   861 net.cpp:201] Creating Layer inception_5b/pool
I0603 04:26:22.234513   861 net.cpp:902] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I0603 04:26:22.234522   861 net.cpp:876] inception_5b/pool -> inception_5b/pool
I0603 04:26:22.234549   861 net.cpp:286] Setting up inception_5b/pool
I0603 04:26:22.234556   861 net.cpp:293] Top shape: 32 832 8 8 (1703936)
I0603 04:26:22.234560   861 net.cpp:301] Memory required for data: 2333855112
I0603 04:26:22.234565   861 layer_factory.hpp:114] Creating layer inception_5b/pool_proj
I0603 04:26:22.234587   861 net.cpp:201] Creating Layer inception_5b/pool_proj
I0603 04:26:22.234593   861 net.cpp:902] inception_5b/pool_proj <- inception_5b/pool
I0603 04:26:22.234604   861 net.cpp:876] inception_5b/pool_proj -> inception_5b/pool_proj
I0603 04:26:22.237424   861 net.cpp:286] Setting up inception_5b/pool_proj
I0603 04:26:22.237447   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.237453   861 net.cpp:301] Memory required for data: 2334903688
I0603 04:26:22.237465   861 layer_factory.hpp:114] Creating layer inception_5b/relu_pool_proj
I0603 04:26:22.237479   861 net.cpp:201] Creating Layer inception_5b/relu_pool_proj
I0603 04:26:22.237486   861 net.cpp:902] inception_5b/relu_pool_proj <- inception_5b/pool_proj
I0603 04:26:22.237498   861 net.cpp:863] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)
I0603 04:26:22.237525   861 net.cpp:286] Setting up inception_5b/relu_pool_proj
I0603 04:26:22.237534   861 net.cpp:293] Top shape: 32 128 8 8 (262144)
I0603 04:26:22.237537   861 net.cpp:301] Memory required for data: 2335952264
I0603 04:26:22.237543   861 layer_factory.hpp:114] Creating layer inception_5b/output
I0603 04:26:22.237556   861 net.cpp:201] Creating Layer inception_5b/output
I0603 04:26:22.237562   861 net.cpp:902] inception_5b/output <- inception_5b/1x1
I0603 04:26:22.237570   861 net.cpp:902] inception_5b/output <- inception_5b/3x3
I0603 04:26:22.237576   861 net.cpp:902] inception_5b/output <- inception_5b/5x5
I0603 04:26:22.237582   861 net.cpp:902] inception_5b/output <- inception_5b/pool_proj
I0603 04:26:22.237589   861 net.cpp:876] inception_5b/output -> inception_5b/output
I0603 04:26:22.237638   861 net.cpp:286] Setting up inception_5b/output
I0603 04:26:22.237646   861 net.cpp:293] Top shape: 32 1024 8 8 (2097152)
I0603 04:26:22.237651   861 net.cpp:301] Memory required for data: 2344340872
I0603 04:26:22.237658   861 layer_factory.hpp:114] Creating layer pool5/7x7_s1
I0603 04:26:22.237668   861 net.cpp:201] Creating Layer pool5/7x7_s1
I0603 04:26:22.237674   861 net.cpp:902] pool5/7x7_s1 <- inception_5b/output
I0603 04:26:22.237684   861 net.cpp:876] pool5/7x7_s1 -> pool5/7x7_s1
I0603 04:26:22.237706   861 net.cpp:286] Setting up pool5/7x7_s1
I0603 04:26:22.237713   861 net.cpp:293] Top shape: 32 1024 2 2 (131072)
I0603 04:26:22.237718   861 net.cpp:301] Memory required for data: 2344865160
I0603 04:26:22.237723   861 layer_factory.hpp:114] Creating layer pool5/drop_7x7_s1
I0603 04:26:22.237735   861 net.cpp:201] Creating Layer pool5/drop_7x7_s1
I0603 04:26:22.237740   861 net.cpp:902] pool5/drop_7x7_s1 <- pool5/7x7_s1
I0603 04:26:22.237747   861 net.cpp:863] pool5/drop_7x7_s1 -> pool5/7x7_s1 (in-place)
I0603 04:26:22.237763   861 net.cpp:286] Setting up pool5/drop_7x7_s1
I0603 04:26:22.237771   861 net.cpp:293] Top shape: 32 1024 2 2 (131072)
I0603 04:26:22.237776   861 net.cpp:301] Memory required for data: 2345389448
I0603 04:26:22.237782   861 layer_factory.hpp:114] Creating layer loss3/classifier
I0603 04:26:22.237795   861 net.cpp:201] Creating Layer loss3/classifier
I0603 04:26:22.237800   861 net.cpp:902] loss3/classifier <- pool5/7x7_s1
I0603 04:26:22.237812   861 net.cpp:876] loss3/classifier -> loss3/classifier
I0603 04:26:22.237987   861 net.cpp:286] Setting up loss3/classifier
I0603 04:26:22.237998   861 net.cpp:293] Top shape: 32 3 (96)
I0603 04:26:22.238003   861 net.cpp:301] Memory required for data: 2345389832
I0603 04:26:22.238013   861 layer_factory.hpp:114] Creating layer loss3/classifier_loss3/classifier_0_split
I0603 04:26:22.238025   861 net.cpp:201] Creating Layer loss3/classifier_loss3/classifier_0_split
I0603 04:26:22.238031   861 net.cpp:902] loss3/classifier_loss3/classifier_0_split <- loss3/classifier
I0603 04:26:22.238041   861 net.cpp:876] loss3/classifier_loss3/classifier_0_split -> loss3/classifier_loss3/classifier_0_split_0
I0603 04:26:22.238050   861 net.cpp:876] loss3/classifier_loss3/classifier_0_split -> loss3/classifier_loss3/classifier_0_split_1
I0603 04:26:22.238072   861 net.cpp:286] Setting up loss3/classifier_loss3/classifier_0_split
I0603 04:26:22.238080   861 net.cpp:293] Top shape: 32 3 (96)
I0603 04:26:22.238085   861 net.cpp:293] Top shape: 32 3 (96)
I0603 04:26:22.238090   861 net.cpp:301] Memory required for data: 2345390600
I0603 04:26:22.238095   861 layer_factory.hpp:114] Creating layer loss3/loss
I0603 04:26:22.238121   861 net.cpp:201] Creating Layer loss3/loss
I0603 04:26:22.238131   861 net.cpp:902] loss3/loss <- loss3/classifier_loss3/classifier_0_split_0
I0603 04:26:22.238137   861 net.cpp:902] loss3/loss <- label_DataColor256_1_split_2
I0603 04:26:22.238145   861 net.cpp:876] loss3/loss -> loss
I0603 04:26:22.238157   861 layer_factory.hpp:114] Creating layer loss3/loss
I0603 04:26:22.238185   861 net.cpp:286] Setting up loss3/loss
I0603 04:26:22.238193   861 net.cpp:293] Top shape: (1)
I0603 04:26:22.238198   861 net.cpp:296]     with loss weight 1
I0603 04:26:22.238215   861 net.cpp:301] Memory required for data: 2345390604
I0603 04:26:22.238221   861 layer_factory.hpp:114] Creating layer accuracy
I0603 04:26:22.238229   861 net.cpp:201] Creating Layer accuracy
I0603 04:26:22.238234   861 net.cpp:902] accuracy <- loss3/classifier_loss3/classifier_0_split_1
I0603 04:26:22.238242   861 net.cpp:902] accuracy <- label_DataColor256_1_split_3
I0603 04:26:22.238250   861 net.cpp:876] accuracy -> accuracy
I0603 04:26:22.238262   861 net.cpp:286] Setting up accuracy
I0603 04:26:22.238287   861 net.cpp:293] Top shape: (1)
I0603 04:26:22.238294   861 net.cpp:301] Memory required for data: 2345390608
I0603 04:26:22.238298   861 net.cpp:365] accuracy does not need backward computation.
I0603 04:26:22.238304   861 net.cpp:363] loss3/loss needs backward computation.
I0603 04:26:22.238309   861 net.cpp:363] loss3/classifier_loss3/classifier_0_split needs backward computation.
I0603 04:26:22.238314   861 net.cpp:363] loss3/classifier needs backward computation.
I0603 04:26:22.238319   861 net.cpp:363] pool5/drop_7x7_s1 needs backward computation.
I0603 04:26:22.238324   861 net.cpp:363] pool5/7x7_s1 needs backward computation.
I0603 04:26:22.238329   861 net.cpp:363] inception_5b/output needs backward computation.
I0603 04:26:22.238335   861 net.cpp:363] inception_5b/relu_pool_proj needs backward computation.
I0603 04:26:22.238340   861 net.cpp:363] inception_5b/pool_proj needs backward computation.
I0603 04:26:22.238345   861 net.cpp:363] inception_5b/pool needs backward computation.
I0603 04:26:22.238350   861 net.cpp:363] inception_5b/relu_5x5 needs backward computation.
I0603 04:26:22.238355   861 net.cpp:363] inception_5b/5x5 needs backward computation.
I0603 04:26:22.238360   861 net.cpp:363] inception_5b/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238364   861 net.cpp:363] inception_5b/5x5_reduce needs backward computation.
I0603 04:26:22.238369   861 net.cpp:363] inception_5b/relu_3x3 needs backward computation.
I0603 04:26:22.238374   861 net.cpp:363] inception_5b/3x3 needs backward computation.
I0603 04:26:22.238379   861 net.cpp:363] inception_5b/relu_3x3_reduce needs backward computation.
I0603 04:26:22.238384   861 net.cpp:363] inception_5b/3x3_reduce needs backward computation.
I0603 04:26:22.238389   861 net.cpp:363] inception_5b/relu_1x1 needs backward computation.
I0603 04:26:22.238394   861 net.cpp:363] inception_5b/1x1 needs backward computation.
I0603 04:26:22.238399   861 net.cpp:363] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0603 04:26:22.238404   861 net.cpp:363] inception_5a/output needs backward computation.
I0603 04:26:22.238411   861 net.cpp:363] inception_5a/relu_pool_proj needs backward computation.
I0603 04:26:22.238416   861 net.cpp:363] inception_5a/pool_proj needs backward computation.
I0603 04:26:22.238422   861 net.cpp:363] inception_5a/pool needs backward computation.
I0603 04:26:22.238427   861 net.cpp:363] inception_5a/relu_5x5 needs backward computation.
I0603 04:26:22.238432   861 net.cpp:363] inception_5a/5x5 needs backward computation.
I0603 04:26:22.238437   861 net.cpp:363] inception_5a/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238443   861 net.cpp:363] inception_5a/5x5_reduce needs backward computation.
I0603 04:26:22.238448   861 net.cpp:363] inception_5a/relu_3x3 needs backward computation.
I0603 04:26:22.238453   861 net.cpp:363] inception_5a/3x3 needs backward computation.
I0603 04:26:22.238471   861 net.cpp:363] inception_5a/relu_3x3_reduce needs backward computation.
I0603 04:26:22.238476   861 net.cpp:363] inception_5a/3x3_reduce needs backward computation.
I0603 04:26:22.238482   861 net.cpp:363] inception_5a/relu_1x1 needs backward computation.
I0603 04:26:22.238487   861 net.cpp:363] inception_5a/1x1 needs backward computation.
I0603 04:26:22.238492   861 net.cpp:363] pool4/3x3_s2_pool4/3x3_s2_0_split needs backward computation.
I0603 04:26:22.238498   861 net.cpp:363] pool4/3x3_s2 needs backward computation.
I0603 04:26:22.238503   861 net.cpp:363] inception_4e/output needs backward computation.
I0603 04:26:22.238512   861 net.cpp:363] inception_4e/relu_pool_proj needs backward computation.
I0603 04:26:22.238517   861 net.cpp:363] inception_4e/pool_proj needs backward computation.
I0603 04:26:22.238523   861 net.cpp:363] inception_4e/pool needs backward computation.
I0603 04:26:22.238528   861 net.cpp:363] inception_4e/relu_5x5 needs backward computation.
I0603 04:26:22.238533   861 net.cpp:363] inception_4e/5x5 needs backward computation.
I0603 04:26:22.238538   861 net.cpp:363] inception_4e/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238543   861 net.cpp:363] inception_4e/5x5_reduce needs backward computation.
I0603 04:26:22.238549   861 net.cpp:363] inception_4e/relu_3x3 needs backward computation.
I0603 04:26:22.238554   861 net.cpp:363] inception_4e/3x3 needs backward computation.
I0603 04:26:22.238560   861 net.cpp:363] inception_4e/relu_3x3_reduce needs backward computation.
I0603 04:26:22.238565   861 net.cpp:363] inception_4e/3x3_reduce needs backward computation.
I0603 04:26:22.238570   861 net.cpp:363] inception_4e/relu_1x1 needs backward computation.
I0603 04:26:22.238575   861 net.cpp:363] inception_4e/1x1 needs backward computation.
I0603 04:26:22.238581   861 net.cpp:363] loss2/loss needs backward computation.
I0603 04:26:22.238589   861 net.cpp:363] loss2/classifier needs backward computation.
I0603 04:26:22.238595   861 net.cpp:363] loss2/drop_fc needs backward computation.
I0603 04:26:22.238600   861 net.cpp:363] loss2/relu_fc needs backward computation.
I0603 04:26:22.238605   861 net.cpp:363] loss2/fc needs backward computation.
I0603 04:26:22.238610   861 net.cpp:363] loss2/relu_conv needs backward computation.
I0603 04:26:22.238615   861 net.cpp:363] loss2/conv needs backward computation.
I0603 04:26:22.238621   861 net.cpp:363] loss2/ave_pool needs backward computation.
I0603 04:26:22.238626   861 net.cpp:363] inception_4d/output_inception_4d/output_0_split needs backward computation.
I0603 04:26:22.238632   861 net.cpp:363] inception_4d/output needs backward computation.
I0603 04:26:22.238639   861 net.cpp:363] inception_4d/relu_pool_proj needs backward computation.
I0603 04:26:22.238646   861 net.cpp:363] inception_4d/pool_proj needs backward computation.
I0603 04:26:22.238651   861 net.cpp:363] inception_4d/pool needs backward computation.
I0603 04:26:22.238656   861 net.cpp:363] inception_4d/relu_5x5 needs backward computation.
I0603 04:26:22.238662   861 net.cpp:363] inception_4d/5x5 needs backward computation.
I0603 04:26:22.238670   861 net.cpp:363] inception_4d/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238677   861 net.cpp:363] inception_4d/5x5_reduce needs backward computation.
I0603 04:26:22.238682   861 net.cpp:363] inception_4d/relu_3x3 needs backward computation.
I0603 04:26:22.238687   861 net.cpp:363] inception_4d/3x3 needs backward computation.
I0603 04:26:22.238692   861 net.cpp:363] inception_4d/relu_3x3_reduce needs backward computation.
I0603 04:26:22.238698   861 net.cpp:363] inception_4d/3x3_reduce needs backward computation.
I0603 04:26:22.238703   861 net.cpp:363] inception_4d/relu_1x1 needs backward computation.
I0603 04:26:22.238708   861 net.cpp:363] inception_4d/1x1 needs backward computation.
I0603 04:26:22.238714   861 net.cpp:363] inception_4c/output_inception_4c/output_0_split needs backward computation.
I0603 04:26:22.238720   861 net.cpp:363] inception_4c/output needs backward computation.
I0603 04:26:22.238735   861 net.cpp:363] inception_4c/relu_pool_proj needs backward computation.
I0603 04:26:22.238741   861 net.cpp:363] inception_4c/pool_proj needs backward computation.
I0603 04:26:22.238746   861 net.cpp:363] inception_4c/pool needs backward computation.
I0603 04:26:22.238752   861 net.cpp:363] inception_4c/relu_5x5 needs backward computation.
I0603 04:26:22.238757   861 net.cpp:363] inception_4c/5x5 needs backward computation.
I0603 04:26:22.238764   861 net.cpp:363] inception_4c/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238768   861 net.cpp:363] inception_4c/5x5_reduce needs backward computation.
I0603 04:26:22.238775   861 net.cpp:363] inception_4c/relu_3x3 needs backward computation.
I0603 04:26:22.238780   861 net.cpp:363] inception_4c/3x3 needs backward computation.
I0603 04:26:22.238785   861 net.cpp:363] inception_4c/relu_3x3_reduce needs backward computation.
I0603 04:26:22.238790   861 net.cpp:363] inception_4c/3x3_reduce needs backward computation.
I0603 04:26:22.238795   861 net.cpp:363] inception_4c/relu_1x1 needs backward computation.
I0603 04:26:22.238801   861 net.cpp:363] inception_4c/1x1 needs backward computation.
I0603 04:26:22.238806   861 net.cpp:363] inception_4b/output_inception_4b/output_0_split needs backward computation.
I0603 04:26:22.238811   861 net.cpp:363] inception_4b/output needs backward computation.
I0603 04:26:22.238819   861 net.cpp:363] inception_4b/relu_pool_proj needs backward computation.
I0603 04:26:22.238824   861 net.cpp:363] inception_4b/pool_proj needs backward computation.
I0603 04:26:22.238831   861 net.cpp:363] inception_4b/pool needs backward computation.
I0603 04:26:22.238836   861 net.cpp:363] inception_4b/relu_5x5 needs backward computation.
I0603 04:26:22.238840   861 net.cpp:363] inception_4b/5x5 needs backward computation.
I0603 04:26:22.238847   861 net.cpp:363] inception_4b/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238852   861 net.cpp:363] inception_4b/5x5_reduce needs backward computation.
I0603 04:26:22.238857   861 net.cpp:363] inception_4b/relu_3x3 needs backward computation.
I0603 04:26:22.238862   861 net.cpp:363] inception_4b/3x3 needs backward computation.
I0603 04:26:22.238868   861 net.cpp:363] inception_4b/relu_3x3_reduce needs backward computation.
I0603 04:26:22.238873   861 net.cpp:363] inception_4b/3x3_reduce needs backward computation.
I0603 04:26:22.238878   861 net.cpp:363] inception_4b/relu_1x1 needs backward computation.
I0603 04:26:22.238884   861 net.cpp:363] inception_4b/1x1 needs backward computation.
I0603 04:26:22.238889   861 net.cpp:363] loss1/loss needs backward computation.
I0603 04:26:22.238896   861 net.cpp:363] loss1/classifier needs backward computation.
I0603 04:26:22.238903   861 net.cpp:363] loss1/drop_fc needs backward computation.
I0603 04:26:22.238907   861 net.cpp:363] loss1/relu_fc needs backward computation.
I0603 04:26:22.238912   861 net.cpp:363] loss1/fc needs backward computation.
I0603 04:26:22.238919   861 net.cpp:363] loss1/relu_conv needs backward computation.
I0603 04:26:22.238926   861 net.cpp:363] loss1/conv needs backward computation.
I0603 04:26:22.238931   861 net.cpp:363] loss1/ave_pool needs backward computation.
I0603 04:26:22.238937   861 net.cpp:363] inception_4a/output_inception_4a/output_0_split needs backward computation.
I0603 04:26:22.238943   861 net.cpp:363] inception_4a/output needs backward computation.
I0603 04:26:22.238950   861 net.cpp:363] inception_4a/relu_pool_proj needs backward computation.
I0603 04:26:22.238956   861 net.cpp:363] inception_4a/pool_proj needs backward computation.
I0603 04:26:22.238962   861 net.cpp:363] inception_4a/pool needs backward computation.
I0603 04:26:22.238967   861 net.cpp:363] inception_4a/relu_5x5 needs backward computation.
I0603 04:26:22.238973   861 net.cpp:363] inception_4a/5x5 needs backward computation.
I0603 04:26:22.238978   861 net.cpp:363] inception_4a/relu_5x5_reduce needs backward computation.
I0603 04:26:22.238984   861 net.cpp:363] inception_4a/5x5_reduce needs backward computation.
I0603 04:26:22.238998   861 net.cpp:363] inception_4a/relu_3x3 needs backward computation.
I0603 04:26:22.239004   861 net.cpp:363] inception_4a/3x3 needs backward computation.
I0603 04:26:22.239009   861 net.cpp:363] inception_4a/relu_3x3_reduce needs backward computation.
I0603 04:26:22.239015   861 net.cpp:363] inception_4a/3x3_reduce needs backward computation.
I0603 04:26:22.239020   861 net.cpp:363] inception_4a/relu_1x1 needs backward computation.
I0603 04:26:22.239025   861 net.cpp:363] inception_4a/1x1 needs backward computation.
I0603 04:26:22.239032   861 net.cpp:363] pool3/3x3_s2_pool3/3x3_s2_0_split needs backward computation.
I0603 04:26:22.239037   861 net.cpp:363] pool3/3x3_s2 needs backward computation.
I0603 04:26:22.239042   861 net.cpp:363] inception_3b/output needs backward computation.
I0603 04:26:22.239050   861 net.cpp:363] inception_3b/relu_pool_proj needs backward computation.
I0603 04:26:22.239056   861 net.cpp:363] inception_3b/pool_proj needs backward computation.
I0603 04:26:22.239061   861 net.cpp:363] inception_3b/pool needs backward computation.
I0603 04:26:22.239068   861 net.cpp:363] inception_3b/relu_5x5 needs backward computation.
I0603 04:26:22.239073   861 net.cpp:363] inception_3b/5x5 needs backward computation.
I0603 04:26:22.239078   861 net.cpp:363] inception_3b/relu_5x5_reduce needs backward computation.
I0603 04:26:22.239084   861 net.cpp:363] inception_3b/5x5_reduce needs backward computation.
I0603 04:26:22.239089   861 net.cpp:363] inception_3b/relu_3x3 needs backward computation.
I0603 04:26:22.239094   861 net.cpp:363] inception_3b/3x3 needs backward computation.
I0603 04:26:22.239099   861 net.cpp:363] inception_3b/relu_3x3_reduce needs backward computation.
I0603 04:26:22.239104   861 net.cpp:363] inception_3b/3x3_reduce needs backward computation.
I0603 04:26:22.239110   861 net.cpp:363] inception_3b/relu_1x1 needs backward computation.
I0603 04:26:22.239115   861 net.cpp:363] inception_3b/1x1 needs backward computation.
I0603 04:26:22.239121   861 net.cpp:363] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0603 04:26:22.239126   861 net.cpp:363] inception_3a/output needs backward computation.
I0603 04:26:22.239133   861 net.cpp:363] inception_3a/relu_pool_proj needs backward computation.
I0603 04:26:22.239140   861 net.cpp:363] inception_3a/pool_proj needs backward computation.
I0603 04:26:22.239145   861 net.cpp:363] inception_3a/pool needs backward computation.
I0603 04:26:22.239151   861 net.cpp:363] inception_3a/relu_5x5 needs backward computation.
I0603 04:26:22.239156   861 net.cpp:363] inception_3a/5x5 needs backward computation.
I0603 04:26:22.239162   861 net.cpp:363] inception_3a/relu_5x5_reduce needs backward computation.
I0603 04:26:22.239167   861 net.cpp:363] inception_3a/5x5_reduce needs backward computation.
I0603 04:26:22.239173   861 net.cpp:363] inception_3a/relu_3x3 needs backward computation.
I0603 04:26:22.239179   861 net.cpp:363] inception_3a/3x3 needs backward computation.
I0603 04:26:22.239186   861 net.cpp:363] inception_3a/relu_3x3_reduce needs backward computation.
I0603 04:26:22.239190   861 net.cpp:363] inception_3a/3x3_reduce needs backward computation.
I0603 04:26:22.239197   861 net.cpp:363] inception_3a/relu_1x1 needs backward computation.
I0603 04:26:22.239202   861 net.cpp:363] inception_3a/1x1 needs backward computation.
I0603 04:26:22.239207   861 net.cpp:363] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I0603 04:26:22.239212   861 net.cpp:363] pool2/3x3_s2 needs backward computation.
I0603 04:26:22.239218   861 net.cpp:363] conv2/norm2 needs backward computation.
I0603 04:26:22.239223   861 net.cpp:363] conv2/relu_3x3 needs backward computation.
I0603 04:26:22.239228   861 net.cpp:363] conv2/3x3 needs backward computation.
I0603 04:26:22.239234   861 net.cpp:363] conv2/relu_3x3_reduce needs backward computation.
I0603 04:26:22.239239   861 net.cpp:363] conv2/3x3_reduce needs backward computation.
I0603 04:26:22.239245   861 net.cpp:363] pool1/norm1 needs backward computation.
I0603 04:26:22.239259   861 net.cpp:363] pool1/3x3_s2 needs backward computation.
I0603 04:26:22.239264   861 net.cpp:363] conv1/relu_7x7 needs backward computation.
I0603 04:26:22.239270   861 net.cpp:363] conv1/7x7_s2 needs backward computation.
I0603 04:26:22.239277   861 net.cpp:365] label_DataColor256_1_split does not need backward computation.
I0603 04:26:22.239284   861 net.cpp:365] DataColor256 does not need backward computation.
I0603 04:26:22.239289   861 net.cpp:407] This network produces output accuracy
I0603 04:26:22.239295   861 net.cpp:407] This network produces output loss
I0603 04:26:22.239300   861 net.cpp:407] This network produces output loss1/loss
I0603 04:26:22.239308   861 net.cpp:407] This network produces output loss2/loss
Rank:0: Finalize:ComputeOp: DataColor256(0) - 0 in, 2 out, 0 wts, 32 localMB, 0 gMBOff
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
Rank:0: Finalize:ComputeOp: label_DataColor256_1_split(1) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 0: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 2: GLen:1 LLen:1 GOff:0 NeedComms:False
OFM 3: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:26:22.239728   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 1, bottom_id 0, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: conv1/7x7_s2(2) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.239745   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 2, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: conv1/relu_7x7(3) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.239758   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 3, bottom_id 0, calculated bottom_size 134217728, real bottom_size 134217728
Rank:0: Finalize:ComputeOp: pool1/3x3_s2(4) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.239768   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 4, bottom_id 0, calculated bottom_size 134217728, real bottom_size 134217728
Rank:0: Finalize:ComputeOp: pool1/norm1(5) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.239778   861 net.cpp:470] InitNet: check bottom sizes for layer LRN, layer_id 5, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/3x3_reduce(6) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:4096 LLen:4096 GOff:0 OLen: 4096 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.239794   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 6, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/relu_3x3_reduce(7) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.239804   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 7, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/3x3(8) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:26:22.239816   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 8, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: conv2/relu_3x3(9) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.239826   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 9, bottom_id 0, calculated bottom_size 100663296, real bottom_size 100663296
Rank:0: Finalize:ComputeOp: conv2/norm2(10) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.239836   861 net.cpp:470] InitNet: check bottom sizes for layer LRN, layer_id 10, bottom_id 0, calculated bottom_size 100663296, real bottom_size 100663296
Rank:0: Finalize:ComputeOp: pool2/3x3_s2(11) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.239846   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 11, bottom_id 0, calculated bottom_size 100663296, real bottom_size 100663296
Rank:0: Finalize:ComputeOp: pool2/3x3_s2_pool2/3x3_s2_0_split(12) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 1: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 2: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 3: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.239858   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 12, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/1x1(13) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.239871   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 13, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_1x1(14) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.239882   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 14, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_3a/3x3_reduce(15) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
WT 0: GLen:18432 LLen:18432 GOff:0 OLen: 18432 OOff:0 NeedComms:False 
WT 1: GLen:96 LLen:96 GOff:0 OLen: 96 OOff:0 NeedComms:False 
I0603 04:26:22.239894   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 15, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_3x3_reduce(16) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
I0603 04:26:22.239905   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 16, bottom_id 0, calculated bottom_size 12582912, real bottom_size 12582912
Rank:0: Finalize:ComputeOp: inception_3a/3x3(17) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.239917   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 17, bottom_id 0, calculated bottom_size 12582912, real bottom_size 12582912
Rank:0: Finalize:ComputeOp: inception_3a/relu_3x3(18) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.239928   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 18, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3a/5x5_reduce(19) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:16 LLen:16 GOff:0 OLen: 16 OOff:0 NeedComms:False 
I0603 04:26:22.239940   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 19, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_5x5_reduce(20) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
I0603 04:26:22.239951   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 20, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_3a/5x5(21) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:512 LLen:512 GOff:0 OLen: 512 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:26:22.239974   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 21, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_3a/relu_5x5(22) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:26:22.239984   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 22, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3a/pool(23) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.239995   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 23, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/pool_proj(24) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:6144 LLen:6144 GOff:0 OLen: 6144 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:26:22.240007   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 24, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3a/relu_pool_proj(25) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:26:22.240018   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 25, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3a/output(27) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 1: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 2: GLen:32 LLen:32 GOff:0 NeedComms:False
IFM 3: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:26:22.240031   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
I0603 04:26:22.240036   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 1, calculated bottom_size 16777216, real bottom_size 16777216
I0603 04:26:22.240041   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 2, calculated bottom_size 4194304, real bottom_size 4194304
I0603 04:26:22.240046   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 26, bottom_id 3, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3a/output_inception_3a/output_0_split(28) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 1: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 2: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 3: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:26:22.240058   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 27, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/1x1(29) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.240070   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 28, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_1x1(30) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.240080   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 29, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3b/3x3_reduce(31) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.240092   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 30, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_3x3_reduce(32) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.240103   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 31, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3b/3x3(33) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:24576 LLen:24576 GOff:0 OLen: 24576 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:26:22.240116   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 32, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_3b/relu_3x3(34) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.240128   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 33, bottom_id 0, calculated bottom_size 25165824, real bottom_size 25165824
Rank:0: Finalize:ComputeOp: inception_3b/5x5_reduce(35) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:8192 LLen:8192 GOff:0 OLen: 8192 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:26:22.240139   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 34, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_5x5_reduce(36) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:26:22.240149   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 35, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3b/5x5(37) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:96 LLen:96 GOff:0 OLen: 96 OOff:0 NeedComms:False 
I0603 04:26:22.240161   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 36, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_3b/relu_5x5(38) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
I0603 04:26:22.240171   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 37, bottom_id 0, calculated bottom_size 12582912, real bottom_size 12582912
Rank:0: Finalize:ComputeOp: inception_3b/pool(39) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:26:22.240181   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 38, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/pool_proj(40) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:16384 LLen:16384 GOff:0 OLen: 16384 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.240193   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 39, bottom_id 0, calculated bottom_size 33554432, real bottom_size 33554432
Rank:0: Finalize:ComputeOp: inception_3b/relu_pool_proj(41) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.240205   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 40, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_3b/output(43) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 1: GLen:192 LLen:192 GOff:0 NeedComms:False
IFM 2: GLen:96 LLen:96 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:26:22.240226   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
I0603 04:26:22.240231   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 1, calculated bottom_size 25165824, real bottom_size 25165824
I0603 04:26:22.240236   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 2, calculated bottom_size 12582912, real bottom_size 12582912
I0603 04:26:22.240241   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 41, bottom_id 3, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: pool3/3x3_s2(44) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:26:22.240250   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 42, bottom_id 0, calculated bottom_size 62914560, real bottom_size 62914560
Rank:0: Finalize:ComputeOp: pool3/3x3_s2_pool3/3x3_s2_0_split(45) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 1: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 2: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 3: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:26:22.240262   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 43, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/1x1(46) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:92160 LLen:92160 GOff:0 OLen: 92160 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:26:22.240274   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 44, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_1x1(47) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.240285   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 45, bottom_id 0, calculated bottom_size 6291456, real bottom_size 6291456
Rank:0: Finalize:ComputeOp: inception_4a/3x3_reduce(48) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
WT 0: GLen:46080 LLen:46080 GOff:0 OLen: 46080 OOff:0 NeedComms:False 
WT 1: GLen:96 LLen:96 GOff:0 OLen: 96 OOff:0 NeedComms:False 
I0603 04:26:22.240298   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 46, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_3x3_reduce(49) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
I0603 04:26:22.240309   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 47, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_4a/3x3(50) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:96 LLen:96 GOff:0 NeedComms:False
OFM 0: GLen:208 LLen:208 GOff:0 NeedComms:False
WT 0: GLen:19968 LLen:19968 GOff:0 OLen: 19968 OOff:0 NeedComms:False 
WT 1: GLen:208 LLen:208 GOff:0 OLen: 208 OOff:0 NeedComms:False 
I0603 04:26:22.240320   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 48, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_4a/relu_3x3(51) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:208 LLen:208 GOff:0 NeedComms:False
OFM 0: GLen:208 LLen:208 GOff:0 NeedComms:False
I0603 04:26:22.240331   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 49, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_4a/5x5_reduce(52) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
WT 0: GLen:7680 LLen:7680 GOff:0 OLen: 7680 OOff:0 NeedComms:False 
WT 1: GLen:16 LLen:16 GOff:0 OLen: 16 OOff:0 NeedComms:False 
I0603 04:26:22.240344   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 50, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_5x5_reduce(53) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
I0603 04:26:22.240353   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 51, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: inception_4a/5x5(54) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:16 LLen:16 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
WT 0: GLen:768 LLen:768 GOff:0 OLen: 768 OOff:0 NeedComms:False 
WT 1: GLen:48 LLen:48 GOff:0 OLen: 48 OOff:0 NeedComms:False 
I0603 04:26:22.240365   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 52, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: inception_4a/relu_5x5(55) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
I0603 04:26:22.240376   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 53, bottom_id 0, calculated bottom_size 1572864, real bottom_size 1572864
Rank:0: Finalize:ComputeOp: inception_4a/pool(56) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
I0603 04:26:22.240386   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 54, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/pool_proj(57) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:480 LLen:480 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:30720 LLen:30720 GOff:0 OLen: 30720 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.240399   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 55, bottom_id 0, calculated bottom_size 15728640, real bottom_size 15728640
Rank:0: Finalize:ComputeOp: inception_4a/relu_pool_proj(58) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.240409   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 56, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4a/output(60) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
IFM 1: GLen:208 LLen:208 GOff:0 NeedComms:False
IFM 2: GLen:48 LLen:48 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240422   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 0, calculated bottom_size 6291456, real bottom_size 6291456
I0603 04:26:22.240427   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 1, calculated bottom_size 6815744, real bottom_size 6815744
I0603 04:26:22.240432   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 2, calculated bottom_size 1572864, real bottom_size 1572864
I0603 04:26:22.240437   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 57, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4a/output_inception_4a/output_0_split(61) - 1 in, 5 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 1: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 2: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 3: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 4: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240450   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 58, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: loss1/ave_pool(62) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240468   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 59, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: loss1/conv(63) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:65536 LLen:65536 GOff:0 OLen: 65536 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.240481   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 60, bottom_id 0, calculated bottom_size 1638400, real bottom_size 1638400
Rank:0: Finalize:ComputeOp: loss1/relu_conv(64) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.240491   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 61, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss1/fc(65) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
WT 0: GLen:3276800 LLen:3276800 GOff:0 OLen: 3276800 OOff:0 NeedComms:False 
WT 1: GLen:1024 LLen:1024 GOff:0 OLen: 1024 OOff:0 NeedComms:False 
I0603 04:26:22.240504   861 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 62, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss1/relu_fc(66) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.240514   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 63, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss1/drop_fc(67) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.240525   861 net.cpp:470] InitNet: check bottom sizes for layer Dropout, layer_id 64, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss1/classifier(68) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:3 LLen:3 GOff:0 OLen: 3 OOff:0 NeedComms:False 
I0603 04:26:22.240537   861 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 65, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss1/loss(69) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:26:22.240548   861 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 66, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:26:22.240553   861 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 66, bottom_id 1, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: inception_4b/1x1(70) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
WT 0: GLen:81920 LLen:81920 GOff:0 OLen: 81920 OOff:0 NeedComms:False 
WT 1: GLen:160 LLen:160 GOff:0 OLen: 160 OOff:0 NeedComms:False 
I0603 04:26:22.240566   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 67, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_1x1(71) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
I0603 04:26:22.240576   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 68, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
Rank:0: Finalize:ComputeOp: inception_4b/3x3_reduce(72) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
WT 0: GLen:57344 LLen:57344 GOff:0 OLen: 57344 OOff:0 NeedComms:False 
WT 1: GLen:112 LLen:112 GOff:0 OLen: 112 OOff:0 NeedComms:False 
I0603 04:26:22.240587   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 69, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_3x3_reduce(73) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
I0603 04:26:22.240597   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 70, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
Rank:0: Finalize:ComputeOp: inception_4b/3x3(74) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
OFM 0: GLen:224 LLen:224 GOff:0 NeedComms:False
WT 0: GLen:25088 LLen:25088 GOff:0 OLen: 25088 OOff:0 NeedComms:False 
WT 1: GLen:224 LLen:224 GOff:0 OLen: 224 OOff:0 NeedComms:False 
I0603 04:26:22.240610   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 71, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
Rank:0: Finalize:ComputeOp: inception_4b/relu_3x3(75) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:224 LLen:224 GOff:0 NeedComms:False
OFM 0: GLen:224 LLen:224 GOff:0 NeedComms:False
I0603 04:26:22.240620   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 72, bottom_id 0, calculated bottom_size 7340032, real bottom_size 7340032
Rank:0: Finalize:ComputeOp: inception_4b/5x5_reduce(76) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:24 LLen:24 GOff:0 OLen: 24 OOff:0 NeedComms:False 
I0603 04:26:22.240633   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 73, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_5x5_reduce(77) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
I0603 04:26:22.240643   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 74, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4b/5x5(78) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:1536 LLen:1536 GOff:0 OLen: 1536 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.240656   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 75, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4b/relu_5x5(79) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.240666   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 76, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4b/pool(80) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240675   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 77, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/pool_proj(81) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.240687   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 78, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4b/relu_pool_proj(82) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.240697   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 79, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4b/output(84) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
IFM 1: GLen:224 LLen:224 GOff:0 NeedComms:False
IFM 2: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240710   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
I0603 04:26:22.240715   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 1, calculated bottom_size 7340032, real bottom_size 7340032
I0603 04:26:22.240728   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 2, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:26:22.240733   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 80, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4b/output_inception_4b/output_0_split(85) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 1: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 2: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 3: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240746   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 81, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/1x1(86) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:65536 LLen:65536 GOff:0 OLen: 65536 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.240758   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 82, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_1x1(87) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.240769   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 83, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4c/3x3_reduce(88) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:65536 LLen:65536 GOff:0 OLen: 65536 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.240782   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 84, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_3x3_reduce(89) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.240797   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 85, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4c/3x3(90) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:256 LLen:256 GOff:0 OLen: 256 OOff:0 NeedComms:False 
I0603 04:26:22.240808   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 86, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4c/relu_3x3(91) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:26:22.240819   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 87, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_4c/5x5_reduce(92) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:24 LLen:24 GOff:0 OLen: 24 OOff:0 NeedComms:False 
I0603 04:26:22.240831   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 88, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_5x5_reduce(93) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
I0603 04:26:22.240842   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 89, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4c/5x5(94) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:24 LLen:24 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:1536 LLen:1536 GOff:0 OLen: 1536 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.240854   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 90, bottom_id 0, calculated bottom_size 786432, real bottom_size 786432
Rank:0: Finalize:ComputeOp: inception_4c/relu_5x5(95) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.240864   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 91, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4c/pool(96) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240873   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 92, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/pool_proj(97) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.240883   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 93, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4c/relu_pool_proj(98) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.240895   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 94, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4c/output(100) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 1: GLen:256 LLen:256 GOff:0 NeedComms:False
IFM 2: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240907   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
I0603 04:26:22.240912   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 1, calculated bottom_size 8388608, real bottom_size 8388608
I0603 04:26:22.240917   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 2, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:26:22.240922   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 95, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4c/output_inception_4c/output_0_split(101) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 1: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 2: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 3: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.240934   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 96, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/1x1(102) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
WT 0: GLen:57344 LLen:57344 GOff:0 OLen: 57344 OOff:0 NeedComms:False 
WT 1: GLen:112 LLen:112 GOff:0 OLen: 112 OOff:0 NeedComms:False 
I0603 04:26:22.240947   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 97, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_1x1(103) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
OFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
I0603 04:26:22.240957   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 98, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
Rank:0: Finalize:ComputeOp: inception_4d/3x3_reduce(104) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
WT 0: GLen:73728 LLen:73728 GOff:0 OLen: 73728 OOff:0 NeedComms:False 
WT 1: GLen:144 LLen:144 GOff:0 OLen: 144 OOff:0 NeedComms:False 
I0603 04:26:22.240969   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 99, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_3x3_reduce(105) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
OFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
I0603 04:26:22.241000   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 100, bottom_id 0, calculated bottom_size 4718592, real bottom_size 4718592
Rank:0: Finalize:ComputeOp: inception_4d/3x3(106) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:144 LLen:144 GOff:0 NeedComms:False
OFM 0: GLen:288 LLen:288 GOff:0 NeedComms:False
WT 0: GLen:41472 LLen:41472 GOff:0 OLen: 41472 OOff:0 NeedComms:False 
WT 1: GLen:288 LLen:288 GOff:0 OLen: 288 OOff:0 NeedComms:False 
I0603 04:26:22.241013   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 101, bottom_id 0, calculated bottom_size 4718592, real bottom_size 4718592
Rank:0: Finalize:ComputeOp: inception_4d/relu_3x3(107) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:288 LLen:288 GOff:0 NeedComms:False
OFM 0: GLen:288 LLen:288 GOff:0 NeedComms:False
I0603 04:26:22.241024   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 102, bottom_id 0, calculated bottom_size 9437184, real bottom_size 9437184
Rank:0: Finalize:ComputeOp: inception_4d/5x5_reduce(108) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:16384 LLen:16384 GOff:0 OLen: 16384 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:26:22.241035   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 103, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_5x5_reduce(109) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:26:22.241046   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 104, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4d/5x5(110) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:2048 LLen:2048 GOff:0 OLen: 2048 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.241058   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 105, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4d/relu_5x5(111) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.241068   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 106, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4d/pool(112) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
I0603 04:26:22.241077   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 107, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/pool_proj(113) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:512 LLen:512 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
WT 0: GLen:32768 LLen:32768 GOff:0 OLen: 32768 OOff:0 NeedComms:False 
WT 1: GLen:64 LLen:64 GOff:0 OLen: 64 OOff:0 NeedComms:False 
I0603 04:26:22.241091   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 108, bottom_id 0, calculated bottom_size 16777216, real bottom_size 16777216
Rank:0: Finalize:ComputeOp: inception_4d/relu_pool_proj(114) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:64 LLen:64 GOff:0 NeedComms:False
I0603 04:26:22.241101   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 109, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4d/output(116) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:112 LLen:112 GOff:0 NeedComms:False
IFM 1: GLen:288 LLen:288 GOff:0 NeedComms:False
IFM 2: GLen:64 LLen:64 GOff:0 NeedComms:False
IFM 3: GLen:64 LLen:64 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:26:22.241113   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 0, calculated bottom_size 3670016, real bottom_size 3670016
I0603 04:26:22.241118   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 1, calculated bottom_size 9437184, real bottom_size 9437184
I0603 04:26:22.241123   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 2, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:26:22.241128   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 110, bottom_id 3, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_4d/output_inception_4d/output_0_split(117) - 1 in, 5 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 1: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 2: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 3: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 4: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:26:22.241142   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 111, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: loss2/ave_pool(118) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:26:22.241152   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 112, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: loss2/conv(119) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:67584 LLen:67584 GOff:0 OLen: 67584 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.241164   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 113, bottom_id 0, calculated bottom_size 1689600, real bottom_size 1689600
Rank:0: Finalize:ComputeOp: loss2/relu_conv(120) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.241175   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 114, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss2/fc(121) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
WT 0: GLen:3276800 LLen:3276800 GOff:0 OLen: 3276800 OOff:0 NeedComms:False 
WT 1: GLen:1024 LLen:1024 GOff:0 OLen: 1024 OOff:0 NeedComms:False 
I0603 04:26:22.241186   861 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 115, bottom_id 0, calculated bottom_size 409600, real bottom_size 409600
Rank:0: Finalize:ComputeOp: loss2/relu_fc(122) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.241197   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 116, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss2/drop_fc(123) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.246598   861 net.cpp:470] InitNet: check bottom sizes for layer Dropout, layer_id 117, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss2/classifier(124) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
WT 0: GLen:3072 LLen:3072 GOff:0 OLen: 3072 OOff:0 NeedComms:False 
WT 1: GLen:3 LLen:3 GOff:0 OLen: 3 OOff:0 NeedComms:False 
I0603 04:26:22.246616   861 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 118, bottom_id 0, calculated bottom_size 131072, real bottom_size 131072
Rank:0: Finalize:ComputeOp: loss2/loss(125) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:26:22.246628   861 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 119, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:26:22.246644   861 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 119, bottom_id 1, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: inception_4e/1x1(126) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
WT 0: GLen:135168 LLen:135168 GOff:0 OLen: 135168 OOff:0 NeedComms:False 
WT 1: GLen:256 LLen:256 GOff:0 OLen: 256 OOff:0 NeedComms:False 
I0603 04:26:22.246657   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 120, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_1x1(127) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:26:22.246667   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 121, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: inception_4e/3x3_reduce(128) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
WT 0: GLen:84480 LLen:84480 GOff:0 OLen: 84480 OOff:0 NeedComms:False 
WT 1: GLen:160 LLen:160 GOff:0 OLen: 160 OOff:0 NeedComms:False 
I0603 04:26:22.246680   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 122, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_3x3_reduce(129) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
I0603 04:26:22.246690   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 123, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
Rank:0: Finalize:ComputeOp: inception_4e/3x3(130) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
WT 0: GLen:51200 LLen:51200 GOff:0 OLen: 51200 OOff:0 NeedComms:False 
WT 1: GLen:320 LLen:320 GOff:0 OLen: 320 OOff:0 NeedComms:False 
I0603 04:26:22.246703   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 124, bottom_id 0, calculated bottom_size 5242880, real bottom_size 5242880
Rank:0: Finalize:ComputeOp: inception_4e/relu_3x3(131) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
I0603 04:26:22.246713   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 125, bottom_id 0, calculated bottom_size 10485760, real bottom_size 10485760
Rank:0: Finalize:ComputeOp: inception_4e/5x5_reduce(132) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:16896 LLen:16896 GOff:0 OLen: 16896 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:26:22.246726   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 126, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_5x5_reduce(133) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:26:22.246737   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 127, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4e/5x5(134) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:4096 LLen:4096 GOff:0 OLen: 4096 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.246749   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 128, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_4e/relu_5x5(135) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.246760   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 129, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4e/pool(136) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
I0603 04:26:22.246772   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 130, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/pool_proj(137) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:528 LLen:528 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:67584 LLen:67584 GOff:0 OLen: 67584 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.246783   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 131, bottom_id 0, calculated bottom_size 17301504, real bottom_size 17301504
Rank:0: Finalize:ComputeOp: inception_4e/relu_pool_proj(138) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.246793   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 132, bottom_id 0, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: inception_4e/output(140) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
IFM 1: GLen:320 LLen:320 GOff:0 NeedComms:False
IFM 2: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 3: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.246814   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
I0603 04:26:22.246819   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 1, calculated bottom_size 10485760, real bottom_size 10485760
I0603 04:26:22.246824   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 2, calculated bottom_size 4194304, real bottom_size 4194304
I0603 04:26:22.246829   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 133, bottom_id 3, calculated bottom_size 4194304, real bottom_size 4194304
Rank:0: Finalize:ComputeOp: pool4/3x3_s2(141) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.252351   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 134, bottom_id 0, calculated bottom_size 27262976, real bottom_size 27262976
Rank:0: Finalize:ComputeOp: pool4/3x3_s2_pool4/3x3_s2_0_split(142) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 1: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 2: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 3: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.252368   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 135, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/1x1(143) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
WT 0: GLen:212992 LLen:212992 GOff:0 OLen: 212992 OOff:0 NeedComms:False 
WT 1: GLen:256 LLen:256 GOff:0 OLen: 256 OOff:0 NeedComms:False 
I0603 04:26:22.252382   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 136, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_1x1(144) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
OFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
I0603 04:26:22.252393   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 137, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
Rank:0: Finalize:ComputeOp: inception_5a/3x3_reduce(145) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
WT 0: GLen:133120 LLen:133120 GOff:0 OLen: 133120 OOff:0 NeedComms:False 
WT 1: GLen:160 LLen:160 GOff:0 OLen: 160 OOff:0 NeedComms:False 
I0603 04:26:22.252404   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 138, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_3x3_reduce(146) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
I0603 04:26:22.252415   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 139, bottom_id 0, calculated bottom_size 1310720, real bottom_size 1310720
Rank:0: Finalize:ComputeOp: inception_5a/3x3(147) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:160 LLen:160 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
WT 0: GLen:51200 LLen:51200 GOff:0 OLen: 51200 OOff:0 NeedComms:False 
WT 1: GLen:320 LLen:320 GOff:0 OLen: 320 OOff:0 NeedComms:False 
I0603 04:26:22.252439   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 140, bottom_id 0, calculated bottom_size 1310720, real bottom_size 1310720
Rank:0: Finalize:ComputeOp: inception_5a/relu_3x3(148) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
OFM 0: GLen:320 LLen:320 GOff:0 NeedComms:False
I0603 04:26:22.252449   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 141, bottom_id 0, calculated bottom_size 2621440, real bottom_size 2621440
Rank:0: Finalize:ComputeOp: inception_5a/5x5_reduce(149) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
WT 0: GLen:26624 LLen:26624 GOff:0 OLen: 26624 OOff:0 NeedComms:False 
WT 1: GLen:32 LLen:32 GOff:0 OLen: 32 OOff:0 NeedComms:False 
I0603 04:26:22.252461   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 142, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_5x5_reduce(150) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
I0603 04:26:22.252472   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 143, bottom_id 0, calculated bottom_size 262144, real bottom_size 262144
Rank:0: Finalize:ComputeOp: inception_5a/5x5(151) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:32 LLen:32 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:4096 LLen:4096 GOff:0 OLen: 4096 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.252485   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 144, bottom_id 0, calculated bottom_size 262144, real bottom_size 262144
Rank:0: Finalize:ComputeOp: inception_5a/relu_5x5(152) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.252496   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 145, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5a/pool(153) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.252506   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 146, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/pool_proj(154) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:106496 LLen:106496 GOff:0 OLen: 106496 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.252517   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 147, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5a/relu_pool_proj(155) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.252528   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 148, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5a/output(157) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:256 LLen:256 GOff:0 NeedComms:False
IFM 1: GLen:320 LLen:320 GOff:0 NeedComms:False
IFM 2: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 3: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.252542   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 0, calculated bottom_size 2097152, real bottom_size 2097152
I0603 04:26:22.252547   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 1, calculated bottom_size 2621440, real bottom_size 2621440
I0603 04:26:22.252550   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 2, calculated bottom_size 1048576, real bottom_size 1048576
I0603 04:26:22.252555   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 149, bottom_id 3, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5a/output_inception_5a/output_0_split(158) - 1 in, 4 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 1: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 2: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 3: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.252568   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 150, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/1x1(159) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
WT 0: GLen:319488 LLen:319488 GOff:0 OLen: 319488 OOff:0 NeedComms:False 
WT 1: GLen:384 LLen:384 GOff:0 OLen: 384 OOff:0 NeedComms:False 
I0603 04:26:22.257205   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 151, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_1x1(160) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
I0603 04:26:22.257225   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 152, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_5b/3x3_reduce(161) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
WT 0: GLen:159744 LLen:159744 GOff:0 OLen: 159744 OOff:0 NeedComms:False 
WT 1: GLen:192 LLen:192 GOff:0 OLen: 192 OOff:0 NeedComms:False 
I0603 04:26:22.257238   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 153, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_3x3_reduce(162) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
I0603 04:26:22.257248   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 154, bottom_id 0, calculated bottom_size 1572864, real bottom_size 1572864
Rank:0: Finalize:ComputeOp: inception_5b/3x3(163) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:192 LLen:192 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
WT 0: GLen:73728 LLen:73728 GOff:0 OLen: 73728 OOff:0 NeedComms:False 
WT 1: GLen:384 LLen:384 GOff:0 OLen: 384 OOff:0 NeedComms:False 
I0603 04:26:22.257261   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 155, bottom_id 0, calculated bottom_size 1572864, real bottom_size 1572864
Rank:0: Finalize:ComputeOp: inception_5b/relu_3x3(164) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
OFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
I0603 04:26:22.257271   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 156, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
Rank:0: Finalize:ComputeOp: inception_5b/5x5_reduce(165) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
WT 0: GLen:39936 LLen:39936 GOff:0 OLen: 39936 OOff:0 NeedComms:False 
WT 1: GLen:48 LLen:48 GOff:0 OLen: 48 OOff:0 NeedComms:False 
I0603 04:26:22.257282   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 157, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_5x5_reduce(166) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
OFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
I0603 04:26:22.257292   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 158, bottom_id 0, calculated bottom_size 393216, real bottom_size 393216
Rank:0: Finalize:ComputeOp: inception_5b/5x5(167) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:48 LLen:48 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:6144 LLen:6144 GOff:0 OLen: 6144 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.257303   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 159, bottom_id 0, calculated bottom_size 393216, real bottom_size 393216
Rank:0: Finalize:ComputeOp: inception_5b/relu_5x5(168) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.257314   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 160, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5b/pool(169) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
I0603 04:26:22.257336   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 161, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/pool_proj(170) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:832 LLen:832 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
WT 0: GLen:106496 LLen:106496 GOff:0 OLen: 106496 OOff:0 NeedComms:False 
WT 1: GLen:128 LLen:128 GOff:0 OLen: 128 OOff:0 NeedComms:False 
I0603 04:26:22.257349   861 net.cpp:470] InitNet: check bottom sizes for layer MklConvolution, layer_id 162, bottom_id 0, calculated bottom_size 6815744, real bottom_size 6815744
Rank:0: Finalize:ComputeOp: inception_5b/relu_pool_proj(171) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:128 LLen:128 GOff:0 NeedComms:False
I0603 04:26:22.257359   861 net.cpp:470] InitNet: check bottom sizes for layer ReLU, layer_id 163, bottom_id 0, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: inception_5b/output(173) - 4 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:384 LLen:384 GOff:0 NeedComms:False
IFM 1: GLen:384 LLen:384 GOff:0 NeedComms:False
IFM 2: GLen:128 LLen:128 GOff:0 NeedComms:False
IFM 3: GLen:128 LLen:128 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.257372   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 0, calculated bottom_size 3145728, real bottom_size 3145728
I0603 04:26:22.257377   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 1, calculated bottom_size 3145728, real bottom_size 3145728
I0603 04:26:22.257382   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 2, calculated bottom_size 1048576, real bottom_size 1048576
I0603 04:26:22.257386   861 net.cpp:470] InitNet: check bottom sizes for layer Concat, layer_id 164, bottom_id 3, calculated bottom_size 1048576, real bottom_size 1048576
Rank:0: Finalize:ComputeOp: pool5/7x7_s1(174) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.257396   861 net.cpp:470] InitNet: check bottom sizes for layer Pooling, layer_id 165, bottom_id 0, calculated bottom_size 8388608, real bottom_size 8388608
Rank:0: Finalize:ComputeOp: pool5/drop_7x7_s1(175) - 1 in, 1 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
I0603 04:26:22.257405   861 net.cpp:470] InitNet: check bottom sizes for layer Dropout, layer_id 166, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: loss3/classifier(176) - 1 in, 1 out, 2 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:1024 LLen:1024 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
WT 0: GLen:12288 LLen:12288 GOff:0 OLen: 12288 OOff:0 NeedComms:False 
WT 1: GLen:3 LLen:3 GOff:0 OLen: 3 OOff:0 NeedComms:False 
I0603 04:26:22.257417   861 net.cpp:470] InitNet: check bottom sizes for layer InnerProduct, layer_id 167, bottom_id 0, calculated bottom_size 524288, real bottom_size 524288
Rank:0: Finalize:ComputeOp: loss3/classifier_loss3/classifier_0_split(177) - 1 in, 2 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
OFM 1: GLen:3 LLen:3 GOff:0 NeedComms:False
I0603 04:26:22.257428   861 net.cpp:470] InitNet: check bottom sizes for layer Split, layer_id 168, bottom_id 0, calculated bottom_size 384, real bottom_size 384
Rank:0: Finalize:ComputeOp: loss3/loss(178) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:26:22.262557   861 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 169, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:26:22.262567   861 net.cpp:470] InitNet: check bottom sizes for layer SoftmaxWithLoss, layer_id 169, bottom_id 1, calculated bottom_size 128, real bottom_size 128
Rank:0: Finalize:ComputeOp: accuracy(179) - 2 in, 0 out, 0 wts, 32 localMB, 0 gMBOff
IFM 0: GLen:3 LLen:3 GOff:0 NeedComms:False
IFM 1: GLen:1 LLen:1 GOff:0 NeedComms:False
I0603 04:26:22.262578   861 net.cpp:470] InitNet: check bottom sizes for layer Accuracy, layer_id 170, bottom_id 0, calculated bottom_size 384, real bottom_size 384
I0603 04:26:22.262583   861 net.cpp:470] InitNet: check bottom sizes for layer Accuracy, layer_id 170, bottom_id 1, calculated bottom_size 128, real bottom_size 128
I0603 04:26:22.262589   861 net.cpp:500] Network initialization done.
I0603 04:26:22.263622   861 solver.cpp:122] Solver scaffolding done.
I0603 04:26:22.263926   861 caffe.cpp:310] Resuming from /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_10.solverstate
I0603 04:26:22.569597   861 sgd_solver.cpp:547] SGDSolver: restoring history
I0603 04:26:22.594597   861 caffe.cpp:329] Starting Optimization
I0603 04:26:22.594633   861 solver.cpp:495] Solving Model4.256
I0603 04:26:22.594638   861 solver.cpp:496] Learning Rate Policy: poly
I0603 04:26:27.054014   861 solver.cpp:316] Iteration 10, loss = 1.55511
I0603 04:26:27.054074   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:26:27.054088   861 solver.cpp:332]     Train net output #1: loss = 0.965559 (* 1 = 0.965559 loss)
I0603 04:26:27.054095   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.953766 (* 0.3 = 0.28613 loss)
I0603 04:26:27.054102   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01142 (* 0.3 = 0.303426 loss)
I0603 04:26:27.054113   861 sgd_solver.cpp:176] Iteration 10, lr = 0.00994778
I0603 04:26:34.919741   861 solver.cpp:316] Iteration 12, loss = 1.72391
I0603 04:26:34.919801   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:26:34.919814   861 solver.cpp:332]     Train net output #1: loss = 1.07153 (* 1 = 1.07153 loss)
I0603 04:26:34.919862   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04293 (* 0.3 = 0.312879 loss)
I0603 04:26:34.919869   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.13168 (* 0.3 = 0.339503 loss)
I0603 04:26:34.919880   861 sgd_solver.cpp:176] Iteration 12, lr = 0.0099373
I0603 04:26:42.691241   861 solver.cpp:316] Iteration 14, loss = 2.41087
I0603 04:26:42.691296   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:26:42.691310   861 solver.cpp:332]     Train net output #1: loss = 1.5139 (* 1 = 1.5139 loss)
I0603 04:26:42.691318   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.8688 (* 0.3 = 0.560641 loss)
I0603 04:26:42.691325   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.12112 (* 0.3 = 0.336337 loss)
I0603 04:26:42.691336   861 sgd_solver.cpp:176] Iteration 14, lr = 0.00992682
I0603 04:26:50.355280   861 solver.cpp:316] Iteration 16, loss = 1.64529
I0603 04:26:50.355339   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:26:50.355352   861 solver.cpp:332]     Train net output #1: loss = 1.0291 (* 1 = 1.0291 loss)
I0603 04:26:50.355360   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.976326 (* 0.3 = 0.292898 loss)
I0603 04:26:50.355366   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07766 (* 0.3 = 0.323298 loss)
I0603 04:26:50.355377   861 sgd_solver.cpp:176] Iteration 16, lr = 0.00991632
I0603 04:27:00.004076   861 solver.cpp:316] Iteration 18, loss = 1.74122
I0603 04:27:00.004184   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:27:00.004197   861 solver.cpp:332]     Train net output #1: loss = 1.06888 (* 1 = 1.06888 loss)
I0603 04:27:00.004205   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.24082 (* 0.3 = 0.372246 loss)
I0603 04:27:00.004211   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00031 (* 0.3 = 0.300094 loss)
I0603 04:27:00.004222   861 sgd_solver.cpp:176] Iteration 18, lr = 0.00990581
I0603 04:27:07.747807   861 solver.cpp:316] Iteration 20, loss = 1.79757
I0603 04:27:07.747864   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:27:07.747879   861 solver.cpp:332]     Train net output #1: loss = 1.10457 (* 1 = 1.10457 loss)
I0603 04:27:07.747886   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.22772 (* 0.3 = 0.368315 loss)
I0603 04:27:07.747892   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08231 (* 0.3 = 0.324692 loss)
I0603 04:27:07.747905   861 sgd_solver.cpp:176] Iteration 20, lr = 0.00989528
I0603 04:27:15.395431   861 solver.cpp:316] Iteration 22, loss = 1.78061
I0603 04:27:15.395484   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:27:15.395498   861 solver.cpp:332]     Train net output #1: loss = 1.13227 (* 1 = 1.13227 loss)
I0603 04:27:15.395506   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03198 (* 0.3 = 0.309594 loss)
I0603 04:27:15.395512   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.12916 (* 0.3 = 0.338748 loss)
I0603 04:27:15.395524   861 sgd_solver.cpp:176] Iteration 22, lr = 0.00988475
I0603 04:27:23.067235   861 solver.cpp:316] Iteration 24, loss = 1.40901
I0603 04:27:23.067293   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:27:23.067307   861 solver.cpp:332]     Train net output #1: loss = 0.873528 (* 1 = 0.873528 loss)
I0603 04:27:23.067314   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.982486 (* 0.3 = 0.294746 loss)
I0603 04:27:23.067322   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.802456 (* 0.3 = 0.240737 loss)
I0603 04:27:23.067332   861 sgd_solver.cpp:176] Iteration 24, lr = 0.00987421
I0603 04:27:32.790181   861 solver.cpp:316] Iteration 26, loss = 1.27113
I0603 04:27:32.790347   861 solver.cpp:332]     Train net output #0: accuracy = 0.75
I0603 04:27:32.790364   861 solver.cpp:332]     Train net output #1: loss = 0.779946 (* 1 = 0.779946 loss)
I0603 04:27:32.790370   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.802763 (* 0.3 = 0.240829 loss)
I0603 04:27:32.790377   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.834518 (* 0.3 = 0.250356 loss)
I0603 04:27:32.790388   861 sgd_solver.cpp:176] Iteration 26, lr = 0.00986365
I0603 04:27:40.719497   861 solver.cpp:316] Iteration 28, loss = 1.74418
I0603 04:27:40.719555   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:27:40.719569   861 solver.cpp:332]     Train net output #1: loss = 1.09442 (* 1 = 1.09442 loss)
I0603 04:27:40.719576   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.11753 (* 0.3 = 0.33526 loss)
I0603 04:27:40.719583   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04835 (* 0.3 = 0.314505 loss)
I0603 04:27:40.719594   861 sgd_solver.cpp:176] Iteration 28, lr = 0.00985309
I0603 04:27:48.405839   861 solver.cpp:316] Iteration 30, loss = 1.60003
I0603 04:27:48.405910   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:27:48.405930   861 solver.cpp:332]     Train net output #1: loss = 1.00569 (* 1 = 1.00569 loss)
I0603 04:27:48.405943   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.91319 (* 0.3 = 0.273957 loss)
I0603 04:27:48.405953   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06794 (* 0.3 = 0.320383 loss)
I0603 04:27:48.405969   861 sgd_solver.cpp:176] Iteration 30, lr = 0.00984251
I0603 04:27:52.207844   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_32.caffemodel
I0603 04:27:52.373286   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_32.solverstate
I0603 04:27:56.235031   861 solver.cpp:316] Iteration 32, loss = 1.73916
I0603 04:27:56.235090   861 solver.cpp:332]     Train net output #0: accuracy = 0.25
I0603 04:27:56.235105   861 solver.cpp:332]     Train net output #1: loss = 1.0977 (* 1 = 1.0977 loss)
I0603 04:27:56.235111   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05769 (* 0.3 = 0.317307 loss)
I0603 04:27:56.235118   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08052 (* 0.3 = 0.324155 loss)
I0603 04:27:56.235129   861 sgd_solver.cpp:176] Iteration 32, lr = 0.00983192
I0603 04:28:03.919275   861 solver.cpp:316] Iteration 34, loss = 1.65966
I0603 04:28:03.919387   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:28:03.919402   861 solver.cpp:332]     Train net output #1: loss = 1.03787 (* 1 = 1.03787 loss)
I0603 04:28:03.919409   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.926714 (* 0.3 = 0.278014 loss)
I0603 04:28:03.919416   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.14595 (* 0.3 = 0.343784 loss)
I0603 04:28:03.919427   861 sgd_solver.cpp:176] Iteration 34, lr = 0.00982132
I0603 04:28:19.043684   861 solver.cpp:316] Iteration 36, loss = 1.89258
I0603 04:28:19.043726   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 04:28:19.043740   861 solver.cpp:332]     Train net output #1: loss = 1.17412 (* 1 = 1.17412 loss)
I0603 04:28:19.043746   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.20802 (* 0.3 = 0.362406 loss)
I0603 04:28:19.043753   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.18685 (* 0.3 = 0.356054 loss)
I0603 04:28:19.043764   861 sgd_solver.cpp:176] Iteration 36, lr = 0.00981071
I0603 04:28:33.886313   861 solver.cpp:316] Iteration 38, loss = 1.46147
I0603 04:28:33.886366   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:28:33.886380   861 solver.cpp:332]     Train net output #1: loss = 0.923156 (* 1 = 0.923156 loss)
I0603 04:28:33.886387   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.804333 (* 0.3 = 0.2413 loss)
I0603 04:28:33.886394   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.990037 (* 0.3 = 0.297011 loss)
I0603 04:28:33.886405   861 sgd_solver.cpp:176] Iteration 38, lr = 0.00980008
I0603 04:28:43.957762   861 solver.cpp:316] Iteration 40, loss = 1.6452
I0603 04:28:43.957906   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:28:43.957922   861 solver.cpp:332]     Train net output #1: loss = 1.02219 (* 1 = 1.02219 loss)
I0603 04:28:43.957931   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.988008 (* 0.3 = 0.296402 loss)
I0603 04:28:43.957937   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08871 (* 0.3 = 0.326613 loss)
I0603 04:28:43.957947   861 sgd_solver.cpp:176] Iteration 40, lr = 0.00978945
I0603 04:28:51.624135   861 solver.cpp:316] Iteration 42, loss = 1.72564
I0603 04:28:51.624189   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:28:51.624203   861 solver.cpp:332]     Train net output #1: loss = 1.04431 (* 1 = 1.04431 loss)
I0603 04:28:51.624210   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.14692 (* 0.3 = 0.344075 loss)
I0603 04:28:51.624217   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.12419 (* 0.3 = 0.337257 loss)
I0603 04:28:51.624228   861 sgd_solver.cpp:176] Iteration 42, lr = 0.0097788
I0603 04:28:59.258409   861 solver.cpp:316] Iteration 44, loss = 1.60092
I0603 04:28:59.258462   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:28:59.258477   861 solver.cpp:332]     Train net output #1: loss = 1.00022 (* 1 = 1.00022 loss)
I0603 04:28:59.258486   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.02703 (* 0.3 = 0.308108 loss)
I0603 04:28:59.258492   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.975295 (* 0.3 = 0.292589 loss)
I0603 04:28:59.258504   861 sgd_solver.cpp:176] Iteration 44, lr = 0.00976815
I0603 04:29:06.870754   861 solver.cpp:316] Iteration 46, loss = 1.66803
I0603 04:29:06.870808   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:29:06.870822   861 solver.cpp:332]     Train net output #1: loss = 1.0249 (* 1 = 1.0249 loss)
I0603 04:29:06.870829   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09105 (* 0.3 = 0.327314 loss)
I0603 04:29:06.870836   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05271 (* 0.3 = 0.315813 loss)
I0603 04:29:06.870847   861 sgd_solver.cpp:176] Iteration 46, lr = 0.00975748
I0603 04:29:14.481459   861 solver.cpp:316] Iteration 48, loss = 1.38711
I0603 04:29:14.481601   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:29:14.481621   861 solver.cpp:332]     Train net output #1: loss = 0.884135 (* 1 = 0.884135 loss)
I0603 04:29:14.481627   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.773242 (* 0.3 = 0.231973 loss)
I0603 04:29:14.481634   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.903348 (* 0.3 = 0.271004 loss)
I0603 04:29:14.481645   861 sgd_solver.cpp:176] Iteration 48, lr = 0.00974679
I0603 04:29:22.154814   861 solver.cpp:316] Iteration 50, loss = 1.73312
I0603 04:29:22.154872   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:29:22.154886   861 solver.cpp:332]     Train net output #1: loss = 1.08965 (* 1 = 1.08965 loss)
I0603 04:29:22.154893   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04218 (* 0.3 = 0.312653 loss)
I0603 04:29:22.154899   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10273 (* 0.3 = 0.330821 loss)
I0603 04:29:22.154911   861 sgd_solver.cpp:176] Iteration 50, lr = 0.0097361
I0603 04:29:29.855366   861 solver.cpp:316] Iteration 52, loss = 1.82871
I0603 04:29:29.855425   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 04:29:29.855439   861 solver.cpp:332]     Train net output #1: loss = 1.14866 (* 1 = 1.14866 loss)
I0603 04:29:29.855446   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07122 (* 0.3 = 0.321367 loss)
I0603 04:29:29.855454   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.1956 (* 0.3 = 0.35868 loss)
I0603 04:29:29.855465   861 sgd_solver.cpp:176] Iteration 52, lr = 0.0097254
I0603 04:29:37.746008   861 solver.cpp:316] Iteration 54, loss = 1.72571
I0603 04:29:37.746063   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:29:37.746076   861 solver.cpp:332]     Train net output #1: loss = 1.05788 (* 1 = 1.05788 loss)
I0603 04:29:37.746083   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.19855 (* 0.3 = 0.359566 loss)
I0603 04:29:37.746090   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02756 (* 0.3 = 0.308267 loss)
I0603 04:29:37.746101   861 sgd_solver.cpp:176] Iteration 54, lr = 0.00971468
I0603 04:29:45.447629   861 solver.cpp:316] Iteration 56, loss = 1.51325
I0603 04:29:45.447763   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:29:45.447779   861 solver.cpp:332]     Train net output #1: loss = 0.956459 (* 1 = 0.956459 loss)
I0603 04:29:45.447788   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.864769 (* 0.3 = 0.259431 loss)
I0603 04:29:45.447793   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.991208 (* 0.3 = 0.297362 loss)
I0603 04:29:45.447804   861 sgd_solver.cpp:176] Iteration 56, lr = 0.00970395
I0603 04:29:53.086602   861 solver.cpp:316] Iteration 58, loss = 1.49765
I0603 04:29:53.086659   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:29:53.086673   861 solver.cpp:332]     Train net output #1: loss = 0.931272 (* 1 = 0.931272 loss)
I0603 04:29:53.086681   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00007 (* 0.3 = 0.300021 loss)
I0603 04:29:53.086688   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.88784 (* 0.3 = 0.266352 loss)
I0603 04:29:53.086699   861 sgd_solver.cpp:176] Iteration 58, lr = 0.00969321
I0603 04:30:00.712993   861 solver.cpp:316] Iteration 60, loss = 1.75185
I0603 04:30:00.713052   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:30:00.713065   861 solver.cpp:332]     Train net output #1: loss = 1.10231 (* 1 = 1.10231 loss)
I0603 04:30:00.713073   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.11546 (* 0.3 = 0.334638 loss)
I0603 04:30:00.713080   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04966 (* 0.3 = 0.314898 loss)
I0603 04:30:00.713091   861 sgd_solver.cpp:176] Iteration 60, lr = 0.00968246
I0603 04:30:08.350955   861 solver.cpp:316] Iteration 62, loss = 1.62355
I0603 04:30:08.351012   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:30:08.351025   861 solver.cpp:332]     Train net output #1: loss = 1.03758 (* 1 = 1.03758 loss)
I0603 04:30:08.351033   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03563 (* 0.3 = 0.310688 loss)
I0603 04:30:08.351040   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.917609 (* 0.3 = 0.275283 loss)
I0603 04:30:08.351052   861 sgd_solver.cpp:176] Iteration 62, lr = 0.00967169
I0603 04:30:12.201956   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_64.caffemodel
I0603 04:30:12.362772   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_64.solverstate
I0603 04:30:16.208061   861 solver.cpp:316] Iteration 64, loss = 1.75945
I0603 04:30:16.208173   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 04:30:16.208194   861 solver.cpp:332]     Train net output #1: loss = 1.08975 (* 1 = 1.08975 loss)
I0603 04:30:16.208204   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.20539 (* 0.3 = 0.361618 loss)
I0603 04:30:16.208214   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02694 (* 0.3 = 0.308082 loss)
I0603 04:30:16.208227   861 sgd_solver.cpp:176] Iteration 64, lr = 0.00966092
I0603 04:30:23.900331   861 solver.cpp:316] Iteration 66, loss = 1.67742
I0603 04:30:23.900388   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:30:23.900403   861 solver.cpp:332]     Train net output #1: loss = 1.03932 (* 1 = 1.03932 loss)
I0603 04:30:23.900410   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05755 (* 0.3 = 0.317265 loss)
I0603 04:30:23.900418   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06944 (* 0.3 = 0.320831 loss)
I0603 04:30:23.900429   861 sgd_solver.cpp:176] Iteration 66, lr = 0.00965013
I0603 04:30:39.217453   861 solver.cpp:316] Iteration 68, loss = 1.72743
I0603 04:30:39.217512   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:30:39.217533   861 solver.cpp:332]     Train net output #1: loss = 1.07869 (* 1 = 1.07869 loss)
I0603 04:30:39.217545   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07825 (* 0.3 = 0.323475 loss)
I0603 04:30:39.217556   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0842 (* 0.3 = 0.32526 loss)
I0603 04:30:39.217572   861 sgd_solver.cpp:176] Iteration 68, lr = 0.00963933
I0603 04:30:53.839738   861 solver.cpp:316] Iteration 70, loss = 1.70096
I0603 04:30:53.839874   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:30:53.839895   861 solver.cpp:332]     Train net output #1: loss = 1.03232 (* 1 = 1.03232 loss)
I0603 04:30:53.839905   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.1198 (* 0.3 = 0.335939 loss)
I0603 04:30:53.839916   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10899 (* 0.3 = 0.332696 loss)
I0603 04:30:53.839931   861 sgd_solver.cpp:176] Iteration 70, lr = 0.00962852
I0603 04:31:03.915221   861 solver.cpp:316] Iteration 72, loss = 1.66889
I0603 04:31:03.915284   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:31:03.915304   861 solver.cpp:332]     Train net output #1: loss = 1.04416 (* 1 = 1.04416 loss)
I0603 04:31:03.915314   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08236 (* 0.3 = 0.324707 loss)
I0603 04:31:03.915324   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00009 (* 0.3 = 0.300026 loss)
I0603 04:31:03.915339   861 sgd_solver.cpp:176] Iteration 72, lr = 0.00961769
I0603 04:31:11.556504   861 solver.cpp:316] Iteration 74, loss = 1.82055
I0603 04:31:11.556565   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:31:11.556582   861 solver.cpp:332]     Train net output #1: loss = 1.0952 (* 1 = 1.0952 loss)
I0603 04:31:11.556592   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.24323 (* 0.3 = 0.37297 loss)
I0603 04:31:11.556603   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.17458 (* 0.3 = 0.352374 loss)
I0603 04:31:11.556618   861 sgd_solver.cpp:176] Iteration 74, lr = 0.00960685
I0603 04:31:19.142336   861 solver.cpp:316] Iteration 76, loss = 1.69598
I0603 04:31:19.142395   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:31:19.142413   861 solver.cpp:332]     Train net output #1: loss = 1.06844 (* 1 = 1.06844 loss)
I0603 04:31:19.142424   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07214 (* 0.3 = 0.321642 loss)
I0603 04:31:19.142434   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01966 (* 0.3 = 0.305897 loss)
I0603 04:31:19.142449   861 sgd_solver.cpp:176] Iteration 76, lr = 0.00959601
I0603 04:31:26.818964   861 solver.cpp:316] Iteration 78, loss = 1.76018
I0603 04:31:26.819070   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:31:26.819092   861 solver.cpp:332]     Train net output #1: loss = 1.05514 (* 1 = 1.05514 loss)
I0603 04:31:26.819103   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.2326 (* 0.3 = 0.369781 loss)
I0603 04:31:26.819113   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.11753 (* 0.3 = 0.33526 loss)
I0603 04:31:26.819128   861 sgd_solver.cpp:176] Iteration 78, lr = 0.00958514
I0603 04:31:34.521596   861 solver.cpp:316] Iteration 80, loss = 1.56704
I0603 04:31:34.521651   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:31:34.521663   861 solver.cpp:332]     Train net output #1: loss = 0.935068 (* 1 = 0.935068 loss)
I0603 04:31:34.521670   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07426 (* 0.3 = 0.322277 loss)
I0603 04:31:34.521677   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0323 (* 0.3 = 0.30969 loss)
I0603 04:31:34.521688   861 sgd_solver.cpp:176] Iteration 80, lr = 0.00957427
I0603 04:31:42.378096   861 solver.cpp:316] Iteration 82, loss = 1.52299
I0603 04:31:42.378154   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:31:42.378168   861 solver.cpp:332]     Train net output #1: loss = 0.957977 (* 1 = 0.957977 loss)
I0603 04:31:42.378176   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.953939 (* 0.3 = 0.286182 loss)
I0603 04:31:42.378182   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.929446 (* 0.3 = 0.278834 loss)
I0603 04:31:42.378193   861 sgd_solver.cpp:176] Iteration 82, lr = 0.00956338
I0603 04:31:50.039405   861 solver.cpp:316] Iteration 84, loss = 1.91643
I0603 04:31:50.039465   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:31:50.039479   861 solver.cpp:332]     Train net output #1: loss = 1.21603 (* 1 = 1.21603 loss)
I0603 04:31:50.039486   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.20148 (* 0.3 = 0.360444 loss)
I0603 04:31:50.039494   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.13318 (* 0.3 = 0.339953 loss)
I0603 04:31:50.039505   861 sgd_solver.cpp:176] Iteration 84, lr = 0.00955249
I0603 04:31:57.659934   861 solver.cpp:316] Iteration 86, loss = 1.46287
I0603 04:31:57.660059   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 04:31:57.660074   861 solver.cpp:332]     Train net output #1: loss = 0.930325 (* 1 = 0.930325 loss)
I0603 04:31:57.660082   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.858717 (* 0.3 = 0.257615 loss)
I0603 04:31:57.660089   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.916434 (* 0.3 = 0.27493 loss)
I0603 04:31:57.660100   861 sgd_solver.cpp:176] Iteration 86, lr = 0.00954158
I0603 04:32:05.337028   861 solver.cpp:316] Iteration 88, loss = 1.49273
I0603 04:32:05.337097   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:32:05.337112   861 solver.cpp:332]     Train net output #1: loss = 0.959872 (* 1 = 0.959872 loss)
I0603 04:32:05.337121   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.881827 (* 0.3 = 0.264548 loss)
I0603 04:32:05.337126   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.894355 (* 0.3 = 0.268306 loss)
I0603 04:32:05.337137   861 sgd_solver.cpp:176] Iteration 88, lr = 0.00953065
I0603 04:32:12.945920   861 solver.cpp:316] Iteration 90, loss = 1.72846
I0603 04:32:12.945976   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:32:12.945996   861 solver.cpp:332]     Train net output #1: loss = 1.0832 (* 1 = 1.0832 loss)
I0603 04:32:12.946008   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08345 (* 0.3 = 0.325034 loss)
I0603 04:32:12.946017   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06742 (* 0.3 = 0.320226 loss)
I0603 04:32:12.946027   861 sgd_solver.cpp:176] Iteration 90, lr = 0.00951972
I0603 04:32:20.567451   861 solver.cpp:316] Iteration 92, loss = 2.20576
I0603 04:32:20.567503   861 solver.cpp:332]     Train net output #0: accuracy = 0.3125
I0603 04:32:20.567517   861 solver.cpp:332]     Train net output #1: loss = 1.41809 (* 1 = 1.41809 loss)
I0603 04:32:20.567525   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.25003 (* 0.3 = 0.375009 loss)
I0603 04:32:20.567533   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.37552 (* 0.3 = 0.412657 loss)
I0603 04:32:20.567543   861 sgd_solver.cpp:176] Iteration 92, lr = 0.00950877
I0603 04:32:28.225020   861 solver.cpp:316] Iteration 94, loss = 1.54849
I0603 04:32:28.225116   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:32:28.225131   861 solver.cpp:332]     Train net output #1: loss = 0.994108 (* 1 = 0.994108 loss)
I0603 04:32:28.225138   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.935213 (* 0.3 = 0.280564 loss)
I0603 04:32:28.225145   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.91274 (* 0.3 = 0.273822 loss)
I0603 04:32:28.225157   861 sgd_solver.cpp:176] Iteration 94, lr = 0.00949781
I0603 04:32:32.097838   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_96.caffemodel
I0603 04:32:32.263229   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_96.solverstate
I0603 04:32:36.366312   861 solver.cpp:316] Iteration 96, loss = 1.73579
I0603 04:32:36.366369   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:32:36.366384   861 solver.cpp:332]     Train net output #1: loss = 1.03874 (* 1 = 1.03874 loss)
I0603 04:32:36.366390   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.23504 (* 0.3 = 0.370511 loss)
I0603 04:32:36.366397   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08846 (* 0.3 = 0.326539 loss)
I0603 04:32:36.366408   861 sgd_solver.cpp:176] Iteration 96, lr = 0.00948683
I0603 04:32:44.082391   861 solver.cpp:316] Iteration 98, loss = 1.62086
I0603 04:32:44.082450   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 04:32:44.082464   861 solver.cpp:332]     Train net output #1: loss = 1.00814 (* 1 = 1.00814 loss)
I0603 04:32:44.082471   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04422 (* 0.3 = 0.313265 loss)
I0603 04:32:44.082479   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.998184 (* 0.3 = 0.299455 loss)
I0603 04:32:44.082490   861 sgd_solver.cpp:176] Iteration 98, lr = 0.00947585
I0603 04:32:59.158324   861 solver.cpp:316] Iteration 100, loss = 1.55034
I0603 04:32:59.158416   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 04:32:59.158430   861 solver.cpp:332]     Train net output #1: loss = 0.976819 (* 1 = 0.976819 loss)
I0603 04:32:59.158438   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.938991 (* 0.3 = 0.281697 loss)
I0603 04:32:59.158444   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.972732 (* 0.3 = 0.291819 loss)
I0603 04:32:59.158454   861 sgd_solver.cpp:176] Iteration 100, lr = 0.00946485
I0603 04:33:13.869601   861 solver.cpp:316] Iteration 102, loss = 1.82861
I0603 04:33:13.869660   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:33:13.869678   861 solver.cpp:332]     Train net output #1: loss = 1.12998 (* 1 = 1.12998 loss)
I0603 04:33:13.869690   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.12308 (* 0.3 = 0.336923 loss)
I0603 04:33:13.869700   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.20568 (* 0.3 = 0.361704 loss)
I0603 04:33:13.869715   861 sgd_solver.cpp:176] Iteration 102, lr = 0.00945383
I0603 04:33:23.731977   861 solver.cpp:316] Iteration 104, loss = 1.70816
I0603 04:33:23.732038   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:33:23.732058   861 solver.cpp:332]     Train net output #1: loss = 1.04891 (* 1 = 1.04891 loss)
I0603 04:33:23.732069   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.15429 (* 0.3 = 0.346287 loss)
I0603 04:33:23.732079   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0432 (* 0.3 = 0.312961 loss)
I0603 04:33:23.732095   861 sgd_solver.cpp:176] Iteration 104, lr = 0.00944281
I0603 04:33:31.374656   861 solver.cpp:316] Iteration 106, loss = 1.57388
I0603 04:33:31.374770   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:33:31.374791   861 solver.cpp:332]     Train net output #1: loss = 0.982325 (* 1 = 0.982325 loss)
I0603 04:33:31.374802   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.986134 (* 0.3 = 0.29584 loss)
I0603 04:33:31.374812   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.9857 (* 0.3 = 0.29571 loss)
I0603 04:33:31.374828   861 sgd_solver.cpp:176] Iteration 106, lr = 0.00943177
I0603 04:33:39.271096   861 solver.cpp:316] Iteration 108, loss = 1.53271
I0603 04:33:39.271148   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:33:39.271167   861 solver.cpp:332]     Train net output #1: loss = 0.958522 (* 1 = 0.958522 loss)
I0603 04:33:39.271178   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.895927 (* 0.3 = 0.268778 loss)
I0603 04:33:39.271188   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01802 (* 0.3 = 0.305407 loss)
I0603 04:33:39.271204   861 sgd_solver.cpp:176] Iteration 108, lr = 0.00942072
I0603 04:33:46.976403   861 solver.cpp:316] Iteration 110, loss = 1.55179
I0603 04:33:46.976464   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:33:46.976482   861 solver.cpp:332]     Train net output #1: loss = 0.955414 (* 1 = 0.955414 loss)
I0603 04:33:46.976495   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.972878 (* 0.3 = 0.291863 loss)
I0603 04:33:46.976505   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01505 (* 0.3 = 0.304514 loss)
I0603 04:33:46.976519   861 sgd_solver.cpp:176] Iteration 110, lr = 0.00940966
I0603 04:33:54.619640   861 solver.cpp:316] Iteration 112, loss = 1.59726
I0603 04:33:54.619701   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:33:54.619720   861 solver.cpp:332]     Train net output #1: loss = 1.002 (* 1 = 1.002 loss)
I0603 04:33:54.619730   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.963094 (* 0.3 = 0.288928 loss)
I0603 04:33:54.619740   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0211 (* 0.3 = 0.306329 loss)
I0603 04:33:54.619755   861 sgd_solver.cpp:176] Iteration 112, lr = 0.00939858
I0603 04:34:02.416239   861 solver.cpp:316] Iteration 114, loss = 1.645
I0603 04:34:02.416357   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:34:02.416376   861 solver.cpp:332]     Train net output #1: loss = 1.00423 (* 1 = 1.00423 loss)
I0603 04:34:02.416388   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10977 (* 0.3 = 0.332931 loss)
I0603 04:34:02.416399   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02614 (* 0.3 = 0.307841 loss)
I0603 04:34:02.416412   861 sgd_solver.cpp:176] Iteration 114, lr = 0.00938749
I0603 04:34:10.050428   861 solver.cpp:316] Iteration 116, loss = 1.6918
I0603 04:34:10.050487   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:34:10.050505   861 solver.cpp:332]     Train net output #1: loss = 1.00162 (* 1 = 1.00162 loss)
I0603 04:34:10.050518   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.17411 (* 0.3 = 0.352233 loss)
I0603 04:34:10.050528   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.12652 (* 0.3 = 0.337957 loss)
I0603 04:34:10.050542   861 sgd_solver.cpp:176] Iteration 116, lr = 0.00937639
I0603 04:34:17.691887   861 solver.cpp:316] Iteration 118, loss = 1.37461
I0603 04:34:17.691946   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:34:17.691963   861 solver.cpp:332]     Train net output #1: loss = 0.858351 (* 1 = 0.858351 loss)
I0603 04:34:17.691975   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.870464 (* 0.3 = 0.261139 loss)
I0603 04:34:17.691987   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.85039 (* 0.3 = 0.255117 loss)
I0603 04:34:17.692003   861 sgd_solver.cpp:176] Iteration 118, lr = 0.00936527
I0603 04:34:25.344893   861 solver.cpp:316] Iteration 120, loss = 1.63087
I0603 04:34:25.344955   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:34:25.344974   861 solver.cpp:332]     Train net output #1: loss = 0.992238 (* 1 = 0.992238 loss)
I0603 04:34:25.344983   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08857 (* 0.3 = 0.326571 loss)
I0603 04:34:25.344992   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04022 (* 0.3 = 0.312065 loss)
I0603 04:34:25.345008   861 sgd_solver.cpp:176] Iteration 120, lr = 0.00935414
I0603 04:34:33.009937   861 solver.cpp:316] Iteration 122, loss = 1.4912
I0603 04:34:33.010146   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:34:33.010169   861 solver.cpp:332]     Train net output #1: loss = 0.922181 (* 1 = 0.922181 loss)
I0603 04:34:33.010180   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.987591 (* 0.3 = 0.296277 loss)
I0603 04:34:33.010190   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.909155 (* 0.3 = 0.272747 loss)
I0603 04:34:33.010206   861 sgd_solver.cpp:176] Iteration 122, lr = 0.009343
I0603 04:34:40.868835   861 solver.cpp:316] Iteration 124, loss = 1.73771
I0603 04:34:40.868897   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:34:40.868916   861 solver.cpp:332]     Train net output #1: loss = 1.12565 (* 1 = 1.12565 loss)
I0603 04:34:40.868927   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04017 (* 0.3 = 0.31205 loss)
I0603 04:34:40.868935   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00005 (* 0.3 = 0.300015 loss)
I0603 04:34:40.868952   861 sgd_solver.cpp:176] Iteration 124, lr = 0.00933184
I0603 04:34:48.567445   861 solver.cpp:316] Iteration 126, loss = 1.55443
I0603 04:34:48.567507   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:34:48.567528   861 solver.cpp:332]     Train net output #1: loss = 0.980205 (* 1 = 0.980205 loss)
I0603 04:34:48.567538   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.94895 (* 0.3 = 0.284685 loss)
I0603 04:34:48.567548   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.965126 (* 0.3 = 0.289538 loss)
I0603 04:34:48.567564   861 sgd_solver.cpp:176] Iteration 126, lr = 0.00932068
I0603 04:34:52.431442   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_128.caffemodel
I0603 04:34:52.591284   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_128.solverstate
I0603 04:34:56.442457   861 solver.cpp:316] Iteration 128, loss = 1.59446
I0603 04:34:56.442509   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:34:56.442523   861 solver.cpp:332]     Train net output #1: loss = 0.996815 (* 1 = 0.996815 loss)
I0603 04:34:56.442531   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.965871 (* 0.3 = 0.289761 loss)
I0603 04:34:56.442538   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02628 (* 0.3 = 0.307883 loss)
I0603 04:34:56.442549   861 sgd_solver.cpp:176] Iteration 128, lr = 0.00930949
I0603 04:35:04.088516   861 solver.cpp:316] Iteration 130, loss = 1.68068
I0603 04:35:04.088668   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:35:04.088683   861 solver.cpp:332]     Train net output #1: loss = 1.04979 (* 1 = 1.04979 loss)
I0603 04:35:04.088691   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0505 (* 0.3 = 0.315149 loss)
I0603 04:35:04.088698   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05247 (* 0.3 = 0.31574 loss)
I0603 04:35:04.088709   861 sgd_solver.cpp:176] Iteration 130, lr = 0.0092983
I0603 04:35:19.114320   861 solver.cpp:316] Iteration 132, loss = 1.63127
I0603 04:35:19.114364   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:35:19.114377   861 solver.cpp:332]     Train net output #1: loss = 1.01853 (* 1 = 1.01853 loss)
I0603 04:35:19.114384   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.11697 (* 0.3 = 0.335092 loss)
I0603 04:35:19.114390   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.925521 (* 0.3 = 0.277656 loss)
I0603 04:35:19.114401   861 sgd_solver.cpp:176] Iteration 132, lr = 0.00928709
I0603 04:35:33.929407   861 solver.cpp:316] Iteration 134, loss = 1.90452
I0603 04:35:33.932590   861 solver.cpp:332]     Train net output #0: accuracy = 0.1875
I0603 04:35:33.932770   861 solver.cpp:332]     Train net output #1: loss = 1.19095 (* 1 = 1.19095 loss)
I0603 04:35:33.934170   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.22123 (* 0.3 = 0.366369 loss)
I0603 04:35:33.934185   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.15734 (* 0.3 = 0.347202 loss)
I0603 04:35:33.934201   861 sgd_solver.cpp:176] Iteration 134, lr = 0.00927586
I0603 04:35:44.135038   861 solver.cpp:316] Iteration 136, loss = 1.55927
I0603 04:35:44.135171   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:35:44.135191   861 solver.cpp:332]     Train net output #1: loss = 0.970417 (* 1 = 0.970417 loss)
I0603 04:35:44.135202   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00595 (* 0.3 = 0.301785 loss)
I0603 04:35:44.135212   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.956881 (* 0.3 = 0.287064 loss)
I0603 04:35:44.135227   861 sgd_solver.cpp:176] Iteration 136, lr = 0.00926463
I0603 04:35:51.799883   861 solver.cpp:316] Iteration 138, loss = 1.7061
I0603 04:35:51.799943   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:35:51.799962   861 solver.cpp:332]     Train net output #1: loss = 1.04298 (* 1 = 1.04298 loss)
I0603 04:35:51.799973   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.14855 (* 0.3 = 0.344565 loss)
I0603 04:35:51.799981   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06184 (* 0.3 = 0.318553 loss)
I0603 04:35:51.799998   861 sgd_solver.cpp:176] Iteration 138, lr = 0.00925338
I0603 04:35:59.468720   861 solver.cpp:316] Iteration 140, loss = 1.60986
I0603 04:35:59.468778   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:35:59.468796   861 solver.cpp:332]     Train net output #1: loss = 1.01731 (* 1 = 1.01731 loss)
I0603 04:35:59.468806   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.978857 (* 0.3 = 0.293657 loss)
I0603 04:35:59.468816   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.996291 (* 0.3 = 0.298887 loss)
I0603 04:35:59.468832   861 sgd_solver.cpp:176] Iteration 140, lr = 0.00924211
I0603 04:36:07.159049   861 solver.cpp:316] Iteration 142, loss = 1.75314
I0603 04:36:07.159099   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:36:07.159112   861 solver.cpp:332]     Train net output #1: loss = 1.09112 (* 1 = 1.09112 loss)
I0603 04:36:07.159119   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.13132 (* 0.3 = 0.339395 loss)
I0603 04:36:07.159126   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07542 (* 0.3 = 0.322627 loss)
I0603 04:36:07.159137   861 sgd_solver.cpp:176] Iteration 142, lr = 0.00923084
I0603 04:36:14.792954   861 solver.cpp:316] Iteration 144, loss = 1.58949
I0603 04:36:14.793052   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:36:14.793067   861 solver.cpp:332]     Train net output #1: loss = 0.96417 (* 1 = 0.96417 loss)
I0603 04:36:14.793074   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08364 (* 0.3 = 0.325093 loss)
I0603 04:36:14.793082   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00077 (* 0.3 = 0.300231 loss)
I0603 04:36:14.793093   861 sgd_solver.cpp:176] Iteration 144, lr = 0.00921954
I0603 04:36:22.426955   861 solver.cpp:316] Iteration 146, loss = 1.65564
I0603 04:36:22.427026   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:36:22.427047   861 solver.cpp:332]     Train net output #1: loss = 1.01782 (* 1 = 1.01782 loss)
I0603 04:36:22.427058   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03645 (* 0.3 = 0.310934 loss)
I0603 04:36:22.427070   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08961 (* 0.3 = 0.326884 loss)
I0603 04:36:22.427086   861 sgd_solver.cpp:176] Iteration 146, lr = 0.00920824
I0603 04:36:30.038972   861 solver.cpp:316] Iteration 148, loss = 1.66329
I0603 04:36:30.039023   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:36:30.039037   861 solver.cpp:332]     Train net output #1: loss = 1.01722 (* 1 = 1.01722 loss)
I0603 04:36:30.039046   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.12792 (* 0.3 = 0.338375 loss)
I0603 04:36:30.039052   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02562 (* 0.3 = 0.307687 loss)
I0603 04:36:30.039062   861 sgd_solver.cpp:176] Iteration 148, lr = 0.00919692
I0603 04:36:37.934818   861 solver.cpp:316] Iteration 150, loss = 1.68736
I0603 04:36:37.934877   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:36:37.934893   861 solver.cpp:332]     Train net output #1: loss = 1.0217 (* 1 = 1.0217 loss)
I0603 04:36:37.934900   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.14344 (* 0.3 = 0.343032 loss)
I0603 04:36:37.934907   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0754 (* 0.3 = 0.32262 loss)
I0603 04:36:37.934919   861 sgd_solver.cpp:176] Iteration 150, lr = 0.00918559
I0603 04:36:45.632561   861 solver.cpp:316] Iteration 152, loss = 1.70101
I0603 04:36:45.632714   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:36:45.632732   861 solver.cpp:332]     Train net output #1: loss = 1.07203 (* 1 = 1.07203 loss)
I0603 04:36:45.632740   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.02921 (* 0.3 = 0.308764 loss)
I0603 04:36:45.632746   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0674 (* 0.3 = 0.320221 loss)
I0603 04:36:45.632757   861 sgd_solver.cpp:176] Iteration 152, lr = 0.00917424
I0603 04:36:53.284750   861 solver.cpp:316] Iteration 154, loss = 1.53145
I0603 04:36:53.284809   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:36:53.284823   861 solver.cpp:332]     Train net output #1: loss = 0.950393 (* 1 = 0.950393 loss)
I0603 04:36:53.284831   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.934154 (* 0.3 = 0.280246 loss)
I0603 04:36:53.284837   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0027 (* 0.3 = 0.300809 loss)
I0603 04:36:53.284848   861 sgd_solver.cpp:176] Iteration 154, lr = 0.00916288
I0603 04:37:00.901412   861 solver.cpp:316] Iteration 156, loss = 1.49454
I0603 04:37:00.901470   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:37:00.901484   861 solver.cpp:332]     Train net output #1: loss = 0.914666 (* 1 = 0.914666 loss)
I0603 04:37:00.901491   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.950576 (* 0.3 = 0.285173 loss)
I0603 04:37:00.901499   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.982348 (* 0.3 = 0.294704 loss)
I0603 04:37:00.901510   861 sgd_solver.cpp:176] Iteration 156, lr = 0.0091515
I0603 04:37:08.577572   861 solver.cpp:316] Iteration 158, loss = 1.50297
I0603 04:37:08.577628   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:37:08.577641   861 solver.cpp:332]     Train net output #1: loss = 0.896983 (* 1 = 0.896983 loss)
I0603 04:37:08.577648   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01551 (* 0.3 = 0.304654 loss)
I0603 04:37:08.577656   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00444 (* 0.3 = 0.301331 loss)
I0603 04:37:08.577666   861 sgd_solver.cpp:176] Iteration 158, lr = 0.00914011
I0603 04:37:12.425318   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_160.caffemodel
I0603 04:37:12.584076   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_160.solverstate
I0603 04:37:16.451517   861 solver.cpp:316] Iteration 160, loss = 1.60462
I0603 04:37:16.451694   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:37:16.451714   861 solver.cpp:332]     Train net output #1: loss = 1.00485 (* 1 = 1.00485 loss)
I0603 04:37:16.451725   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01928 (* 0.3 = 0.305784 loss)
I0603 04:37:16.451735   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.979967 (* 0.3 = 0.29399 loss)
I0603 04:37:16.451750   861 sgd_solver.cpp:176] Iteration 160, lr = 0.00912871
I0603 04:37:24.211079   861 solver.cpp:316] Iteration 162, loss = 1.7355
I0603 04:37:24.211136   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:37:24.211154   861 solver.cpp:332]     Train net output #1: loss = 1.08944 (* 1 = 1.08944 loss)
I0603 04:37:24.211165   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.993965 (* 0.3 = 0.29819 loss)
I0603 04:37:24.211176   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.15959 (* 0.3 = 0.347878 loss)
I0603 04:37:24.211192   861 sgd_solver.cpp:176] Iteration 162, lr = 0.00911729
I0603 04:37:39.559628   861 solver.cpp:316] Iteration 164, loss = 1.66455
I0603 04:37:39.559674   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 04:37:39.559687   861 solver.cpp:332]     Train net output #1: loss = 1.0299 (* 1 = 1.0299 loss)
I0603 04:37:39.559695   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.13091 (* 0.3 = 0.339273 loss)
I0603 04:37:39.559700   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.984572 (* 0.3 = 0.295372 loss)
I0603 04:37:39.559712   861 sgd_solver.cpp:176] Iteration 164, lr = 0.00910586
I0603 04:37:54.288138   861 solver.cpp:316] Iteration 166, loss = 1.82666
I0603 04:37:54.288235   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:37:54.288255   861 solver.cpp:332]     Train net output #1: loss = 1.13863 (* 1 = 1.13863 loss)
I0603 04:37:54.288266   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.18775 (* 0.3 = 0.356326 loss)
I0603 04:37:54.288276   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.1057 (* 0.3 = 0.33171 loss)
I0603 04:37:54.288291   861 sgd_solver.cpp:176] Iteration 166, lr = 0.00909441
I0603 04:38:04.270639   861 solver.cpp:316] Iteration 168, loss = 1.51564
I0603 04:38:04.270700   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:38:04.270719   861 solver.cpp:332]     Train net output #1: loss = 0.959748 (* 1 = 0.959748 loss)
I0603 04:38:04.270730   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.919675 (* 0.3 = 0.275903 loss)
I0603 04:38:04.270740   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.933303 (* 0.3 = 0.279991 loss)
I0603 04:38:04.270754   861 sgd_solver.cpp:176] Iteration 168, lr = 0.00908295
I0603 04:38:11.882388   861 solver.cpp:316] Iteration 170, loss = 1.61935
I0603 04:38:11.882452   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:38:11.882472   861 solver.cpp:332]     Train net output #1: loss = 1.0076 (* 1 = 1.0076 loss)
I0603 04:38:11.882483   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01365 (* 0.3 = 0.304094 loss)
I0603 04:38:11.882491   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02553 (* 0.3 = 0.307659 loss)
I0603 04:38:11.882508   861 sgd_solver.cpp:176] Iteration 170, lr = 0.00907147
I0603 04:38:19.500347   861 solver.cpp:316] Iteration 172, loss = 1.6617
I0603 04:38:19.500406   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:38:19.500423   861 solver.cpp:332]     Train net output #1: loss = 1.01735 (* 1 = 1.01735 loss)
I0603 04:38:19.500434   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07918 (* 0.3 = 0.323754 loss)
I0603 04:38:19.500444   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06866 (* 0.3 = 0.320599 loss)
I0603 04:38:19.500460   861 sgd_solver.cpp:176] Iteration 172, lr = 0.00905999
I0603 04:38:27.170441   861 solver.cpp:316] Iteration 174, loss = 1.61381
I0603 04:38:27.170559   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:38:27.170580   861 solver.cpp:332]     Train net output #1: loss = 0.99273 (* 1 = 0.99273 loss)
I0603 04:38:27.170591   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08619 (* 0.3 = 0.325858 loss)
I0603 04:38:27.170601   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.984067 (* 0.3 = 0.29522 loss)
I0603 04:38:27.170617   861 sgd_solver.cpp:176] Iteration 174, lr = 0.00904848
I0603 04:38:35.022742   861 solver.cpp:316] Iteration 176, loss = 1.63971
I0603 04:38:35.022799   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:38:35.022817   861 solver.cpp:332]     Train net output #1: loss = 1.01724 (* 1 = 1.01724 loss)
I0603 04:38:35.022828   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.941695 (* 0.3 = 0.282509 loss)
I0603 04:38:35.022840   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.1332 (* 0.3 = 0.339961 loss)
I0603 04:38:35.022855   861 sgd_solver.cpp:176] Iteration 176, lr = 0.00903696
I0603 04:38:42.721168   861 solver.cpp:316] Iteration 178, loss = 1.70123
I0603 04:38:42.721230   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:38:42.721248   861 solver.cpp:332]     Train net output #1: loss = 1.05851 (* 1 = 1.05851 loss)
I0603 04:38:42.721258   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06577 (* 0.3 = 0.31973 loss)
I0603 04:38:42.721268   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07663 (* 0.3 = 0.322989 loss)
I0603 04:38:42.721284   861 sgd_solver.cpp:176] Iteration 178, lr = 0.00902543
I0603 04:38:50.381229   861 solver.cpp:316] Iteration 180, loss = 1.63239
I0603 04:38:50.381294   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:38:50.381312   861 solver.cpp:332]     Train net output #1: loss = 0.993491 (* 1 = 0.993491 loss)
I0603 04:38:50.381323   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07552 (* 0.3 = 0.322656 loss)
I0603 04:38:50.381333   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05413 (* 0.3 = 0.31624 loss)
I0603 04:38:50.381348   861 sgd_solver.cpp:176] Iteration 180, lr = 0.00901388
I0603 04:38:58.043695   861 solver.cpp:316] Iteration 182, loss = 1.7396
I0603 04:38:58.043849   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:38:58.043864   861 solver.cpp:332]     Train net output #1: loss = 1.07384 (* 1 = 1.07384 loss)
I0603 04:38:58.043872   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0877 (* 0.3 = 0.326309 loss)
I0603 04:38:58.043879   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.13149 (* 0.3 = 0.339447 loss)
I0603 04:38:58.043889   861 sgd_solver.cpp:176] Iteration 182, lr = 0.00900231
I0603 04:39:05.681715   861 solver.cpp:316] Iteration 184, loss = 1.78936
I0603 04:39:05.681774   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:39:05.681787   861 solver.cpp:332]     Train net output #1: loss = 1.0704 (* 1 = 1.0704 loss)
I0603 04:39:05.681795   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.3099 (* 0.3 = 0.39297 loss)
I0603 04:39:05.681802   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08662 (* 0.3 = 0.325986 loss)
I0603 04:39:05.681813   861 sgd_solver.cpp:176] Iteration 184, lr = 0.00899074
I0603 04:39:13.264647   861 solver.cpp:316] Iteration 186, loss = 1.35518
I0603 04:39:13.264711   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:39:13.264729   861 solver.cpp:332]     Train net output #1: loss = 0.860426 (* 1 = 0.860426 loss)
I0603 04:39:13.264740   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847393 (* 0.3 = 0.254218 loss)
I0603 04:39:13.264750   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.801782 (* 0.3 = 0.240535 loss)
I0603 04:39:13.264765   861 sgd_solver.cpp:176] Iteration 186, lr = 0.00897914
I0603 04:39:20.868660   861 solver.cpp:316] Iteration 188, loss = 1.2525
I0603 04:39:20.868721   861 solver.cpp:332]     Train net output #0: accuracy = 0.75
I0603 04:39:20.868741   861 solver.cpp:332]     Train net output #1: loss = 0.782786 (* 1 = 0.782786 loss)
I0603 04:39:20.868751   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.784936 (* 0.3 = 0.235481 loss)
I0603 04:39:20.868760   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.780791 (* 0.3 = 0.234237 loss)
I0603 04:39:20.868774   861 sgd_solver.cpp:176] Iteration 188, lr = 0.00896753
I0603 04:39:28.547127   861 solver.cpp:316] Iteration 190, loss = 1.60609
I0603 04:39:28.547241   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:39:28.547261   861 solver.cpp:332]     Train net output #1: loss = 1.00329 (* 1 = 1.00329 loss)
I0603 04:39:28.547271   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01747 (* 0.3 = 0.30524 loss)
I0603 04:39:28.547282   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.991865 (* 0.3 = 0.297559 loss)
I0603 04:39:28.547297   861 sgd_solver.cpp:176] Iteration 190, lr = 0.00895591
I0603 04:39:32.361351   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_192.caffemodel
I0603 04:39:32.521695   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_192.solverstate
I0603 04:39:36.645234   861 solver.cpp:316] Iteration 192, loss = 1.61472
I0603 04:39:36.645293   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:39:36.645305   861 solver.cpp:332]     Train net output #1: loss = 1.00748 (* 1 = 1.00748 loss)
I0603 04:39:36.645313   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08373 (* 0.3 = 0.325119 loss)
I0603 04:39:36.645321   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.940405 (* 0.3 = 0.282122 loss)
I0603 04:39:36.645332   861 sgd_solver.cpp:176] Iteration 192, lr = 0.00894427
I0603 04:39:44.299461   861 solver.cpp:316] Iteration 194, loss = 1.83642
I0603 04:39:44.299517   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 04:39:44.299530   861 solver.cpp:332]     Train net output #1: loss = 1.11535 (* 1 = 1.11535 loss)
I0603 04:39:44.299537   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.24405 (* 0.3 = 0.373214 loss)
I0603 04:39:44.299545   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.1595 (* 0.3 = 0.347849 loss)
I0603 04:39:44.299556   861 sgd_solver.cpp:176] Iteration 194, lr = 0.00893262
I0603 04:39:59.621140   861 solver.cpp:316] Iteration 196, loss = 1.56168
I0603 04:39:59.621280   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:39:59.621301   861 solver.cpp:332]     Train net output #1: loss = 0.97575 (* 1 = 0.97575 loss)
I0603 04:39:59.621320   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.98638 (* 0.3 = 0.295914 loss)
I0603 04:39:59.621325   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.966714 (* 0.3 = 0.290014 loss)
I0603 04:39:59.621336   861 sgd_solver.cpp:176] Iteration 196, lr = 0.00892095
I0603 04:40:14.336874   861 solver.cpp:316] Iteration 198, loss = 1.734
I0603 04:40:14.336933   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:40:14.336951   861 solver.cpp:332]     Train net output #1: loss = 1.08439 (* 1 = 1.08439 loss)
I0603 04:40:14.336961   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.11265 (* 0.3 = 0.333796 loss)
I0603 04:40:14.336971   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05272 (* 0.3 = 0.315816 loss)
I0603 04:40:14.336984   861 sgd_solver.cpp:176] Iteration 198, lr = 0.00890926
I0603 04:40:24.171983   861 solver.cpp:316] Iteration 200, loss = 1.45941
I0603 04:40:24.172039   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:40:24.172057   861 solver.cpp:332]     Train net output #1: loss = 0.900994 (* 1 = 0.900994 loss)
I0603 04:40:24.172068   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.929085 (* 0.3 = 0.278725 loss)
I0603 04:40:24.172078   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.932304 (* 0.3 = 0.279691 loss)
I0603 04:40:24.172096   861 sgd_solver.cpp:176] Iteration 200, lr = 0.00889757
I0603 04:40:31.829006   861 solver.cpp:316] Iteration 202, loss = 1.58015
I0603 04:40:31.829113   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:40:31.829133   861 solver.cpp:332]     Train net output #1: loss = 0.977433 (* 1 = 0.977433 loss)
I0603 04:40:31.829144   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.965693 (* 0.3 = 0.289708 loss)
I0603 04:40:31.829154   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04337 (* 0.3 = 0.313011 loss)
I0603 04:40:31.829169   861 sgd_solver.cpp:176] Iteration 202, lr = 0.00888585
I0603 04:40:39.764925   861 solver.cpp:316] Iteration 204, loss = 1.72899
I0603 04:40:39.764986   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:40:39.764999   861 solver.cpp:332]     Train net output #1: loss = 1.04962 (* 1 = 1.04962 loss)
I0603 04:40:39.765007   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.22625 (* 0.3 = 0.367875 loss)
I0603 04:40:39.765014   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03831 (* 0.3 = 0.311493 loss)
I0603 04:40:39.765025   861 sgd_solver.cpp:176] Iteration 204, lr = 0.00887412
I0603 04:40:47.459444   861 solver.cpp:316] Iteration 206, loss = 1.57305
I0603 04:40:47.459499   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:40:47.459512   861 solver.cpp:332]     Train net output #1: loss = 0.985124 (* 1 = 0.985124 loss)
I0603 04:40:47.459520   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01682 (* 0.3 = 0.305047 loss)
I0603 04:40:47.459527   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.942923 (* 0.3 = 0.282877 loss)
I0603 04:40:47.459537   861 sgd_solver.cpp:176] Iteration 206, lr = 0.00886237
I0603 04:40:55.113518   861 solver.cpp:316] Iteration 208, loss = 1.64542
I0603 04:40:55.113582   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:40:55.113603   861 solver.cpp:332]     Train net output #1: loss = 1.03993 (* 1 = 1.03993 loss)
I0603 04:40:55.113613   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00165 (* 0.3 = 0.300495 loss)
I0603 04:40:55.113623   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01664 (* 0.3 = 0.304991 loss)
I0603 04:40:55.113638   861 sgd_solver.cpp:176] Iteration 208, lr = 0.00885061
I0603 04:41:02.698828   861 solver.cpp:316] Iteration 210, loss = 1.45007
I0603 04:41:02.698961   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:41:02.698983   861 solver.cpp:332]     Train net output #1: loss = 0.881903 (* 1 = 0.881903 loss)
I0603 04:41:02.698997   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.9876 (* 0.3 = 0.29628 loss)
I0603 04:41:02.699007   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.906286 (* 0.3 = 0.271886 loss)
I0603 04:41:02.699021   861 sgd_solver.cpp:176] Iteration 210, lr = 0.00883883
I0603 04:41:10.343504   861 solver.cpp:316] Iteration 212, loss = 1.64056
I0603 04:41:10.343564   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:41:10.343577   861 solver.cpp:332]     Train net output #1: loss = 1.01931 (* 1 = 1.01931 loss)
I0603 04:41:10.343585   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09289 (* 0.3 = 0.327868 loss)
I0603 04:41:10.343591   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.97794 (* 0.3 = 0.293382 loss)
I0603 04:41:10.343602   861 sgd_solver.cpp:176] Iteration 212, lr = 0.00882704
I0603 04:41:17.943302   861 solver.cpp:316] Iteration 214, loss = 1.79059
I0603 04:41:17.943361   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:41:17.943374   861 solver.cpp:332]     Train net output #1: loss = 1.09129 (* 1 = 1.09129 loss)
I0603 04:41:17.943382   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.2609 (* 0.3 = 0.37827 loss)
I0603 04:41:17.943389   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07009 (* 0.3 = 0.321028 loss)
I0603 04:41:17.943400   861 sgd_solver.cpp:176] Iteration 214, lr = 0.00881523
I0603 04:41:25.612432   861 solver.cpp:316] Iteration 216, loss = 1.58976
I0603 04:41:25.612494   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:41:25.612507   861 solver.cpp:332]     Train net output #1: loss = 0.966406 (* 1 = 0.966406 loss)
I0603 04:41:25.612515   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05042 (* 0.3 = 0.315127 loss)
I0603 04:41:25.612522   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02744 (* 0.3 = 0.308231 loss)
I0603 04:41:25.612534   861 sgd_solver.cpp:176] Iteration 216, lr = 0.00880341
I0603 04:41:33.234891   861 solver.cpp:316] Iteration 218, loss = 1.44678
I0603 04:41:33.235055   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:41:33.235076   861 solver.cpp:332]     Train net output #1: loss = 0.892596 (* 1 = 0.892596 loss)
I0603 04:41:33.235087   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.97016 (* 0.3 = 0.291048 loss)
I0603 04:41:33.235097   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.877134 (* 0.3 = 0.26314 loss)
I0603 04:41:33.235112   861 sgd_solver.cpp:176] Iteration 218, lr = 0.00879157
I0603 04:41:41.120582   861 solver.cpp:316] Iteration 220, loss = 1.51047
I0603 04:41:41.120641   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:41:41.120654   861 solver.cpp:332]     Train net output #1: loss = 0.927871 (* 1 = 0.927871 loss)
I0603 04:41:41.120662   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.986121 (* 0.3 = 0.295836 loss)
I0603 04:41:41.120668   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.955883 (* 0.3 = 0.286765 loss)
I0603 04:41:41.120679   861 sgd_solver.cpp:176] Iteration 220, lr = 0.00877971
I0603 04:41:48.795310   861 solver.cpp:316] Iteration 222, loss = 1.74859
I0603 04:41:48.795364   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:41:48.795377   861 solver.cpp:332]     Train net output #1: loss = 1.09902 (* 1 = 1.09902 loss)
I0603 04:41:48.795385   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06921 (* 0.3 = 0.320763 loss)
I0603 04:41:48.795392   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09602 (* 0.3 = 0.328805 loss)
I0603 04:41:48.795403   861 sgd_solver.cpp:176] Iteration 222, lr = 0.00876784
I0603 04:41:52.606767   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_224.caffemodel
I0603 04:41:52.769750   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_224.solverstate
I0603 04:41:56.659744   861 solver.cpp:316] Iteration 224, loss = 1.61211
I0603 04:41:56.659797   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:41:56.659811   861 solver.cpp:332]     Train net output #1: loss = 0.987599 (* 1 = 0.987599 loss)
I0603 04:41:56.659818   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07224 (* 0.3 = 0.321672 loss)
I0603 04:41:56.659826   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00945 (* 0.3 = 0.302836 loss)
I0603 04:41:56.659835   861 sgd_solver.cpp:176] Iteration 224, lr = 0.00875595
I0603 04:42:04.315476   861 solver.cpp:316] Iteration 226, loss = 1.68207
I0603 04:42:04.315589   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:42:04.315603   861 solver.cpp:332]     Train net output #1: loss = 1.04988 (* 1 = 1.04988 loss)
I0603 04:42:04.315611   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04684 (* 0.3 = 0.314052 loss)
I0603 04:42:04.315618   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06049 (* 0.3 = 0.318147 loss)
I0603 04:42:04.315630   861 sgd_solver.cpp:176] Iteration 226, lr = 0.00874405
I0603 04:42:19.403923   861 solver.cpp:316] Iteration 228, loss = 1.70952
I0603 04:42:19.403969   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:42:19.403982   861 solver.cpp:332]     Train net output #1: loss = 1.05086 (* 1 = 1.05086 loss)
I0603 04:42:19.403990   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.1225 (* 0.3 = 0.33675 loss)
I0603 04:42:19.403996   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07305 (* 0.3 = 0.321916 loss)
I0603 04:42:19.404008   861 sgd_solver.cpp:176] Iteration 228, lr = 0.00873212
I0603 04:42:33.902518   861 solver.cpp:316] Iteration 230, loss = 1.59401
I0603 04:42:33.902567   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:42:33.902580   861 solver.cpp:332]     Train net output #1: loss = 1.00248 (* 1 = 1.00248 loss)
I0603 04:42:33.902588   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.994379 (* 0.3 = 0.298314 loss)
I0603 04:42:33.902595   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.977395 (* 0.3 = 0.293218 loss)
I0603 04:42:33.902606   861 sgd_solver.cpp:176] Iteration 230, lr = 0.00872019
I0603 04:42:44.255012   861 solver.cpp:316] Iteration 232, loss = 1.72774
I0603 04:42:44.255134   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:42:44.255149   861 solver.cpp:332]     Train net output #1: loss = 1.07101 (* 1 = 1.07101 loss)
I0603 04:42:44.255157   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10415 (* 0.3 = 0.331245 loss)
I0603 04:42:44.255164   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08496 (* 0.3 = 0.325488 loss)
I0603 04:42:44.255175   861 sgd_solver.cpp:176] Iteration 232, lr = 0.00870823
I0603 04:42:51.907409   861 solver.cpp:316] Iteration 234, loss = 1.60464
I0603 04:42:51.907470   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:42:51.907485   861 solver.cpp:332]     Train net output #1: loss = 1.01355 (* 1 = 1.01355 loss)
I0603 04:42:51.907491   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.923786 (* 0.3 = 0.277136 loss)
I0603 04:42:51.907498   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04654 (* 0.3 = 0.313962 loss)
I0603 04:42:51.907510   861 sgd_solver.cpp:176] Iteration 234, lr = 0.00869626
I0603 04:42:59.522142   861 solver.cpp:316] Iteration 236, loss = 1.79681
I0603 04:42:59.522202   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:42:59.522217   861 solver.cpp:332]     Train net output #1: loss = 1.10606 (* 1 = 1.10606 loss)
I0603 04:42:59.522224   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.16941 (* 0.3 = 0.350823 loss)
I0603 04:42:59.522231   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.13307 (* 0.3 = 0.339922 loss)
I0603 04:42:59.522243   861 sgd_solver.cpp:176] Iteration 236, lr = 0.00868428
I0603 04:43:07.166008   861 solver.cpp:316] Iteration 238, loss = 1.64626
I0603 04:43:07.166059   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:43:07.166072   861 solver.cpp:332]     Train net output #1: loss = 1.02448 (* 1 = 1.02448 loss)
I0603 04:43:07.166080   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0084 (* 0.3 = 0.302519 loss)
I0603 04:43:07.166086   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0642 (* 0.3 = 0.319261 loss)
I0603 04:43:07.166097   861 sgd_solver.cpp:176] Iteration 238, lr = 0.00867227
I0603 04:43:14.787331   861 solver.cpp:316] Iteration 240, loss = 1.60539
I0603 04:43:14.787461   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:43:14.787475   861 solver.cpp:332]     Train net output #1: loss = 0.981538 (* 1 = 0.981538 loss)
I0603 04:43:14.787482   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09577 (* 0.3 = 0.32873 loss)
I0603 04:43:14.787489   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.983727 (* 0.3 = 0.295118 loss)
I0603 04:43:14.787500   861 sgd_solver.cpp:176] Iteration 240, lr = 0.00866025
I0603 04:43:22.467170   861 solver.cpp:316] Iteration 242, loss = 1.56333
I0603 04:43:22.467229   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:43:22.467247   861 solver.cpp:332]     Train net output #1: loss = 0.97192 (* 1 = 0.97192 loss)
I0603 04:43:22.467258   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05254 (* 0.3 = 0.315762 loss)
I0603 04:43:22.467268   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.918816 (* 0.3 = 0.275645 loss)
I0603 04:43:22.467284   861 sgd_solver.cpp:176] Iteration 242, lr = 0.00864822
I0603 04:43:30.077832   861 solver.cpp:316] Iteration 244, loss = 1.39565
I0603 04:43:30.077893   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:43:30.077911   861 solver.cpp:332]     Train net output #1: loss = 0.8641 (* 1 = 0.8641 loss)
I0603 04:43:30.077924   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.908529 (* 0.3 = 0.272559 loss)
I0603 04:43:30.077934   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.863289 (* 0.3 = 0.258987 loss)
I0603 04:43:30.077950   861 sgd_solver.cpp:176] Iteration 244, lr = 0.00863616
I0603 04:43:37.953965   861 solver.cpp:316] Iteration 246, loss = 1.8679
I0603 04:43:37.954027   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:43:37.954046   861 solver.cpp:332]     Train net output #1: loss = 1.14403 (* 1 = 1.14403 loss)
I0603 04:43:37.954056   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.25621 (* 0.3 = 0.376862 loss)
I0603 04:43:37.954066   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.15668 (* 0.3 = 0.347005 loss)
I0603 04:43:37.954082   861 sgd_solver.cpp:176] Iteration 246, lr = 0.00862409
I0603 04:43:45.595528   861 solver.cpp:316] Iteration 248, loss = 1.3435
I0603 04:43:45.595700   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 04:43:45.595719   861 solver.cpp:332]     Train net output #1: loss = 0.846199 (* 1 = 0.846199 loss)
I0603 04:43:45.595731   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.854115 (* 0.3 = 0.256234 loss)
I0603 04:43:45.595741   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.803554 (* 0.3 = 0.241066 loss)
I0603 04:43:45.595757   861 sgd_solver.cpp:176] Iteration 248, lr = 0.00861201
I0603 04:43:53.222349   861 solver.cpp:316] Iteration 250, loss = 1.45945
I0603 04:43:53.222406   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:43:53.222424   861 solver.cpp:332]     Train net output #1: loss = 0.913427 (* 1 = 0.913427 loss)
I0603 04:43:53.222434   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.87764 (* 0.3 = 0.263292 loss)
I0603 04:43:53.222445   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.942448 (* 0.3 = 0.282735 loss)
I0603 04:43:53.222460   861 sgd_solver.cpp:176] Iteration 250, lr = 0.0085999
I0603 04:44:00.833786   861 solver.cpp:316] Iteration 252, loss = 1.72037
I0603 04:44:00.833849   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:44:00.833869   861 solver.cpp:332]     Train net output #1: loss = 1.07356 (* 1 = 1.07356 loss)
I0603 04:44:00.833878   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01971 (* 0.3 = 0.305914 loss)
I0603 04:44:00.833889   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.13631 (* 0.3 = 0.340894 loss)
I0603 04:44:00.833902   861 sgd_solver.cpp:176] Iteration 252, lr = 0.00858778
I0603 04:44:08.499336   861 solver.cpp:316] Iteration 254, loss = 2.00035
I0603 04:44:08.499399   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 04:44:08.499421   861 solver.cpp:332]     Train net output #1: loss = 1.23099 (* 1 = 1.23099 loss)
I0603 04:44:08.499433   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.30413 (* 0.3 = 0.391238 loss)
I0603 04:44:08.499444   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.2604 (* 0.3 = 0.378121 loss)
I0603 04:44:08.499460   861 sgd_solver.cpp:176] Iteration 254, lr = 0.00857564
I0603 04:44:12.329890   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_256.caffemodel
I0603 04:44:12.489521   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_256.solverstate
I0603 04:44:16.328233   861 solver.cpp:316] Iteration 256, loss = 1.53758
I0603 04:44:16.328333   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:44:16.328348   861 solver.cpp:332]     Train net output #1: loss = 0.94977 (* 1 = 0.94977 loss)
I0603 04:44:16.328356   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.977369 (* 0.3 = 0.293211 loss)
I0603 04:44:16.328363   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.981987 (* 0.3 = 0.294596 loss)
I0603 04:44:16.328374   861 sgd_solver.cpp:176] Iteration 256, lr = 0.00856349
I0603 04:44:24.005904   861 solver.cpp:316] Iteration 258, loss = 1.71528
I0603 04:44:24.005964   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:44:24.005978   861 solver.cpp:332]     Train net output #1: loss = 1.07779 (* 1 = 1.07779 loss)
I0603 04:44:24.005985   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09216 (* 0.3 = 0.327648 loss)
I0603 04:44:24.005991   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03281 (* 0.3 = 0.309843 loss)
I0603 04:44:24.006002   861 sgd_solver.cpp:176] Iteration 258, lr = 0.00855132
I0603 04:44:39.328852   861 solver.cpp:316] Iteration 260, loss = 1.56276
I0603 04:44:39.328897   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:44:39.328909   861 solver.cpp:332]     Train net output #1: loss = 0.934999 (* 1 = 0.934999 loss)
I0603 04:44:39.328917   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10041 (* 0.3 = 0.330122 loss)
I0603 04:44:39.328923   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.992128 (* 0.3 = 0.297638 loss)
I0603 04:44:39.328934   861 sgd_solver.cpp:176] Iteration 260, lr = 0.00853913
I0603 04:44:54.046315   861 solver.cpp:316] Iteration 262, loss = 1.46133
I0603 04:44:54.046440   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:44:54.046454   861 solver.cpp:332]     Train net output #1: loss = 0.907805 (* 1 = 0.907805 loss)
I0603 04:44:54.046463   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.909669 (* 0.3 = 0.272901 loss)
I0603 04:44:54.046468   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.935418 (* 0.3 = 0.280625 loss)
I0603 04:44:54.046480   861 sgd_solver.cpp:176] Iteration 262, lr = 0.00852692
I0603 04:45:03.944641   861 solver.cpp:316] Iteration 264, loss = 1.84207
I0603 04:45:03.944694   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 04:45:03.944708   861 solver.cpp:332]     Train net output #1: loss = 1.13101 (* 1 = 1.13101 loss)
I0603 04:45:03.944715   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.19142 (* 0.3 = 0.357427 loss)
I0603 04:45:03.944722   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.17878 (* 0.3 = 0.353635 loss)
I0603 04:45:03.944732   861 sgd_solver.cpp:176] Iteration 264, lr = 0.00851469
I0603 04:45:11.559981   861 solver.cpp:316] Iteration 266, loss = 1.6714
I0603 04:45:11.560036   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 04:45:11.560050   861 solver.cpp:332]     Train net output #1: loss = 1.04976 (* 1 = 1.04976 loss)
I0603 04:45:11.560058   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05636 (* 0.3 = 0.316907 loss)
I0603 04:45:11.560070   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01578 (* 0.3 = 0.304734 loss)
I0603 04:45:11.560086   861 sgd_solver.cpp:176] Iteration 266, lr = 0.00850245
I0603 04:45:19.212563   861 solver.cpp:316] Iteration 268, loss = 1.66431
I0603 04:45:19.212618   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:45:19.212632   861 solver.cpp:332]     Train net output #1: loss = 1.03446 (* 1 = 1.03446 loss)
I0603 04:45:19.212641   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04953 (* 0.3 = 0.314858 loss)
I0603 04:45:19.212647   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04996 (* 0.3 = 0.314989 loss)
I0603 04:45:19.212657   861 sgd_solver.cpp:176] Iteration 268, lr = 0.00849019
I0603 04:45:26.872467   861 solver.cpp:316] Iteration 270, loss = 1.55274
I0603 04:45:26.872572   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 04:45:26.872586   861 solver.cpp:332]     Train net output #1: loss = 0.918937 (* 1 = 0.918937 loss)
I0603 04:45:26.872594   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.13681 (* 0.3 = 0.341042 loss)
I0603 04:45:26.872601   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.975863 (* 0.3 = 0.292759 loss)
I0603 04:45:26.872611   861 sgd_solver.cpp:176] Iteration 270, lr = 0.00847791
I0603 04:45:34.523682   861 solver.cpp:316] Iteration 272, loss = 1.59908
I0603 04:45:34.523737   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:45:34.523751   861 solver.cpp:332]     Train net output #1: loss = 0.972701 (* 1 = 0.972701 loss)
I0603 04:45:34.523758   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04631 (* 0.3 = 0.313894 loss)
I0603 04:45:34.523766   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04163 (* 0.3 = 0.31249 loss)
I0603 04:45:34.523777   861 sgd_solver.cpp:176] Iteration 272, lr = 0.00846562
I0603 04:45:42.373114   861 solver.cpp:316] Iteration 274, loss = 1.47962
I0603 04:45:42.373175   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:45:42.373188   861 solver.cpp:332]     Train net output #1: loss = 0.932585 (* 1 = 0.932585 loss)
I0603 04:45:42.373195   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.897859 (* 0.3 = 0.269358 loss)
I0603 04:45:42.373203   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.925605 (* 0.3 = 0.277682 loss)
I0603 04:45:42.373214   861 sgd_solver.cpp:176] Iteration 274, lr = 0.0084533
I0603 04:45:50.049968   861 solver.cpp:316] Iteration 276, loss = 1.62888
I0603 04:45:50.050024   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:45:50.050040   861 solver.cpp:332]     Train net output #1: loss = 1.00294 (* 1 = 1.00294 loss)
I0603 04:45:50.050048   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04998 (* 0.3 = 0.314994 loss)
I0603 04:45:50.050055   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03649 (* 0.3 = 0.310946 loss)
I0603 04:45:50.050066   861 sgd_solver.cpp:176] Iteration 276, lr = 0.00844097
I0603 04:45:57.662794   861 solver.cpp:316] Iteration 278, loss = 1.66358
I0603 04:45:57.662928   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:45:57.662945   861 solver.cpp:332]     Train net output #1: loss = 1.03993 (* 1 = 1.03993 loss)
I0603 04:45:57.662951   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.986248 (* 0.3 = 0.295874 loss)
I0603 04:45:57.662957   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0926 (* 0.3 = 0.327779 loss)
I0603 04:45:57.662968   861 sgd_solver.cpp:176] Iteration 278, lr = 0.00842862
I0603 04:46:05.282337   861 solver.cpp:316] Iteration 280, loss = 1.3092
I0603 04:46:05.282392   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:46:05.282409   861 solver.cpp:332]     Train net output #1: loss = 0.826045 (* 1 = 0.826045 loss)
I0603 04:46:05.282420   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.806748 (* 0.3 = 0.242024 loss)
I0603 04:46:05.282430   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.803758 (* 0.3 = 0.241127 loss)
I0603 04:46:05.282445   861 sgd_solver.cpp:176] Iteration 280, lr = 0.00841625
I0603 04:46:12.941845   861 solver.cpp:316] Iteration 282, loss = 1.64584
I0603 04:46:12.941905   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:46:12.941925   861 solver.cpp:332]     Train net output #1: loss = 1.0247 (* 1 = 1.0247 loss)
I0603 04:46:12.941934   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.02431 (* 0.3 = 0.307293 loss)
I0603 04:46:12.941946   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04618 (* 0.3 = 0.313853 loss)
I0603 04:46:12.941959   861 sgd_solver.cpp:176] Iteration 282, lr = 0.00840387
I0603 04:46:20.617406   861 solver.cpp:316] Iteration 284, loss = 1.49991
I0603 04:46:20.617470   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:46:20.617489   861 solver.cpp:332]     Train net output #1: loss = 0.936976 (* 1 = 0.936976 loss)
I0603 04:46:20.617499   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.934485 (* 0.3 = 0.280346 loss)
I0603 04:46:20.617508   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.941952 (* 0.3 = 0.282586 loss)
I0603 04:46:20.617522   861 sgd_solver.cpp:176] Iteration 284, lr = 0.00839146
I0603 04:46:28.349779   861 solver.cpp:316] Iteration 286, loss = 1.73316
I0603 04:46:28.349885   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:46:28.349905   861 solver.cpp:332]     Train net output #1: loss = 1.05411 (* 1 = 1.05411 loss)
I0603 04:46:28.349916   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09882 (* 0.3 = 0.329646 loss)
I0603 04:46:28.349927   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.16467 (* 0.3 = 0.349402 loss)
I0603 04:46:28.349941   861 sgd_solver.cpp:176] Iteration 286, lr = 0.00837904
I0603 04:46:32.172816   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_288.caffemodel
I0603 04:46:32.339949   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_288.solverstate
I0603 04:46:36.409395   861 solver.cpp:316] Iteration 288, loss = 1.45988
I0603 04:46:36.409449   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:46:36.409462   861 solver.cpp:332]     Train net output #1: loss = 0.895503 (* 1 = 0.895503 loss)
I0603 04:46:36.409469   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.92979 (* 0.3 = 0.278937 loss)
I0603 04:46:36.409476   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.95148 (* 0.3 = 0.285444 loss)
I0603 04:46:36.409487   861 sgd_solver.cpp:176] Iteration 288, lr = 0.0083666
I0603 04:46:44.134903   861 solver.cpp:316] Iteration 290, loss = 1.65637
I0603 04:46:44.134956   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:46:44.134969   861 solver.cpp:332]     Train net output #1: loss = 1.01798 (* 1 = 1.01798 loss)
I0603 04:46:44.134977   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10063 (* 0.3 = 0.330189 loss)
I0603 04:46:44.134984   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02734 (* 0.3 = 0.308201 loss)
I0603 04:46:44.134994   861 sgd_solver.cpp:176] Iteration 290, lr = 0.00835414
I0603 04:46:59.188798   861 solver.cpp:316] Iteration 292, loss = 1.69445
I0603 04:46:59.198303   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:46:59.198321   861 solver.cpp:332]     Train net output #1: loss = 1.04407 (* 1 = 1.04407 loss)
I0603 04:46:59.198328   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.11581 (* 0.3 = 0.334744 loss)
I0603 04:46:59.198334   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05212 (* 0.3 = 0.315635 loss)
I0603 04:46:59.198345   861 sgd_solver.cpp:176] Iteration 292, lr = 0.00834166
I0603 04:47:13.963277   861 solver.cpp:316] Iteration 294, loss = 1.59774
I0603 04:47:13.963333   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:47:13.963352   861 solver.cpp:332]     Train net output #1: loss = 0.993383 (* 1 = 0.993383 loss)
I0603 04:47:13.963363   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07359 (* 0.3 = 0.322077 loss)
I0603 04:47:13.963373   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.94092 (* 0.3 = 0.282276 loss)
I0603 04:47:13.963387   861 sgd_solver.cpp:176] Iteration 294, lr = 0.00832917
I0603 04:47:23.983566   861 solver.cpp:316] Iteration 296, loss = 1.80168
I0603 04:47:23.983628   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:47:23.983644   861 solver.cpp:332]     Train net output #1: loss = 1.13862 (* 1 = 1.13862 loss)
I0603 04:47:23.983654   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.12095 (* 0.3 = 0.336286 loss)
I0603 04:47:23.983664   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08924 (* 0.3 = 0.326773 loss)
I0603 04:47:23.983680   861 sgd_solver.cpp:176] Iteration 296, lr = 0.00831665
I0603 04:47:31.634467   861 solver.cpp:316] Iteration 298, loss = 1.57488
I0603 04:47:31.634567   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:47:31.634587   861 solver.cpp:332]     Train net output #1: loss = 0.9563 (* 1 = 0.9563 loss)
I0603 04:47:31.634598   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07733 (* 0.3 = 0.323199 loss)
I0603 04:47:31.634608   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.984601 (* 0.3 = 0.29538 loss)
I0603 04:47:31.634623   861 sgd_solver.cpp:176] Iteration 298, lr = 0.00830412
I0603 04:47:39.537503   861 solver.cpp:316] Iteration 300, loss = 1.69713
I0603 04:47:39.537567   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:47:39.537586   861 solver.cpp:332]     Train net output #1: loss = 1.03085 (* 1 = 1.03085 loss)
I0603 04:47:39.537596   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.11417 (* 0.3 = 0.334251 loss)
I0603 04:47:39.537607   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10677 (* 0.3 = 0.332032 loss)
I0603 04:47:39.537621   861 sgd_solver.cpp:176] Iteration 300, lr = 0.00829156
I0603 04:47:47.175611   861 solver.cpp:316] Iteration 302, loss = 1.56118
I0603 04:47:47.175668   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:47:47.175686   861 solver.cpp:332]     Train net output #1: loss = 0.951596 (* 1 = 0.951596 loss)
I0603 04:47:47.175698   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08511 (* 0.3 = 0.325532 loss)
I0603 04:47:47.175706   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.946834 (* 0.3 = 0.28405 loss)
I0603 04:47:47.175720   861 sgd_solver.cpp:176] Iteration 302, lr = 0.00827899
I0603 04:47:54.809639   861 solver.cpp:316] Iteration 304, loss = 1.70529
I0603 04:47:54.809700   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:47:54.809718   861 solver.cpp:332]     Train net output #1: loss = 1.03686 (* 1 = 1.03686 loss)
I0603 04:47:54.809728   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.16427 (* 0.3 = 0.349281 loss)
I0603 04:47:54.809738   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06381 (* 0.3 = 0.319144 loss)
I0603 04:47:54.809752   861 sgd_solver.cpp:176] Iteration 304, lr = 0.0082664
I0603 04:48:02.445907   861 solver.cpp:316] Iteration 306, loss = 1.57554
I0603 04:48:02.446089   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:48:02.446110   861 solver.cpp:332]     Train net output #1: loss = 0.961416 (* 1 = 0.961416 loss)
I0603 04:48:02.446120   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05689 (* 0.3 = 0.317068 loss)
I0603 04:48:02.446130   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.990187 (* 0.3 = 0.297056 loss)
I0603 04:48:02.446144   861 sgd_solver.cpp:176] Iteration 306, lr = 0.00825379
I0603 04:48:10.065201   861 solver.cpp:316] Iteration 308, loss = 1.68356
I0603 04:48:10.065266   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:48:10.065285   861 solver.cpp:332]     Train net output #1: loss = 1.02764 (* 1 = 1.02764 loss)
I0603 04:48:10.065296   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.14724 (* 0.3 = 0.344171 loss)
I0603 04:48:10.065306   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03915 (* 0.3 = 0.311746 loss)
I0603 04:48:10.065320   861 sgd_solver.cpp:176] Iteration 308, lr = 0.00824116
I0603 04:48:17.627353   861 solver.cpp:316] Iteration 310, loss = 1.63364
I0603 04:48:17.627408   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:48:17.627423   861 solver.cpp:332]     Train net output #1: loss = 1.0174 (* 1 = 1.0174 loss)
I0603 04:48:17.627430   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00892 (* 0.3 = 0.302676 loss)
I0603 04:48:17.627437   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04522 (* 0.3 = 0.313565 loss)
I0603 04:48:17.627447   861 sgd_solver.cpp:176] Iteration 310, lr = 0.00822851
I0603 04:48:25.320894   861 solver.cpp:316] Iteration 312, loss = 1.6508
I0603 04:48:25.320955   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:48:25.320967   861 solver.cpp:332]     Train net output #1: loss = 1.00368 (* 1 = 1.00368 loss)
I0603 04:48:25.320974   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08655 (* 0.3 = 0.325966 loss)
I0603 04:48:25.320981   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07051 (* 0.3 = 0.321153 loss)
I0603 04:48:25.320992   861 sgd_solver.cpp:176] Iteration 312, lr = 0.00821584
I0603 04:48:33.025817   861 solver.cpp:316] Iteration 314, loss = 1.69792
I0603 04:48:33.025928   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:48:33.025943   861 solver.cpp:332]     Train net output #1: loss = 1.04801 (* 1 = 1.04801 loss)
I0603 04:48:33.025949   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.12287 (* 0.3 = 0.33686 loss)
I0603 04:48:33.025956   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04351 (* 0.3 = 0.313052 loss)
I0603 04:48:33.025967   861 sgd_solver.cpp:176] Iteration 314, lr = 0.00820315
I0603 04:48:40.960984   861 solver.cpp:316] Iteration 316, loss = 1.46349
I0603 04:48:40.961038   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:48:40.961052   861 solver.cpp:332]     Train net output #1: loss = 0.910323 (* 1 = 0.910323 loss)
I0603 04:48:40.961060   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.885044 (* 0.3 = 0.265513 loss)
I0603 04:48:40.961066   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.95883 (* 0.3 = 0.287649 loss)
I0603 04:48:40.961077   861 sgd_solver.cpp:176] Iteration 316, lr = 0.00819044
I0603 04:48:48.583014   861 solver.cpp:316] Iteration 318, loss = 1.43318
I0603 04:48:48.583070   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:48:48.583082   861 solver.cpp:332]     Train net output #1: loss = 0.881993 (* 1 = 0.881993 loss)
I0603 04:48:48.583091   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.917202 (* 0.3 = 0.27516 loss)
I0603 04:48:48.583096   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.920081 (* 0.3 = 0.276024 loss)
I0603 04:48:48.583107   861 sgd_solver.cpp:176] Iteration 318, lr = 0.00817771
I0603 04:48:52.416973   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_320.caffemodel
I0603 04:48:52.576081   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_320.solverstate
I0603 04:48:56.435643   861 solver.cpp:316] Iteration 320, loss = 1.50942
I0603 04:48:56.435698   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:48:56.435710   861 solver.cpp:332]     Train net output #1: loss = 0.907321 (* 1 = 0.907321 loss)
I0603 04:48:56.435719   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06369 (* 0.3 = 0.319108 loss)
I0603 04:48:56.435724   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.943307 (* 0.3 = 0.282992 loss)
I0603 04:48:56.435735   861 sgd_solver.cpp:176] Iteration 320, lr = 0.00816497
I0603 04:49:04.082005   861 solver.cpp:316] Iteration 322, loss = 1.56717
I0603 04:49:04.082118   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:49:04.082132   861 solver.cpp:332]     Train net output #1: loss = 0.954982 (* 1 = 0.954982 loss)
I0603 04:49:04.082139   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07048 (* 0.3 = 0.321145 loss)
I0603 04:49:04.082146   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.970149 (* 0.3 = 0.291045 loss)
I0603 04:49:04.082157   861 sgd_solver.cpp:176] Iteration 322, lr = 0.0081522
I0603 04:49:19.074324   861 solver.cpp:316] Iteration 324, loss = 1.77927
I0603 04:49:19.074368   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 04:49:19.074380   861 solver.cpp:332]     Train net output #1: loss = 1.09327 (* 1 = 1.09327 loss)
I0603 04:49:19.074388   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.16199 (* 0.3 = 0.348596 loss)
I0603 04:49:19.074394   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.12468 (* 0.3 = 0.337405 loss)
I0603 04:49:19.074405   861 sgd_solver.cpp:176] Iteration 324, lr = 0.00813941
I0603 04:49:33.842315   861 solver.cpp:316] Iteration 326, loss = 1.63571
I0603 04:49:33.842376   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:49:33.842396   861 solver.cpp:332]     Train net output #1: loss = 1.01823 (* 1 = 1.01823 loss)
I0603 04:49:33.842406   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01727 (* 0.3 = 0.305182 loss)
I0603 04:49:33.842416   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04101 (* 0.3 = 0.312303 loss)
I0603 04:49:33.842429   861 sgd_solver.cpp:176] Iteration 326, lr = 0.0081266
I0603 04:49:43.982859   861 solver.cpp:316] Iteration 328, loss = 1.79237
I0603 04:49:43.983017   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:49:43.983038   861 solver.cpp:332]     Train net output #1: loss = 1.14268 (* 1 = 1.14268 loss)
I0603 04:49:43.983050   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07117 (* 0.3 = 0.32135 loss)
I0603 04:49:43.983060   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09449 (* 0.3 = 0.328346 loss)
I0603 04:49:43.983075   861 sgd_solver.cpp:176] Iteration 328, lr = 0.00811377
I0603 04:49:51.655158   861 solver.cpp:316] Iteration 330, loss = 1.62591
I0603 04:49:51.655221   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:49:51.655241   861 solver.cpp:332]     Train net output #1: loss = 1.01405 (* 1 = 1.01405 loss)
I0603 04:49:51.655251   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08493 (* 0.3 = 0.325479 loss)
I0603 04:49:51.655261   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.954601 (* 0.3 = 0.28638 loss)
I0603 04:49:51.655275   861 sgd_solver.cpp:176] Iteration 330, lr = 0.00810093
I0603 04:49:59.262918   861 solver.cpp:316] Iteration 332, loss = 1.60009
I0603 04:49:59.262975   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:49:59.262989   861 solver.cpp:332]     Train net output #1: loss = 0.970385 (* 1 = 0.970385 loss)
I0603 04:49:59.262996   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.14011 (* 0.3 = 0.342034 loss)
I0603 04:49:59.263002   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.958889 (* 0.3 = 0.287667 loss)
I0603 04:49:59.263012   861 sgd_solver.cpp:176] Iteration 332, lr = 0.00808806
I0603 04:50:06.881906   861 solver.cpp:316] Iteration 334, loss = 1.60708
I0603 04:50:06.881968   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:50:06.881983   861 solver.cpp:332]     Train net output #1: loss = 0.982204 (* 1 = 0.982204 loss)
I0603 04:50:06.881989   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06081 (* 0.3 = 0.318243 loss)
I0603 04:50:06.881995   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02212 (* 0.3 = 0.306635 loss)
I0603 04:50:06.882006   861 sgd_solver.cpp:176] Iteration 334, lr = 0.00807517
I0603 04:50:14.467115   861 solver.cpp:316] Iteration 336, loss = 1.58588
I0603 04:50:14.467270   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:50:14.467286   861 solver.cpp:332]     Train net output #1: loss = 0.978008 (* 1 = 0.978008 loss)
I0603 04:50:14.467293   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00833 (* 0.3 = 0.302498 loss)
I0603 04:50:14.467300   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01792 (* 0.3 = 0.305377 loss)
I0603 04:50:14.467311   861 sgd_solver.cpp:176] Iteration 336, lr = 0.00806226
I0603 04:50:22.073685   861 solver.cpp:316] Iteration 338, loss = 1.64599
I0603 04:50:22.073745   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:50:22.073760   861 solver.cpp:332]     Train net output #1: loss = 1.02674 (* 1 = 1.02674 loss)
I0603 04:50:22.073767   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06551 (* 0.3 = 0.319654 loss)
I0603 04:50:22.073776   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.998649 (* 0.3 = 0.299595 loss)
I0603 04:50:22.073786   861 sgd_solver.cpp:176] Iteration 338, lr = 0.00804933
I0603 04:50:29.760411   861 solver.cpp:316] Iteration 340, loss = 1.63637
I0603 04:50:29.760466   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:50:29.760479   861 solver.cpp:332]     Train net output #1: loss = 1.02784 (* 1 = 1.02784 loss)
I0603 04:50:29.760488   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04577 (* 0.3 = 0.313732 loss)
I0603 04:50:29.760493   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.982672 (* 0.3 = 0.294802 loss)
I0603 04:50:29.760504   861 sgd_solver.cpp:176] Iteration 340, lr = 0.00803638
I0603 04:50:37.678189   861 solver.cpp:316] Iteration 342, loss = 1.60251
I0603 04:50:37.678246   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:50:37.678258   861 solver.cpp:332]     Train net output #1: loss = 0.980742 (* 1 = 0.980742 loss)
I0603 04:50:37.678266   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05667 (* 0.3 = 0.317002 loss)
I0603 04:50:37.678287   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0159 (* 0.3 = 0.304769 loss)
I0603 04:50:37.678297   861 sgd_solver.cpp:176] Iteration 342, lr = 0.0080234
I0603 04:50:45.367115   861 solver.cpp:316] Iteration 344, loss = 1.66846
I0603 04:50:45.367290   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:50:45.367305   861 solver.cpp:332]     Train net output #1: loss = 1.04443 (* 1 = 1.04443 loss)
I0603 04:50:45.367312   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06093 (* 0.3 = 0.318279 loss)
I0603 04:50:45.367319   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01917 (* 0.3 = 0.305751 loss)
I0603 04:50:45.367331   861 sgd_solver.cpp:176] Iteration 344, lr = 0.00801041
I0603 04:50:52.993391   861 solver.cpp:316] Iteration 346, loss = 1.70742
I0603 04:50:52.993446   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:50:52.993460   861 solver.cpp:332]     Train net output #1: loss = 1.07063 (* 1 = 1.07063 loss)
I0603 04:50:52.993468   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03541 (* 0.3 = 0.310622 loss)
I0603 04:50:52.993474   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.08723 (* 0.3 = 0.326168 loss)
I0603 04:50:52.993484   861 sgd_solver.cpp:176] Iteration 346, lr = 0.0079974
I0603 04:51:00.616184   861 solver.cpp:316] Iteration 348, loss = 1.32355
I0603 04:51:00.616245   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:51:00.616257   861 solver.cpp:332]     Train net output #1: loss = 0.823537 (* 1 = 0.823537 loss)
I0603 04:51:00.616266   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.856967 (* 0.3 = 0.25709 loss)
I0603 04:51:00.616272   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.809758 (* 0.3 = 0.242928 loss)
I0603 04:51:00.616284   861 sgd_solver.cpp:176] Iteration 348, lr = 0.00798436
I0603 04:51:08.220712   861 solver.cpp:316] Iteration 350, loss = 1.30982
I0603 04:51:08.220767   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 04:51:08.220780   861 solver.cpp:332]     Train net output #1: loss = 0.804668 (* 1 = 0.804668 loss)
I0603 04:51:08.220788   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.858742 (* 0.3 = 0.257623 loss)
I0603 04:51:08.220795   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.825105 (* 0.3 = 0.247532 loss)
I0603 04:51:08.220806   861 sgd_solver.cpp:176] Iteration 350, lr = 0.0079713
I0603 04:51:12.075465   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_352.caffemodel
I0603 04:51:12.235752   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_352.solverstate
I0603 04:51:16.073439   861 solver.cpp:316] Iteration 352, loss = 1.61416
I0603 04:51:16.073566   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:51:16.073581   861 solver.cpp:332]     Train net output #1: loss = 1.00792 (* 1 = 1.00792 loss)
I0603 04:51:16.073590   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.985777 (* 0.3 = 0.295733 loss)
I0603 04:51:16.073596   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03502 (* 0.3 = 0.310506 loss)
I0603 04:51:16.073607   861 sgd_solver.cpp:176] Iteration 352, lr = 0.00795822
I0603 04:51:23.744269   861 solver.cpp:316] Iteration 354, loss = 1.58688
I0603 04:51:23.744328   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:51:23.744341   861 solver.cpp:332]     Train net output #1: loss = 0.98944 (* 1 = 0.98944 loss)
I0603 04:51:23.744349   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00413 (* 0.3 = 0.301238 loss)
I0603 04:51:23.744355   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.987351 (* 0.3 = 0.296205 loss)
I0603 04:51:23.744366   861 sgd_solver.cpp:176] Iteration 354, lr = 0.00794512
I0603 04:51:39.118996   861 solver.cpp:316] Iteration 356, loss = 1.87455
I0603 04:51:39.119042   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 04:51:39.119055   861 solver.cpp:332]     Train net output #1: loss = 1.12917 (* 1 = 1.12917 loss)
I0603 04:51:39.119062   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.32879 (* 0.3 = 0.398636 loss)
I0603 04:51:39.119068   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.15582 (* 0.3 = 0.346747 loss)
I0603 04:51:39.119078   861 sgd_solver.cpp:176] Iteration 356, lr = 0.007932
I0603 04:51:53.848242   861 solver.cpp:316] Iteration 358, loss = 1.52237
I0603 04:51:53.848387   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:51:53.848407   861 solver.cpp:332]     Train net output #1: loss = 0.953165 (* 1 = 0.953165 loss)
I0603 04:51:53.848417   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.937664 (* 0.3 = 0.281299 loss)
I0603 04:51:53.848428   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.95967 (* 0.3 = 0.287901 loss)
I0603 04:51:53.848443   861 sgd_solver.cpp:176] Iteration 358, lr = 0.00791886
I0603 04:52:03.804263   861 solver.cpp:316] Iteration 360, loss = 1.76398
I0603 04:52:03.804327   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:52:03.804347   861 solver.cpp:332]     Train net output #1: loss = 1.08535 (* 1 = 1.08535 loss)
I0603 04:52:03.804358   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.21836 (* 0.3 = 0.365508 loss)
I0603 04:52:03.804366   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04374 (* 0.3 = 0.313123 loss)
I0603 04:52:03.804380   861 sgd_solver.cpp:176] Iteration 360, lr = 0.00790569
I0603 04:52:11.469544   861 solver.cpp:316] Iteration 362, loss = 1.48278
I0603 04:52:11.469609   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:52:11.469627   861 solver.cpp:332]     Train net output #1: loss = 0.920961 (* 1 = 0.920961 loss)
I0603 04:52:11.469637   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.965147 (* 0.3 = 0.289544 loss)
I0603 04:52:11.469646   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.907586 (* 0.3 = 0.272276 loss)
I0603 04:52:11.469661   861 sgd_solver.cpp:176] Iteration 362, lr = 0.00789251
I0603 04:52:19.035454   861 solver.cpp:316] Iteration 364, loss = 1.52247
I0603 04:52:19.035516   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:52:19.035537   861 solver.cpp:332]     Train net output #1: loss = 0.957102 (* 1 = 0.957102 loss)
I0603 04:52:19.035547   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.938734 (* 0.3 = 0.28162 loss)
I0603 04:52:19.035557   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.945827 (* 0.3 = 0.283748 loss)
I0603 04:52:19.035571   861 sgd_solver.cpp:176] Iteration 364, lr = 0.0078793
I0603 04:52:26.721331   861 solver.cpp:316] Iteration 366, loss = 1.58885
I0603 04:52:26.721433   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:52:26.721452   861 solver.cpp:332]     Train net output #1: loss = 0.983296 (* 1 = 0.983296 loss)
I0603 04:52:26.721463   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10414 (* 0.3 = 0.331242 loss)
I0603 04:52:26.721473   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.914381 (* 0.3 = 0.274314 loss)
I0603 04:52:26.721487   861 sgd_solver.cpp:176] Iteration 366, lr = 0.00786607
I0603 04:52:34.384064   861 solver.cpp:316] Iteration 368, loss = 1.60588
I0603 04:52:34.384121   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:52:34.384140   861 solver.cpp:332]     Train net output #1: loss = 0.957247 (* 1 = 0.957247 loss)
I0603 04:52:34.384150   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.14675 (* 0.3 = 0.344025 loss)
I0603 04:52:34.384160   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01536 (* 0.3 = 0.304609 loss)
I0603 04:52:34.384176   861 sgd_solver.cpp:176] Iteration 368, lr = 0.00785281
I0603 04:52:42.258692   861 solver.cpp:316] Iteration 370, loss = 1.60341
I0603 04:52:42.258749   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:52:42.258767   861 solver.cpp:332]     Train net output #1: loss = 0.99565 (* 1 = 0.99565 loss)
I0603 04:52:42.258777   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03249 (* 0.3 = 0.309747 loss)
I0603 04:52:42.258787   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.993367 (* 0.3 = 0.29801 loss)
I0603 04:52:42.258801   861 sgd_solver.cpp:176] Iteration 370, lr = 0.00783954
I0603 04:52:49.907511   861 solver.cpp:316] Iteration 372, loss = 1.41738
I0603 04:52:49.907575   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 04:52:49.907593   861 solver.cpp:332]     Train net output #1: loss = 0.889867 (* 1 = 0.889867 loss)
I0603 04:52:49.907603   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.938837 (* 0.3 = 0.281651 loss)
I0603 04:52:49.907613   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.819523 (* 0.3 = 0.245857 loss)
I0603 04:52:49.907629   861 sgd_solver.cpp:176] Iteration 372, lr = 0.00782624
I0603 04:52:57.532975   861 solver.cpp:316] Iteration 374, loss = 1.52805
I0603 04:52:57.533167   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:52:57.533190   861 solver.cpp:332]     Train net output #1: loss = 0.946257 (* 1 = 0.946257 loss)
I0603 04:52:57.533200   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04659 (* 0.3 = 0.313977 loss)
I0603 04:52:57.533210   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.892725 (* 0.3 = 0.267818 loss)
I0603 04:52:57.533226   861 sgd_solver.cpp:176] Iteration 374, lr = 0.00781292
I0603 04:53:05.134320   861 solver.cpp:316] Iteration 376, loss = 1.75445
I0603 04:53:05.134377   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:53:05.134393   861 solver.cpp:332]     Train net output #1: loss = 1.07985 (* 1 = 1.07985 loss)
I0603 04:53:05.134404   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.16954 (* 0.3 = 0.350862 loss)
I0603 04:53:05.134414   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07912 (* 0.3 = 0.323737 loss)
I0603 04:53:05.134428   861 sgd_solver.cpp:176] Iteration 376, lr = 0.00779957
I0603 04:53:12.770378   861 solver.cpp:316] Iteration 378, loss = 1.52866
I0603 04:53:12.770439   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:53:12.770457   861 solver.cpp:332]     Train net output #1: loss = 0.931778 (* 1 = 0.931778 loss)
I0603 04:53:12.770467   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07276 (* 0.3 = 0.321828 loss)
I0603 04:53:12.770479   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.916857 (* 0.3 = 0.275057 loss)
I0603 04:53:12.770495   861 sgd_solver.cpp:176] Iteration 378, lr = 0.00778621
I0603 04:53:20.347051   861 solver.cpp:316] Iteration 380, loss = 1.44945
I0603 04:53:20.347110   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:53:20.347129   861 solver.cpp:332]     Train net output #1: loss = 0.884727 (* 1 = 0.884727 loss)
I0603 04:53:20.347139   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.977295 (* 0.3 = 0.293188 loss)
I0603 04:53:20.347149   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.905111 (* 0.3 = 0.271533 loss)
I0603 04:53:20.347163   861 sgd_solver.cpp:176] Iteration 380, lr = 0.00777282
I0603 04:53:28.006471   861 solver.cpp:316] Iteration 382, loss = 1.49775
I0603 04:53:28.006660   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:53:28.006680   861 solver.cpp:332]     Train net output #1: loss = 0.929747 (* 1 = 0.929747 loss)
I0603 04:53:28.006691   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.950737 (* 0.3 = 0.285221 loss)
I0603 04:53:28.006700   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.9426 (* 0.3 = 0.28278 loss)
I0603 04:53:28.006716   861 sgd_solver.cpp:176] Iteration 382, lr = 0.0077594
I0603 04:53:31.882068   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_384.caffemodel
I0603 04:53:32.038529   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_384.solverstate
I0603 04:53:36.091130   861 solver.cpp:316] Iteration 384, loss = 1.7316
I0603 04:53:36.091188   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:53:36.091208   861 solver.cpp:332]     Train net output #1: loss = 1.08184 (* 1 = 1.08184 loss)
I0603 04:53:36.091218   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06994 (* 0.3 = 0.320981 loss)
I0603 04:53:36.091228   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09593 (* 0.3 = 0.328779 loss)
I0603 04:53:36.091243   861 sgd_solver.cpp:176] Iteration 384, lr = 0.00774597
I0603 04:53:43.840728   861 solver.cpp:316] Iteration 386, loss = 1.56769
I0603 04:53:43.840790   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:53:43.840808   861 solver.cpp:332]     Train net output #1: loss = 0.987676 (* 1 = 0.987676 loss)
I0603 04:53:43.840818   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.94884 (* 0.3 = 0.284652 loss)
I0603 04:53:43.840828   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.984546 (* 0.3 = 0.295364 loss)
I0603 04:53:43.840842   861 sgd_solver.cpp:176] Iteration 386, lr = 0.00773251
I0603 04:53:58.897863   861 solver.cpp:316] Iteration 388, loss = 1.63919
I0603 04:53:58.903833   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:53:58.903851   861 solver.cpp:332]     Train net output #1: loss = 1.00482 (* 1 = 1.00482 loss)
I0603 04:53:58.903857   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09087 (* 0.3 = 0.327261 loss)
I0603 04:53:58.903864   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02371 (* 0.3 = 0.307113 loss)
I0603 04:53:58.903875   861 sgd_solver.cpp:176] Iteration 388, lr = 0.00771902
I0603 04:54:13.570552   861 solver.cpp:316] Iteration 390, loss = 1.71122
I0603 04:54:13.570605   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:54:13.570623   861 solver.cpp:332]     Train net output #1: loss = 1.04816 (* 1 = 1.04816 loss)
I0603 04:54:13.570636   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09209 (* 0.3 = 0.327628 loss)
I0603 04:54:13.570646   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.11813 (* 0.3 = 0.335439 loss)
I0603 04:54:13.570659   861 sgd_solver.cpp:176] Iteration 390, lr = 0.00770552
I0603 04:54:23.536648   861 solver.cpp:316] Iteration 392, loss = 1.57015
I0603 04:54:23.536711   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:54:23.536732   861 solver.cpp:332]     Train net output #1: loss = 0.969947 (* 1 = 0.969947 loss)
I0603 04:54:23.536741   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04367 (* 0.3 = 0.313101 loss)
I0603 04:54:23.536752   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.957 (* 0.3 = 0.2871 loss)
I0603 04:54:23.536768   861 sgd_solver.cpp:176] Iteration 392, lr = 0.00769199
I0603 04:54:31.108395   861 solver.cpp:316] Iteration 394, loss = 1.67126
I0603 04:54:31.108518   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:54:31.108538   861 solver.cpp:332]     Train net output #1: loss = 1.04563 (* 1 = 1.04563 loss)
I0603 04:54:31.108548   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03948 (* 0.3 = 0.311843 loss)
I0603 04:54:31.108557   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04595 (* 0.3 = 0.313784 loss)
I0603 04:54:31.108572   861 sgd_solver.cpp:176] Iteration 394, lr = 0.00767843
I0603 04:54:38.999449   861 solver.cpp:316] Iteration 396, loss = 1.62331
I0603 04:54:38.999508   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:54:38.999527   861 solver.cpp:332]     Train net output #1: loss = 1.02288 (* 1 = 1.02288 loss)
I0603 04:54:38.999537   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.990589 (* 0.3 = 0.297177 loss)
I0603 04:54:38.999547   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01085 (* 0.3 = 0.303254 loss)
I0603 04:54:38.999562   861 sgd_solver.cpp:176] Iteration 396, lr = 0.00766485
I0603 04:54:46.701336   861 solver.cpp:316] Iteration 398, loss = 1.77693
I0603 04:54:46.701392   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:54:46.701406   861 solver.cpp:332]     Train net output #1: loss = 1.10348 (* 1 = 1.10348 loss)
I0603 04:54:46.701412   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.15159 (* 0.3 = 0.345476 loss)
I0603 04:54:46.701419   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09325 (* 0.3 = 0.327974 loss)
I0603 04:54:46.701429   861 sgd_solver.cpp:176] Iteration 398, lr = 0.00765125
I0603 04:54:54.348768   861 solver.cpp:316] Iteration 400, loss = 1.63863
I0603 04:54:54.348829   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:54:54.348842   861 solver.cpp:332]     Train net output #1: loss = 0.994429 (* 1 = 0.994429 loss)
I0603 04:54:54.348850   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09889 (* 0.3 = 0.329666 loss)
I0603 04:54:54.348856   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04845 (* 0.3 = 0.314534 loss)
I0603 04:54:54.348868   861 sgd_solver.cpp:176] Iteration 400, lr = 0.00763763
I0603 04:55:01.974936   861 solver.cpp:316] Iteration 402, loss = 1.52969
I0603 04:55:01.975095   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:55:01.975116   861 solver.cpp:332]     Train net output #1: loss = 0.955817 (* 1 = 0.955817 loss)
I0603 04:55:01.975127   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.979505 (* 0.3 = 0.293851 loss)
I0603 04:55:01.975137   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.93342 (* 0.3 = 0.280026 loss)
I0603 04:55:01.975152   861 sgd_solver.cpp:176] Iteration 402, lr = 0.00762398
I0603 04:55:09.583408   861 solver.cpp:316] Iteration 404, loss = 1.53021
I0603 04:55:09.583461   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:55:09.583478   861 solver.cpp:332]     Train net output #1: loss = 0.951874 (* 1 = 0.951874 loss)
I0603 04:55:09.583488   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.969987 (* 0.3 = 0.290996 loss)
I0603 04:55:09.583498   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.957785 (* 0.3 = 0.287336 loss)
I0603 04:55:09.583513   861 sgd_solver.cpp:176] Iteration 404, lr = 0.0076103
I0603 04:55:17.191352   861 solver.cpp:316] Iteration 406, loss = 1.38381
I0603 04:55:17.191408   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:55:17.191428   861 solver.cpp:332]     Train net output #1: loss = 0.854945 (* 1 = 0.854945 loss)
I0603 04:55:17.191438   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.929875 (* 0.3 = 0.278962 loss)
I0603 04:55:17.191448   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.833014 (* 0.3 = 0.249904 loss)
I0603 04:55:17.191462   861 sgd_solver.cpp:176] Iteration 406, lr = 0.0075966
I0603 04:55:24.837746   861 solver.cpp:316] Iteration 408, loss = 1.85785
I0603 04:55:24.837810   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:55:24.837828   861 solver.cpp:332]     Train net output #1: loss = 1.16927 (* 1 = 1.16927 loss)
I0603 04:55:24.837838   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.23451 (* 0.3 = 0.370352 loss)
I0603 04:55:24.837847   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06077 (* 0.3 = 0.318231 loss)
I0603 04:55:24.837862   861 sgd_solver.cpp:176] Iteration 408, lr = 0.00758287
I0603 04:55:32.448217   861 solver.cpp:316] Iteration 410, loss = 1.36599
I0603 04:55:32.448361   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 04:55:32.448382   861 solver.cpp:332]     Train net output #1: loss = 0.8439 (* 1 = 0.8439 loss)
I0603 04:55:32.448392   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.879562 (* 0.3 = 0.263869 loss)
I0603 04:55:32.448403   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.860733 (* 0.3 = 0.25822 loss)
I0603 04:55:32.448417   861 sgd_solver.cpp:176] Iteration 410, lr = 0.00756913
I0603 04:55:40.363113   861 solver.cpp:316] Iteration 412, loss = 1.53844
I0603 04:55:40.363170   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:55:40.363189   861 solver.cpp:332]     Train net output #1: loss = 0.966541 (* 1 = 0.966541 loss)
I0603 04:55:40.363200   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.996325 (* 0.3 = 0.298897 loss)
I0603 04:55:40.363210   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.910017 (* 0.3 = 0.273005 loss)
I0603 04:55:40.363225   861 sgd_solver.cpp:176] Iteration 412, lr = 0.00755535
I0603 04:55:48.054538   861 solver.cpp:316] Iteration 414, loss = 1.72678
I0603 04:55:48.054595   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:55:48.054615   861 solver.cpp:332]     Train net output #1: loss = 1.05471 (* 1 = 1.05471 loss)
I0603 04:55:48.054625   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.16658 (* 0.3 = 0.349975 loss)
I0603 04:55:48.054635   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07365 (* 0.3 = 0.322095 loss)
I0603 04:55:48.054648   861 sgd_solver.cpp:176] Iteration 414, lr = 0.00754155
I0603 04:55:51.868329   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_416.caffemodel
I0603 04:55:52.029023   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_416.solverstate
I0603 04:55:55.890405   861 solver.cpp:316] Iteration 416, loss = 1.99517
I0603 04:55:55.890457   861 solver.cpp:332]     Train net output #0: accuracy = 0.3125
I0603 04:55:55.890470   861 solver.cpp:332]     Train net output #1: loss = 1.25564 (* 1 = 1.25564 loss)
I0603 04:55:55.890478   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.28634 (* 0.3 = 0.385901 loss)
I0603 04:55:55.890486   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.17876 (* 0.3 = 0.353628 loss)
I0603 04:55:55.890496   861 sgd_solver.cpp:176] Iteration 416, lr = 0.00752773
I0603 04:56:03.577761   861 solver.cpp:316] Iteration 418, loss = 1.44927
I0603 04:56:03.577886   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:56:03.577905   861 solver.cpp:332]     Train net output #1: loss = 0.911117 (* 1 = 0.911117 loss)
I0603 04:56:03.577916   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.88845 (* 0.3 = 0.266535 loss)
I0603 04:56:03.577926   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.905388 (* 0.3 = 0.271617 loss)
I0603 04:56:03.577941   861 sgd_solver.cpp:176] Iteration 418, lr = 0.00751388
I0603 04:56:18.586313   861 solver.cpp:316] Iteration 420, loss = 1.67985
I0603 04:56:18.586357   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:56:18.586370   861 solver.cpp:332]     Train net output #1: loss = 1.05832 (* 1 = 1.05832 loss)
I0603 04:56:18.586377   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08472 (* 0.3 = 0.325416 loss)
I0603 04:56:18.586383   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.987053 (* 0.3 = 0.296116 loss)
I0603 04:56:18.586395   861 sgd_solver.cpp:176] Iteration 420, lr = 0.0075
I0603 04:56:33.340656   861 solver.cpp:316] Iteration 422, loss = 1.51631
I0603 04:56:33.340721   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:56:33.340740   861 solver.cpp:332]     Train net output #1: loss = 0.937823 (* 1 = 0.937823 loss)
I0603 04:56:33.340751   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01577 (* 0.3 = 0.304732 loss)
I0603 04:56:33.340761   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.912512 (* 0.3 = 0.273754 loss)
I0603 04:56:33.340777   861 sgd_solver.cpp:176] Iteration 422, lr = 0.0074861
I0603 04:56:43.543582   861 solver.cpp:316] Iteration 424, loss = 1.4251
I0603 04:56:43.543735   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:56:43.543751   861 solver.cpp:332]     Train net output #1: loss = 0.88666 (* 1 = 0.88666 loss)
I0603 04:56:43.543757   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.906725 (* 0.3 = 0.272018 loss)
I0603 04:56:43.543764   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.888085 (* 0.3 = 0.266426 loss)
I0603 04:56:43.543774   861 sgd_solver.cpp:176] Iteration 424, lr = 0.00747217
I0603 04:56:51.212213   861 solver.cpp:316] Iteration 426, loss = 1.78761
I0603 04:56:51.212265   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:56:51.212280   861 solver.cpp:332]     Train net output #1: loss = 1.1185 (* 1 = 1.1185 loss)
I0603 04:56:51.212287   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07165 (* 0.3 = 0.321494 loss)
I0603 04:56:51.212294   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.15874 (* 0.3 = 0.347621 loss)
I0603 04:56:51.212304   861 sgd_solver.cpp:176] Iteration 426, lr = 0.00745822
I0603 04:56:58.860550   861 solver.cpp:316] Iteration 428, loss = 1.7188
I0603 04:56:58.860605   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:56:58.860622   861 solver.cpp:332]     Train net output #1: loss = 1.06694 (* 1 = 1.06694 loss)
I0603 04:56:58.860630   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08221 (* 0.3 = 0.324662 loss)
I0603 04:56:58.860637   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09066 (* 0.3 = 0.327198 loss)
I0603 04:56:58.860647   861 sgd_solver.cpp:176] Iteration 428, lr = 0.00744424
I0603 04:57:06.510747   861 solver.cpp:316] Iteration 430, loss = 1.70214
I0603 04:57:06.510804   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 04:57:06.510823   861 solver.cpp:332]     Train net output #1: loss = 1.06519 (* 1 = 1.06519 loss)
I0603 04:57:06.510833   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08953 (* 0.3 = 0.32686 loss)
I0603 04:57:06.510843   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03365 (* 0.3 = 0.310095 loss)
I0603 04:57:06.510859   861 sgd_solver.cpp:176] Iteration 430, lr = 0.00743023
I0603 04:57:14.120184   861 solver.cpp:316] Iteration 432, loss = 1.43707
I0603 04:57:14.120314   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 04:57:14.120335   861 solver.cpp:332]     Train net output #1: loss = 0.905693 (* 1 = 0.905693 loss)
I0603 04:57:14.120347   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.865697 (* 0.3 = 0.259709 loss)
I0603 04:57:14.120357   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.905565 (* 0.3 = 0.271669 loss)
I0603 04:57:14.120371   861 sgd_solver.cpp:176] Iteration 432, lr = 0.0074162
I0603 04:57:21.691668   861 solver.cpp:316] Iteration 434, loss = 1.63814
I0603 04:57:21.691725   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:57:21.691738   861 solver.cpp:332]     Train net output #1: loss = 1.00564 (* 1 = 1.00564 loss)
I0603 04:57:21.691745   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10052 (* 0.3 = 0.330155 loss)
I0603 04:57:21.691752   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00781 (* 0.3 = 0.302343 loss)
I0603 04:57:21.691763   861 sgd_solver.cpp:176] Iteration 434, lr = 0.00740214
I0603 04:57:29.376541   861 solver.cpp:316] Iteration 436, loss = 1.48639
I0603 04:57:29.376596   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:57:29.376611   861 solver.cpp:332]     Train net output #1: loss = 0.931349 (* 1 = 0.931349 loss)
I0603 04:57:29.376618   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.942634 (* 0.3 = 0.28279 loss)
I0603 04:57:29.376626   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.907492 (* 0.3 = 0.272248 loss)
I0603 04:57:29.376636   861 sgd_solver.cpp:176] Iteration 436, lr = 0.00738805
I0603 04:57:37.229195   861 solver.cpp:316] Iteration 438, loss = 1.5908
I0603 04:57:37.229274   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:57:37.229302   861 solver.cpp:332]     Train net output #1: loss = 0.999262 (* 1 = 0.999262 loss)
I0603 04:57:37.229320   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.986546 (* 0.3 = 0.295964 loss)
I0603 04:57:37.229336   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.985232 (* 0.3 = 0.29557 loss)
I0603 04:57:37.229356   861 sgd_solver.cpp:176] Iteration 438, lr = 0.00737394
I0603 04:57:44.935791   861 solver.cpp:316] Iteration 440, loss = 1.6065
I0603 04:57:44.936440   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 04:57:44.936466   861 solver.cpp:332]     Train net output #1: loss = 1.00902 (* 1 = 1.00902 loss)
I0603 04:57:44.936480   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.955194 (* 0.3 = 0.286558 loss)
I0603 04:57:44.936489   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0364 (* 0.3 = 0.310919 loss)
I0603 04:57:44.936506   861 sgd_solver.cpp:176] Iteration 440, lr = 0.0073598
I0603 04:57:52.590258   861 solver.cpp:316] Iteration 442, loss = 1.38661
I0603 04:57:52.590329   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 04:57:52.590349   861 solver.cpp:332]     Train net output #1: loss = 0.851916 (* 1 = 0.851916 loss)
I0603 04:57:52.590359   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.898491 (* 0.3 = 0.269547 loss)
I0603 04:57:52.590369   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.883821 (* 0.3 = 0.265146 loss)
I0603 04:57:52.590384   861 sgd_solver.cpp:176] Iteration 442, lr = 0.00734563
I0603 04:58:00.231240   861 solver.cpp:316] Iteration 444, loss = 1.67292
I0603 04:58:00.231300   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:58:00.231319   861 solver.cpp:332]     Train net output #1: loss = 1.05584 (* 1 = 1.05584 loss)
I0603 04:58:00.231329   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.989737 (* 0.3 = 0.296921 loss)
I0603 04:58:00.231338   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06718 (* 0.3 = 0.320154 loss)
I0603 04:58:00.231353   861 sgd_solver.cpp:176] Iteration 444, lr = 0.00733144
I0603 04:58:07.865365   861 solver.cpp:316] Iteration 446, loss = 1.48587
I0603 04:58:07.865427   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 04:58:07.865444   861 solver.cpp:332]     Train net output #1: loss = 0.920489 (* 1 = 0.920489 loss)
I0603 04:58:07.865454   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.9756 (* 0.3 = 0.29268 loss)
I0603 04:58:07.865463   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.909007 (* 0.3 = 0.272702 loss)
I0603 04:58:07.865478   861 sgd_solver.cpp:176] Iteration 446, lr = 0.00731722
I0603 04:58:11.691753   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_448.caffemodel
I0603 04:58:11.849608   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_448.solverstate
I0603 04:58:15.725107   861 solver.cpp:316] Iteration 448, loss = 1.70136
I0603 04:58:15.725210   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 04:58:15.725230   861 solver.cpp:332]     Train net output #1: loss = 1.0467 (* 1 = 1.0467 loss)
I0603 04:58:15.725241   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09067 (* 0.3 = 0.327201 loss)
I0603 04:58:15.725252   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09155 (* 0.3 = 0.327465 loss)
I0603 04:58:15.725266   861 sgd_solver.cpp:176] Iteration 448, lr = 0.00730297
I0603 04:58:23.378430   861 solver.cpp:316] Iteration 450, loss = 1.3944
I0603 04:58:23.378486   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:58:23.378504   861 solver.cpp:332]     Train net output #1: loss = 0.882976 (* 1 = 0.882976 loss)
I0603 04:58:23.378515   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.868663 (* 0.3 = 0.260599 loss)
I0603 04:58:23.378525   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.836093 (* 0.3 = 0.250828 loss)
I0603 04:58:23.378540   861 sgd_solver.cpp:176] Iteration 450, lr = 0.00728869
I0603 04:58:38.823645   861 solver.cpp:316] Iteration 452, loss = 1.5892
I0603 04:58:38.823693   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:58:38.823704   861 solver.cpp:332]     Train net output #1: loss = 0.998414 (* 1 = 0.998414 loss)
I0603 04:58:38.823712   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0184 (* 0.3 = 0.305519 loss)
I0603 04:58:38.823719   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.950901 (* 0.3 = 0.28527 loss)
I0603 04:58:38.823729   861 sgd_solver.cpp:176] Iteration 452, lr = 0.00727438
I0603 04:58:53.594360   861 solver.cpp:316] Iteration 454, loss = 1.6803
I0603 04:58:53.594509   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:58:53.594532   861 solver.cpp:332]     Train net output #1: loss = 1.03082 (* 1 = 1.03082 loss)
I0603 04:58:53.594542   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09544 (* 0.3 = 0.328631 loss)
I0603 04:58:53.594553   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06951 (* 0.3 = 0.320854 loss)
I0603 04:58:53.594568   861 sgd_solver.cpp:176] Iteration 454, lr = 0.00726005
I0603 04:59:03.418108   861 solver.cpp:316] Iteration 456, loss = 1.54277
I0603 04:59:03.418174   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:59:03.418193   861 solver.cpp:332]     Train net output #1: loss = 0.958991 (* 1 = 0.958991 loss)
I0603 04:59:03.418203   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.963524 (* 0.3 = 0.289057 loss)
I0603 04:59:03.418212   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.982392 (* 0.3 = 0.294718 loss)
I0603 04:59:03.418227   861 sgd_solver.cpp:176] Iteration 456, lr = 0.00724569
I0603 04:59:11.072863   861 solver.cpp:316] Iteration 458, loss = 1.83201
I0603 04:59:11.072926   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 04:59:11.072945   861 solver.cpp:332]     Train net output #1: loss = 1.13866 (* 1 = 1.13866 loss)
I0603 04:59:11.072957   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.17461 (* 0.3 = 0.352382 loss)
I0603 04:59:11.072968   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.13657 (* 0.3 = 0.340971 loss)
I0603 04:59:11.072981   861 sgd_solver.cpp:176] Iteration 458, lr = 0.0072313
I0603 04:59:18.702617   861 solver.cpp:316] Iteration 460, loss = 1.55884
I0603 04:59:18.702674   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:59:18.702692   861 solver.cpp:332]     Train net output #1: loss = 0.964129 (* 1 = 0.964129 loss)
I0603 04:59:18.702703   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.02743 (* 0.3 = 0.30823 loss)
I0603 04:59:18.702713   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.954926 (* 0.3 = 0.286478 loss)
I0603 04:59:18.702728   861 sgd_solver.cpp:176] Iteration 460, lr = 0.00721688
I0603 04:59:26.346573   861 solver.cpp:316] Iteration 462, loss = 1.63686
I0603 04:59:26.346690   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:59:26.346710   861 solver.cpp:332]     Train net output #1: loss = 1.02196 (* 1 = 1.02196 loss)
I0603 04:59:26.346722   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00319 (* 0.3 = 0.300958 loss)
I0603 04:59:26.346734   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0465 (* 0.3 = 0.313949 loss)
I0603 04:59:26.346750   861 sgd_solver.cpp:176] Iteration 462, lr = 0.00720243
I0603 04:59:34.001740   861 solver.cpp:316] Iteration 464, loss = 1.4878
I0603 04:59:34.001802   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:59:34.001816   861 solver.cpp:332]     Train net output #1: loss = 0.937582 (* 1 = 0.937582 loss)
I0603 04:59:34.001823   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.937032 (* 0.3 = 0.28111 loss)
I0603 04:59:34.001830   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.897038 (* 0.3 = 0.269111 loss)
I0603 04:59:34.001842   861 sgd_solver.cpp:176] Iteration 464, lr = 0.00718795
I0603 04:59:41.881645   861 solver.cpp:316] Iteration 466, loss = 1.65861
I0603 04:59:41.881703   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 04:59:41.881716   861 solver.cpp:332]     Train net output #1: loss = 1.01643 (* 1 = 1.01643 loss)
I0603 04:59:41.881723   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06661 (* 0.3 = 0.319982 loss)
I0603 04:59:41.881731   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.074 (* 0.3 = 0.3222 loss)
I0603 04:59:41.881741   861 sgd_solver.cpp:176] Iteration 466, lr = 0.00717345
I0603 04:59:49.542583   861 solver.cpp:316] Iteration 468, loss = 1.51167
I0603 04:59:49.542639   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 04:59:49.542651   861 solver.cpp:332]     Train net output #1: loss = 0.936745 (* 1 = 0.936745 loss)
I0603 04:59:49.542659   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.994355 (* 0.3 = 0.298307 loss)
I0603 04:59:49.542665   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.922065 (* 0.3 = 0.27662 loss)
I0603 04:59:49.542677   861 sgd_solver.cpp:176] Iteration 468, lr = 0.00715891
I0603 04:59:57.206701   861 solver.cpp:316] Iteration 470, loss = 1.6098
I0603 04:59:57.206840   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 04:59:57.206857   861 solver.cpp:332]     Train net output #1: loss = 0.992667 (* 1 = 0.992667 loss)
I0603 04:59:57.206866   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.02448 (* 0.3 = 0.307345 loss)
I0603 04:59:57.206871   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03262 (* 0.3 = 0.309786 loss)
I0603 04:59:57.206883   861 sgd_solver.cpp:176] Iteration 470, lr = 0.00714434
I0603 05:00:04.871394   861 solver.cpp:316] Iteration 472, loss = 1.62412
I0603 05:00:04.871453   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:00:04.871470   861 solver.cpp:332]     Train net output #1: loss = 1.00794 (* 1 = 1.00794 loss)
I0603 05:00:04.871481   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.02935 (* 0.3 = 0.308805 loss)
I0603 05:00:04.871492   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02459 (* 0.3 = 0.307378 loss)
I0603 05:00:04.871507   861 sgd_solver.cpp:176] Iteration 472, lr = 0.00712975
I0603 05:00:12.504886   861 solver.cpp:316] Iteration 474, loss = 1.67436
I0603 05:00:12.504962   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:00:12.504989   861 solver.cpp:332]     Train net output #1: loss = 1.02013 (* 1 = 1.02013 loss)
I0603 05:00:12.505007   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.12994 (* 0.3 = 0.338983 loss)
I0603 05:00:12.505022   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05083 (* 0.3 = 0.31525 loss)
I0603 05:00:12.505040   861 sgd_solver.cpp:176] Iteration 474, lr = 0.00711512
I0603 05:00:20.145926   861 solver.cpp:316] Iteration 476, loss = 1.63375
I0603 05:00:20.145992   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:00:20.146011   861 solver.cpp:332]     Train net output #1: loss = 1.02831 (* 1 = 1.02831 loss)
I0603 05:00:20.146021   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00372 (* 0.3 = 0.301117 loss)
I0603 05:00:20.146030   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0144 (* 0.3 = 0.30432 loss)
I0603 05:00:20.146044   861 sgd_solver.cpp:176] Iteration 476, lr = 0.00710047
I0603 05:00:27.832484   861 solver.cpp:316] Iteration 478, loss = 1.46128
I0603 05:00:27.832607   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:00:27.832628   861 solver.cpp:332]     Train net output #1: loss = 0.908487 (* 1 = 0.908487 loss)
I0603 05:00:27.832639   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.906443 (* 0.3 = 0.271933 loss)
I0603 05:00:27.832649   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.936199 (* 0.3 = 0.28086 loss)
I0603 05:00:27.832664   861 sgd_solver.cpp:176] Iteration 478, lr = 0.00708578
I0603 05:00:31.673562   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_480.caffemodel
I0603 05:00:31.830183   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_480.solverstate
I0603 05:00:35.947945   861 solver.cpp:316] Iteration 480, loss = 1.3857
I0603 05:00:35.948011   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:00:35.948030   861 solver.cpp:332]     Train net output #1: loss = 0.851543 (* 1 = 0.851543 loss)
I0603 05:00:35.948041   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.934172 (* 0.3 = 0.280252 loss)
I0603 05:00:35.948051   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.846354 (* 0.3 = 0.253906 loss)
I0603 05:00:35.948066   861 sgd_solver.cpp:176] Iteration 480, lr = 0.00707107
I0603 05:00:43.691612   861 solver.cpp:316] Iteration 482, loss = 1.37802
I0603 05:00:43.691668   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:00:43.691686   861 solver.cpp:332]     Train net output #1: loss = 0.861664 (* 1 = 0.861664 loss)
I0603 05:00:43.691696   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.878641 (* 0.3 = 0.263592 loss)
I0603 05:00:43.691706   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.842539 (* 0.3 = 0.252762 loss)
I0603 05:00:43.691721   861 sgd_solver.cpp:176] Iteration 482, lr = 0.00705632
I0603 05:00:58.695003   861 solver.cpp:316] Iteration 484, loss = 1.52048
I0603 05:00:58.697760   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:00:58.697777   861 solver.cpp:332]     Train net output #1: loss = 0.944468 (* 1 = 0.944468 loss)
I0603 05:00:58.697783   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.964414 (* 0.3 = 0.289324 loss)
I0603 05:00:58.697789   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.955614 (* 0.3 = 0.286684 loss)
I0603 05:00:58.697800   861 sgd_solver.cpp:176] Iteration 484, lr = 0.00704154
I0603 05:01:13.526871   861 solver.cpp:316] Iteration 486, loss = 1.74438
I0603 05:01:13.526927   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:01:13.526945   861 solver.cpp:332]     Train net output #1: loss = 1.0767 (* 1 = 1.0767 loss)
I0603 05:01:13.526957   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10309 (* 0.3 = 0.330926 loss)
I0603 05:01:13.526967   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.12251 (* 0.3 = 0.336753 loss)
I0603 05:01:13.526983   861 sgd_solver.cpp:176] Iteration 486, lr = 0.00702673
I0603 05:01:23.542397   861 solver.cpp:316] Iteration 488, loss = 1.60724
I0603 05:01:23.542457   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:01:23.542476   861 solver.cpp:332]     Train net output #1: loss = 1.00203 (* 1 = 1.00203 loss)
I0603 05:01:23.542486   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04853 (* 0.3 = 0.314558 loss)
I0603 05:01:23.542496   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.968845 (* 0.3 = 0.290654 loss)
I0603 05:01:23.542511   861 sgd_solver.cpp:176] Iteration 488, lr = 0.00701189
I0603 05:01:31.223501   861 solver.cpp:316] Iteration 490, loss = 1.7756
I0603 05:01:31.223629   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:01:31.223645   861 solver.cpp:332]     Train net output #1: loss = 1.10851 (* 1 = 1.10851 loss)
I0603 05:01:31.223652   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07752 (* 0.3 = 0.323257 loss)
I0603 05:01:31.223659   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.14613 (* 0.3 = 0.343838 loss)
I0603 05:01:31.223670   861 sgd_solver.cpp:176] Iteration 490, lr = 0.00699702
I0603 05:01:39.084684   861 solver.cpp:316] Iteration 492, loss = 1.51197
I0603 05:01:39.084741   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:01:39.084759   861 solver.cpp:332]     Train net output #1: loss = 0.95025 (* 1 = 0.95025 loss)
I0603 05:01:39.084770   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.926023 (* 0.3 = 0.277807 loss)
I0603 05:01:39.084781   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.946365 (* 0.3 = 0.28391 loss)
I0603 05:01:39.084795   861 sgd_solver.cpp:176] Iteration 492, lr = 0.00698212
I0603 05:01:46.758605   861 solver.cpp:316] Iteration 494, loss = 1.50988
I0603 05:01:46.758661   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:01:46.758678   861 solver.cpp:332]     Train net output #1: loss = 0.942712 (* 1 = 0.942712 loss)
I0603 05:01:46.758688   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.928496 (* 0.3 = 0.278549 loss)
I0603 05:01:46.758698   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.962049 (* 0.3 = 0.288615 loss)
I0603 05:01:46.758713   861 sgd_solver.cpp:176] Iteration 494, lr = 0.00696718
I0603 05:01:54.371521   861 solver.cpp:316] Iteration 496, loss = 1.56323
I0603 05:01:54.371582   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:01:54.371601   861 solver.cpp:332]     Train net output #1: loss = 0.991504 (* 1 = 0.991504 loss)
I0603 05:01:54.371611   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.944163 (* 0.3 = 0.283249 loss)
I0603 05:01:54.371621   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.961579 (* 0.3 = 0.288474 loss)
I0603 05:01:54.371635   861 sgd_solver.cpp:176] Iteration 496, lr = 0.00695222
I0603 05:02:02.022311   861 solver.cpp:316] Iteration 498, loss = 1.54236
I0603 05:02:02.022440   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:02:02.022459   861 solver.cpp:332]     Train net output #1: loss = 0.981483 (* 1 = 0.981483 loss)
I0603 05:02:02.022465   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.912323 (* 0.3 = 0.273697 loss)
I0603 05:02:02.022472   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.957263 (* 0.3 = 0.287179 loss)
I0603 05:02:02.022483   861 sgd_solver.cpp:176] Iteration 498, lr = 0.00693722
I0603 05:02:09.658169   861 solver.cpp:316] Iteration 500, loss = 1.60301
I0603 05:02:09.658222   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:02:09.658236   861 solver.cpp:332]     Train net output #1: loss = 1.01236 (* 1 = 1.01236 loss)
I0603 05:02:09.658243   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.982802 (* 0.3 = 0.294841 loss)
I0603 05:02:09.658249   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.986019 (* 0.3 = 0.295806 loss)
I0603 05:02:09.658260   861 sgd_solver.cpp:176] Iteration 500, lr = 0.00692219
I0603 05:02:17.285372   861 solver.cpp:316] Iteration 502, loss = 1.65023
I0603 05:02:17.285430   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:02:17.285444   861 solver.cpp:332]     Train net output #1: loss = 1.00996 (* 1 = 1.00996 loss)
I0603 05:02:17.285451   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.13482 (* 0.3 = 0.340447 loss)
I0603 05:02:17.285459   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.999409 (* 0.3 = 0.299823 loss)
I0603 05:02:17.285468   861 sgd_solver.cpp:176] Iteration 502, lr = 0.00690712
I0603 05:02:24.905282   861 solver.cpp:316] Iteration 504, loss = 1.4469
I0603 05:02:24.905339   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:02:24.905357   861 solver.cpp:332]     Train net output #1: loss = 0.929014 (* 1 = 0.929014 loss)
I0603 05:02:24.905369   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.848385 (* 0.3 = 0.254516 loss)
I0603 05:02:24.905378   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.877896 (* 0.3 = 0.263369 loss)
I0603 05:02:24.905392   861 sgd_solver.cpp:176] Iteration 504, lr = 0.00689202
I0603 05:02:32.550586   861 solver.cpp:316] Iteration 506, loss = 1.69649
I0603 05:02:32.550694   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:02:32.550715   861 solver.cpp:332]     Train net output #1: loss = 1.06546 (* 1 = 1.06546 loss)
I0603 05:02:32.550727   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06991 (* 0.3 = 0.320973 loss)
I0603 05:02:32.550737   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03355 (* 0.3 = 0.310064 loss)
I0603 05:02:32.550752   861 sgd_solver.cpp:176] Iteration 506, lr = 0.00687689
I0603 05:02:40.463486   861 solver.cpp:316] Iteration 508, loss = 1.6423
I0603 05:02:40.463544   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:02:40.463562   861 solver.cpp:332]     Train net output #1: loss = 1.02821 (* 1 = 1.02821 loss)
I0603 05:02:40.463573   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00948 (* 0.3 = 0.302844 loss)
I0603 05:02:40.463582   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0375 (* 0.3 = 0.311249 loss)
I0603 05:02:40.463598   861 sgd_solver.cpp:176] Iteration 508, lr = 0.00686173
I0603 05:02:48.152750   861 solver.cpp:316] Iteration 510, loss = 1.31427
I0603 05:02:48.152806   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 05:02:48.152824   861 solver.cpp:332]     Train net output #1: loss = 0.826845 (* 1 = 0.826845 loss)
I0603 05:02:48.152835   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.797362 (* 0.3 = 0.239209 loss)
I0603 05:02:48.152845   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.827401 (* 0.3 = 0.24822 loss)
I0603 05:02:48.152861   861 sgd_solver.cpp:176] Iteration 510, lr = 0.00684653
I0603 05:02:51.970404   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_512.caffemodel
I0603 05:02:52.128403   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_512.solverstate
I0603 05:02:55.978623   861 solver.cpp:316] Iteration 512, loss = 1.35336
I0603 05:02:55.978682   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:02:55.978699   861 solver.cpp:332]     Train net output #1: loss = 0.845837 (* 1 = 0.845837 loss)
I0603 05:02:55.978709   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.881666 (* 0.3 = 0.2645 loss)
I0603 05:02:55.978719   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.810063 (* 0.3 = 0.243019 loss)
I0603 05:02:55.978734   861 sgd_solver.cpp:176] Iteration 512, lr = 0.0068313
I0603 05:03:03.646908   861 solver.cpp:316] Iteration 514, loss = 1.55012
I0603 05:03:03.647049   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:03:03.647065   861 solver.cpp:332]     Train net output #1: loss = 0.975608 (* 1 = 0.975608 loss)
I0603 05:03:03.647073   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.928267 (* 0.3 = 0.27848 loss)
I0603 05:03:03.647080   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.98677 (* 0.3 = 0.296031 loss)
I0603 05:03:03.647090   861 sgd_solver.cpp:176] Iteration 514, lr = 0.00681603
I0603 05:03:18.640652   861 solver.cpp:316] Iteration 516, loss = 1.51436
I0603 05:03:18.640697   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:03:18.640710   861 solver.cpp:332]     Train net output #1: loss = 0.966964 (* 1 = 0.966964 loss)
I0603 05:03:18.640718   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.857723 (* 0.3 = 0.257317 loss)
I0603 05:03:18.640724   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.966946 (* 0.3 = 0.290084 loss)
I0603 05:03:18.640735   861 sgd_solver.cpp:176] Iteration 516, lr = 0.00680073
I0603 05:03:33.262874   861 solver.cpp:316] Iteration 518, loss = 1.77674
I0603 05:03:33.262930   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:03:33.262943   861 solver.cpp:332]     Train net output #1: loss = 1.0746 (* 1 = 1.0746 loss)
I0603 05:03:33.262951   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.23192 (* 0.3 = 0.369576 loss)
I0603 05:03:33.262958   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10853 (* 0.3 = 0.332558 loss)
I0603 05:03:33.262969   861 sgd_solver.cpp:176] Iteration 518, lr = 0.0067854
I0603 05:03:43.528441   861 solver.cpp:316] Iteration 520, loss = 1.48331
I0603 05:03:43.528642   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:03:43.528669   861 solver.cpp:332]     Train net output #1: loss = 0.920835 (* 1 = 0.920835 loss)
I0603 05:03:43.528682   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.925766 (* 0.3 = 0.27773 loss)
I0603 05:03:43.528694   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.949149 (* 0.3 = 0.284745 loss)
I0603 05:03:43.528710   861 sgd_solver.cpp:176] Iteration 520, lr = 0.00677003
I0603 05:03:51.178797   861 solver.cpp:316] Iteration 522, loss = 1.68444
I0603 05:03:51.178850   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:03:51.178864   861 solver.cpp:332]     Train net output #1: loss = 1.05932 (* 1 = 1.05932 loss)
I0603 05:03:51.178871   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.985703 (* 0.3 = 0.295711 loss)
I0603 05:03:51.178879   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09803 (* 0.3 = 0.329408 loss)
I0603 05:03:51.178889   861 sgd_solver.cpp:176] Iteration 522, lr = 0.00675463
I0603 05:03:58.826506   861 solver.cpp:316] Iteration 524, loss = 1.52579
I0603 05:03:58.826558   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:03:58.826571   861 solver.cpp:332]     Train net output #1: loss = 0.926448 (* 1 = 0.926448 loss)
I0603 05:03:58.826580   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03161 (* 0.3 = 0.309483 loss)
I0603 05:03:58.826586   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.966195 (* 0.3 = 0.289858 loss)
I0603 05:03:58.826597   861 sgd_solver.cpp:176] Iteration 524, lr = 0.00673919
I0603 05:04:06.459625   861 solver.cpp:316] Iteration 526, loss = 1.54643
I0603 05:04:06.459682   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:04:06.459697   861 solver.cpp:332]     Train net output #1: loss = 0.970091 (* 1 = 0.970091 loss)
I0603 05:04:06.459703   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.976216 (* 0.3 = 0.292865 loss)
I0603 05:04:06.459710   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.944905 (* 0.3 = 0.283472 loss)
I0603 05:04:06.459722   861 sgd_solver.cpp:176] Iteration 526, lr = 0.00672371
I0603 05:04:14.110375   861 solver.cpp:316] Iteration 528, loss = 1.54873
I0603 05:04:14.110478   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:04:14.110496   861 solver.cpp:332]     Train net output #1: loss = 0.962423 (* 1 = 0.962423 loss)
I0603 05:04:14.110503   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.977406 (* 0.3 = 0.293222 loss)
I0603 05:04:14.110509   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.976944 (* 0.3 = 0.293083 loss)
I0603 05:04:14.110520   861 sgd_solver.cpp:176] Iteration 528, lr = 0.0067082
I0603 05:04:21.745879   861 solver.cpp:316] Iteration 530, loss = 1.46898
I0603 05:04:21.745942   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:04:21.745960   861 solver.cpp:332]     Train net output #1: loss = 0.92127 (* 1 = 0.92127 loss)
I0603 05:04:21.745970   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.879809 (* 0.3 = 0.263943 loss)
I0603 05:04:21.745980   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.945892 (* 0.3 = 0.283768 loss)
I0603 05:04:21.745995   861 sgd_solver.cpp:176] Iteration 530, lr = 0.00669266
I0603 05:04:29.408102   861 solver.cpp:316] Iteration 532, loss = 1.57227
I0603 05:04:29.408161   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:04:29.408180   861 solver.cpp:332]     Train net output #1: loss = 0.99606 (* 1 = 0.99606 loss)
I0603 05:04:29.408192   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.972341 (* 0.3 = 0.291702 loss)
I0603 05:04:29.408202   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.948347 (* 0.3 = 0.284504 loss)
I0603 05:04:29.408216   861 sgd_solver.cpp:176] Iteration 532, lr = 0.00667707
I0603 05:04:37.231922   861 solver.cpp:316] Iteration 534, loss = 1.4914
I0603 05:04:37.231981   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:04:37.231999   861 solver.cpp:332]     Train net output #1: loss = 0.953107 (* 1 = 0.953107 loss)
I0603 05:04:37.232010   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.908984 (* 0.3 = 0.272695 loss)
I0603 05:04:37.232020   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.885325 (* 0.3 = 0.265598 loss)
I0603 05:04:37.232035   861 sgd_solver.cpp:176] Iteration 534, lr = 0.00666146
I0603 05:04:44.927150   861 solver.cpp:316] Iteration 536, loss = 1.51397
I0603 05:04:44.927276   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:04:44.927299   861 solver.cpp:332]     Train net output #1: loss = 0.960661 (* 1 = 0.960661 loss)
I0603 05:04:44.927309   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847392 (* 0.3 = 0.254218 loss)
I0603 05:04:44.927320   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.99698 (* 0.3 = 0.299094 loss)
I0603 05:04:44.927335   861 sgd_solver.cpp:176] Iteration 536, lr = 0.0066458
I0603 05:04:52.612802   861 solver.cpp:316] Iteration 538, loss = 1.76203
I0603 05:04:52.612860   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:04:52.612879   861 solver.cpp:332]     Train net output #1: loss = 1.11731 (* 1 = 1.11731 loss)
I0603 05:04:52.612890   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03983 (* 0.3 = 0.311949 loss)
I0603 05:04:52.612900   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10923 (* 0.3 = 0.33277 loss)
I0603 05:04:52.612913   861 sgd_solver.cpp:176] Iteration 538, lr = 0.00663011
I0603 05:05:00.234912   861 solver.cpp:316] Iteration 540, loss = 1.39582
I0603 05:05:00.234972   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:05:00.234985   861 solver.cpp:332]     Train net output #1: loss = 0.886674 (* 1 = 0.886674 loss)
I0603 05:05:00.234993   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847804 (* 0.3 = 0.254341 loss)
I0603 05:05:00.234999   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.849346 (* 0.3 = 0.254804 loss)
I0603 05:05:00.235010   861 sgd_solver.cpp:176] Iteration 540, lr = 0.00661438
I0603 05:05:07.885494   861 solver.cpp:316] Iteration 542, loss = 1.44804
I0603 05:05:07.885557   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:05:07.885571   861 solver.cpp:332]     Train net output #1: loss = 0.908611 (* 1 = 0.908611 loss)
I0603 05:05:07.885577   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.935034 (* 0.3 = 0.28051 loss)
I0603 05:05:07.885584   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.863053 (* 0.3 = 0.258916 loss)
I0603 05:05:07.885596   861 sgd_solver.cpp:176] Iteration 542, lr = 0.00659861
I0603 05:05:11.720598   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_544.caffemodel
I0603 05:05:11.885349   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_544.solverstate
I0603 05:05:15.736806   861 solver.cpp:316] Iteration 544, loss = 1.49878
I0603 05:05:15.736910   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:05:15.736924   861 solver.cpp:332]     Train net output #1: loss = 0.930932 (* 1 = 0.930932 loss)
I0603 05:05:15.736932   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.956837 (* 0.3 = 0.287051 loss)
I0603 05:05:15.736938   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.935998 (* 0.3 = 0.280799 loss)
I0603 05:05:15.736949   861 sgd_solver.cpp:176] Iteration 544, lr = 0.00658281
I0603 05:05:23.409018   861 solver.cpp:316] Iteration 546, loss = 1.82828
I0603 05:05:23.409078   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:05:23.409092   861 solver.cpp:332]     Train net output #1: loss = 1.11342 (* 1 = 1.11342 loss)
I0603 05:05:23.409101   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.23855 (* 0.3 = 0.371566 loss)
I0603 05:05:23.409106   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.14434 (* 0.3 = 0.343301 loss)
I0603 05:05:23.409117   861 sgd_solver.cpp:176] Iteration 546, lr = 0.00656696
I0603 05:05:38.706313   861 solver.cpp:316] Iteration 548, loss = 1.46482
I0603 05:05:38.706358   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:05:38.706370   861 solver.cpp:332]     Train net output #1: loss = 0.918589 (* 1 = 0.918589 loss)
I0603 05:05:38.706377   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.867011 (* 0.3 = 0.260103 loss)
I0603 05:05:38.706384   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.953743 (* 0.3 = 0.286123 loss)
I0603 05:05:38.706394   861 sgd_solver.cpp:176] Iteration 548, lr = 0.00655108
I0603 05:05:53.440716   861 solver.cpp:316] Iteration 550, loss = 1.61728
I0603 05:05:53.440855   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:05:53.440874   861 solver.cpp:332]     Train net output #1: loss = 1.0076 (* 1 = 1.0076 loss)
I0603 05:05:53.440886   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04216 (* 0.3 = 0.312647 loss)
I0603 05:05:53.440896   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.990114 (* 0.3 = 0.297034 loss)
I0603 05:05:53.440910   861 sgd_solver.cpp:176] Iteration 550, lr = 0.00653516
I0603 05:06:03.503006   861 solver.cpp:316] Iteration 552, loss = 1.62529
I0603 05:06:03.503063   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:06:03.503082   861 solver.cpp:332]     Train net output #1: loss = 1.00711 (* 1 = 1.00711 loss)
I0603 05:06:03.503093   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08341 (* 0.3 = 0.325024 loss)
I0603 05:06:03.503103   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.977196 (* 0.3 = 0.293159 loss)
I0603 05:06:03.503116   861 sgd_solver.cpp:176] Iteration 552, lr = 0.0065192
I0603 05:06:11.151393   861 solver.cpp:316] Iteration 554, loss = 1.53412
I0603 05:06:11.151451   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:06:11.151469   861 solver.cpp:332]     Train net output #1: loss = 0.963153 (* 1 = 0.963153 loss)
I0603 05:06:11.151479   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.941694 (* 0.3 = 0.282508 loss)
I0603 05:06:11.151490   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.961543 (* 0.3 = 0.288463 loss)
I0603 05:06:11.151505   861 sgd_solver.cpp:176] Iteration 554, lr = 0.0065032
I0603 05:06:18.772910   861 solver.cpp:316] Iteration 556, loss = 1.74494
I0603 05:06:18.772972   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:06:18.772990   861 solver.cpp:332]     Train net output #1: loss = 1.10613 (* 1 = 1.10613 loss)
I0603 05:06:18.773001   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.05576 (* 0.3 = 0.316727 loss)
I0603 05:06:18.773011   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07358 (* 0.3 = 0.322075 loss)
I0603 05:06:18.773025   861 sgd_solver.cpp:176] Iteration 556, lr = 0.00648717
I0603 05:06:26.426082   861 solver.cpp:316] Iteration 558, loss = 1.56035
I0603 05:06:26.426208   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:06:26.426223   861 solver.cpp:332]     Train net output #1: loss = 0.965298 (* 1 = 0.965298 loss)
I0603 05:06:26.426231   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01777 (* 0.3 = 0.305332 loss)
I0603 05:06:26.426239   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.965724 (* 0.3 = 0.289717 loss)
I0603 05:06:26.426249   861 sgd_solver.cpp:176] Iteration 558, lr = 0.00647109
I0603 05:06:34.112383   861 solver.cpp:316] Iteration 560, loss = 1.65804
I0603 05:06:34.112438   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:06:34.112452   861 solver.cpp:332]     Train net output #1: loss = 1.07192 (* 1 = 1.07192 loss)
I0603 05:06:34.112460   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.960047 (* 0.3 = 0.288014 loss)
I0603 05:06:34.112468   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.993696 (* 0.3 = 0.298109 loss)
I0603 05:06:34.112478   861 sgd_solver.cpp:176] Iteration 560, lr = 0.00645497
I0603 05:06:41.944941   861 solver.cpp:316] Iteration 562, loss = 1.6259
I0603 05:06:41.945003   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:06:41.945019   861 solver.cpp:332]     Train net output #1: loss = 1.05364 (* 1 = 1.05364 loss)
I0603 05:06:41.945030   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.923017 (* 0.3 = 0.276905 loss)
I0603 05:06:41.945040   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.98452 (* 0.3 = 0.295356 loss)
I0603 05:06:41.945055   861 sgd_solver.cpp:176] Iteration 562, lr = 0.00643881
I0603 05:06:49.679826   861 solver.cpp:316] Iteration 564, loss = 1.51188
I0603 05:06:49.679883   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:06:49.679901   861 solver.cpp:332]     Train net output #1: loss = 0.934102 (* 1 = 0.934102 loss)
I0603 05:06:49.679913   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.976197 (* 0.3 = 0.292859 loss)
I0603 05:06:49.679922   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.949725 (* 0.3 = 0.284917 loss)
I0603 05:06:49.679936   861 sgd_solver.cpp:176] Iteration 564, lr = 0.00642262
I0603 05:06:57.291090   861 solver.cpp:316] Iteration 566, loss = 1.56561
I0603 05:06:57.291209   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:06:57.291229   861 solver.cpp:332]     Train net output #1: loss = 1.00578 (* 1 = 1.00578 loss)
I0603 05:06:57.291241   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.957284 (* 0.3 = 0.287185 loss)
I0603 05:06:57.291251   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.908846 (* 0.3 = 0.272654 loss)
I0603 05:06:57.291266   861 sgd_solver.cpp:176] Iteration 566, lr = 0.00640638
I0603 05:07:04.954599   861 solver.cpp:316] Iteration 568, loss = 1.36356
I0603 05:07:04.954660   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:07:04.954679   861 solver.cpp:332]     Train net output #1: loss = 0.865454 (* 1 = 0.865454 loss)
I0603 05:07:04.954689   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.839583 (* 0.3 = 0.251875 loss)
I0603 05:07:04.954700   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.820756 (* 0.3 = 0.246227 loss)
I0603 05:07:04.954715   861 sgd_solver.cpp:176] Iteration 568, lr = 0.0063901
I0603 05:07:12.612623   861 solver.cpp:316] Iteration 570, loss = 1.72393
I0603 05:07:12.612684   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:07:12.612702   861 solver.cpp:332]     Train net output #1: loss = 1.08393 (* 1 = 1.08393 loss)
I0603 05:07:12.612713   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08014 (* 0.3 = 0.324042 loss)
I0603 05:07:12.612723   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05321 (* 0.3 = 0.315962 loss)
I0603 05:07:12.612737   861 sgd_solver.cpp:176] Iteration 570, lr = 0.00637377
I0603 05:07:20.264897   861 solver.cpp:316] Iteration 572, loss = 1.31881
I0603 05:07:20.264955   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:07:20.264974   861 solver.cpp:332]     Train net output #1: loss = 0.814532 (* 1 = 0.814532 loss)
I0603 05:07:20.264986   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.859014 (* 0.3 = 0.257704 loss)
I0603 05:07:20.264994   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.821914 (* 0.3 = 0.246574 loss)
I0603 05:07:20.265009   861 sgd_solver.cpp:176] Iteration 572, lr = 0.00635741
I0603 05:07:27.922816   861 solver.cpp:316] Iteration 574, loss = 1.41616
I0603 05:07:27.922976   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:07:27.922996   861 solver.cpp:332]     Train net output #1: loss = 0.92208 (* 1 = 0.92208 loss)
I0603 05:07:27.923007   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.745888 (* 0.3 = 0.223766 loss)
I0603 05:07:27.923017   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.901049 (* 0.3 = 0.270315 loss)
I0603 05:07:27.923032   861 sgd_solver.cpp:176] Iteration 574, lr = 0.006341
I0603 05:07:31.784775   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_576.caffemodel
I0603 05:07:31.954238   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_576.solverstate
I0603 05:07:36.047380   861 solver.cpp:316] Iteration 576, loss = 1.66247
I0603 05:07:36.047446   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:07:36.047463   861 solver.cpp:332]     Train net output #1: loss = 1.06447 (* 1 = 1.06447 loss)
I0603 05:07:36.047474   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.934578 (* 0.3 = 0.280373 loss)
I0603 05:07:36.047484   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05877 (* 0.3 = 0.317631 loss)
I0603 05:07:36.047499   861 sgd_solver.cpp:176] Iteration 576, lr = 0.00632455
I0603 05:07:43.816735   861 solver.cpp:316] Iteration 578, loss = 1.91532
I0603 05:07:43.816794   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 05:07:43.816813   861 solver.cpp:332]     Train net output #1: loss = 1.22203 (* 1 = 1.22203 loss)
I0603 05:07:43.816823   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09202 (* 0.3 = 0.327606 loss)
I0603 05:07:43.816833   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.21896 (* 0.3 = 0.365687 loss)
I0603 05:07:43.816848   861 sgd_solver.cpp:176] Iteration 578, lr = 0.00630806
I0603 05:07:58.918314   861 solver.cpp:316] Iteration 580, loss = 1.41285
I0603 05:07:58.918427   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:07:58.918442   861 solver.cpp:332]     Train net output #1: loss = 0.896001 (* 1 = 0.896001 loss)
I0603 05:07:58.918449   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.85171 (* 0.3 = 0.255513 loss)
I0603 05:07:58.918457   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.871104 (* 0.3 = 0.261331 loss)
I0603 05:07:58.918467   861 sgd_solver.cpp:176] Iteration 580, lr = 0.00629153
I0603 05:08:13.630054   861 solver.cpp:316] Iteration 582, loss = 1.53748
I0603 05:08:13.630110   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:08:13.630122   861 solver.cpp:332]     Train net output #1: loss = 0.987111 (* 1 = 0.987111 loss)
I0603 05:08:13.630129   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.864401 (* 0.3 = 0.25932 loss)
I0603 05:08:13.630136   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.970179 (* 0.3 = 0.291054 loss)
I0603 05:08:13.630147   861 sgd_solver.cpp:176] Iteration 582, lr = 0.00627495
I0603 05:08:23.606559   861 solver.cpp:316] Iteration 584, loss = 1.47863
I0603 05:08:23.606618   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:08:23.606631   861 solver.cpp:332]     Train net output #1: loss = 0.929935 (* 1 = 0.929935 loss)
I0603 05:08:23.606639   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.926358 (* 0.3 = 0.277907 loss)
I0603 05:08:23.606645   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.902627 (* 0.3 = 0.270788 loss)
I0603 05:08:23.606657   861 sgd_solver.cpp:176] Iteration 584, lr = 0.00625833
I0603 05:08:31.242058   861 solver.cpp:316] Iteration 586, loss = 1.48957
I0603 05:08:31.242162   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:08:31.242177   861 solver.cpp:332]     Train net output #1: loss = 0.931619 (* 1 = 0.931619 loss)
I0603 05:08:31.242184   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.965908 (* 0.3 = 0.289772 loss)
I0603 05:08:31.242192   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.893942 (* 0.3 = 0.268183 loss)
I0603 05:08:31.242202   861 sgd_solver.cpp:176] Iteration 586, lr = 0.00624166
I0603 05:08:39.117920   861 solver.cpp:316] Iteration 588, loss = 1.75348
I0603 05:08:39.117979   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:08:39.117993   861 solver.cpp:332]     Train net output #1: loss = 1.10122 (* 1 = 1.10122 loss)
I0603 05:08:39.118001   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.1084 (* 0.3 = 0.33252 loss)
I0603 05:08:39.118007   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06582 (* 0.3 = 0.319747 loss)
I0603 05:08:39.118018   861 sgd_solver.cpp:176] Iteration 588, lr = 0.00622495
I0603 05:08:46.820375   861 solver.cpp:316] Iteration 590, loss = 1.63902
I0603 05:08:46.820435   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:08:46.820447   861 solver.cpp:332]     Train net output #1: loss = 1.03626 (* 1 = 1.03626 loss)
I0603 05:08:46.820454   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.989566 (* 0.3 = 0.29687 loss)
I0603 05:08:46.820461   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01962 (* 0.3 = 0.305886 loss)
I0603 05:08:46.820472   861 sgd_solver.cpp:176] Iteration 590, lr = 0.00620819
I0603 05:08:54.476306   861 solver.cpp:316] Iteration 592, loss = 1.61236
I0603 05:08:54.476358   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:08:54.476372   861 solver.cpp:332]     Train net output #1: loss = 1.01546 (* 1 = 1.01546 loss)
I0603 05:08:54.476380   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.974285 (* 0.3 = 0.292285 loss)
I0603 05:08:54.476388   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01536 (* 0.3 = 0.304607 loss)
I0603 05:08:54.476399   861 sgd_solver.cpp:176] Iteration 592, lr = 0.00619139
I0603 05:09:02.176082   861 solver.cpp:316] Iteration 594, loss = 1.35407
I0603 05:09:02.176211   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:09:02.176234   861 solver.cpp:332]     Train net output #1: loss = 0.861335 (* 1 = 0.861335 loss)
I0603 05:09:02.176245   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.853238 (* 0.3 = 0.255971 loss)
I0603 05:09:02.176255   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.789208 (* 0.3 = 0.236763 loss)
I0603 05:09:02.176270   861 sgd_solver.cpp:176] Iteration 594, lr = 0.00617454
I0603 05:09:09.796835   861 solver.cpp:316] Iteration 596, loss = 1.62058
I0603 05:09:09.796898   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:09:09.796921   861 solver.cpp:332]     Train net output #1: loss = 1.01194 (* 1 = 1.01194 loss)
I0603 05:09:09.796931   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07568 (* 0.3 = 0.322703 loss)
I0603 05:09:09.796941   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.953121 (* 0.3 = 0.285936 loss)
I0603 05:09:09.796954   861 sgd_solver.cpp:176] Iteration 596, lr = 0.00615765
I0603 05:09:17.420429   861 solver.cpp:316] Iteration 598, loss = 1.43594
I0603 05:09:17.420488   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:09:17.420507   861 solver.cpp:332]     Train net output #1: loss = 0.923808 (* 1 = 0.923808 loss)
I0603 05:09:17.420518   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847664 (* 0.3 = 0.254299 loss)
I0603 05:09:17.420528   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.859444 (* 0.3 = 0.257833 loss)
I0603 05:09:17.420542   861 sgd_solver.cpp:176] Iteration 598, lr = 0.00614071
I0603 05:09:25.099512   861 solver.cpp:316] Iteration 600, loss = 1.47154
I0603 05:09:25.099573   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:09:25.099592   861 solver.cpp:332]     Train net output #1: loss = 0.928439 (* 1 = 0.928439 loss)
I0603 05:09:25.099602   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.91272 (* 0.3 = 0.273816 loss)
I0603 05:09:25.099611   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.897621 (* 0.3 = 0.269286 loss)
I0603 05:09:25.099627   861 sgd_solver.cpp:176] Iteration 600, lr = 0.00612372
I0603 05:09:32.765719   861 solver.cpp:316] Iteration 602, loss = 1.39252
I0603 05:09:32.765851   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:09:32.765872   861 solver.cpp:332]     Train net output #1: loss = 0.881626 (* 1 = 0.881626 loss)
I0603 05:09:32.765882   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.810926 (* 0.3 = 0.243278 loss)
I0603 05:09:32.765892   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.892057 (* 0.3 = 0.267617 loss)
I0603 05:09:32.765908   861 sgd_solver.cpp:176] Iteration 602, lr = 0.00610669
I0603 05:09:40.681038   861 solver.cpp:316] Iteration 604, loss = 1.34633
I0603 05:09:40.681092   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:09:40.681112   861 solver.cpp:332]     Train net output #1: loss = 0.831762 (* 1 = 0.831762 loss)
I0603 05:09:40.681123   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.872082 (* 0.3 = 0.261624 loss)
I0603 05:09:40.681133   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.843152 (* 0.3 = 0.252946 loss)
I0603 05:09:40.681147   861 sgd_solver.cpp:176] Iteration 604, lr = 0.00608961
I0603 05:09:48.329874   861 solver.cpp:316] Iteration 606, loss = 1.59678
I0603 05:09:48.329942   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:09:48.329962   861 solver.cpp:332]     Train net output #1: loss = 1.02725 (* 1 = 1.02725 loss)
I0603 05:09:48.329974   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.945084 (* 0.3 = 0.283525 loss)
I0603 05:09:48.329985   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.953329 (* 0.3 = 0.285999 loss)
I0603 05:09:48.330001   861 sgd_solver.cpp:176] Iteration 606, lr = 0.00607248
I0603 05:09:52.195667   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_608.caffemodel
I0603 05:09:52.360975   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_608.solverstate
I0603 05:09:56.213845   861 solver.cpp:316] Iteration 608, loss = 1.35102
I0603 05:09:56.213904   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:09:56.213925   861 solver.cpp:332]     Train net output #1: loss = 0.87054 (* 1 = 0.87054 loss)
I0603 05:09:56.213935   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.72649 (* 0.3 = 0.217947 loss)
I0603 05:09:56.213945   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.875095 (* 0.3 = 0.262529 loss)
I0603 05:09:56.213959   861 sgd_solver.cpp:176] Iteration 608, lr = 0.0060553
I0603 05:10:03.922366   861 solver.cpp:316] Iteration 610, loss = 1.63645
I0603 05:10:03.922480   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:10:03.922500   861 solver.cpp:332]     Train net output #1: loss = 1.01138 (* 1 = 1.01138 loss)
I0603 05:10:03.922510   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.998059 (* 0.3 = 0.299418 loss)
I0603 05:10:03.922521   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0855 (* 0.3 = 0.325649 loss)
I0603 05:10:03.922535   861 sgd_solver.cpp:176] Iteration 610, lr = 0.00603807
I0603 05:10:19.058320   861 solver.cpp:316] Iteration 612, loss = 1.40119
I0603 05:10:19.058367   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:10:19.058378   861 solver.cpp:332]     Train net output #1: loss = 0.887059 (* 1 = 0.887059 loss)
I0603 05:10:19.058387   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.883699 (* 0.3 = 0.26511 loss)
I0603 05:10:19.058393   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.830067 (* 0.3 = 0.24902 loss)
I0603 05:10:19.058403   861 sgd_solver.cpp:176] Iteration 612, lr = 0.0060208
I0603 05:10:33.818327   861 solver.cpp:316] Iteration 614, loss = 1.47704
I0603 05:10:33.818383   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:10:33.818403   861 solver.cpp:332]     Train net output #1: loss = 0.942621 (* 1 = 0.942621 loss)
I0603 05:10:33.818413   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.829464 (* 0.3 = 0.248839 loss)
I0603 05:10:33.818423   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.951921 (* 0.3 = 0.285576 loss)
I0603 05:10:33.818439   861 sgd_solver.cpp:176] Iteration 614, lr = 0.00600347
I0603 05:10:43.880115   861 solver.cpp:316] Iteration 616, loss = 1.48856
I0603 05:10:43.880250   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:10:43.880271   861 solver.cpp:332]     Train net output #1: loss = 0.926941 (* 1 = 0.926941 loss)
I0603 05:10:43.880281   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.902895 (* 0.3 = 0.270869 loss)
I0603 05:10:43.880291   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.969181 (* 0.3 = 0.290754 loss)
I0603 05:10:43.880306   861 sgd_solver.cpp:176] Iteration 616, lr = 0.00598609
I0603 05:10:51.546311   861 solver.cpp:316] Iteration 618, loss = 1.51071
I0603 05:10:51.546368   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:10:51.546386   861 solver.cpp:332]     Train net output #1: loss = 0.903254 (* 1 = 0.903254 loss)
I0603 05:10:51.546397   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00254 (* 0.3 = 0.300762 loss)
I0603 05:10:51.546407   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0223 (* 0.3 = 0.30669 loss)
I0603 05:10:51.546423   861 sgd_solver.cpp:176] Iteration 618, lr = 0.00596867
I0603 05:10:59.172277   861 solver.cpp:316] Iteration 620, loss = 1.77234
I0603 05:10:59.172338   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:10:59.172355   861 solver.cpp:332]     Train net output #1: loss = 1.12529 (* 1 = 1.12529 loss)
I0603 05:10:59.172365   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04756 (* 0.3 = 0.314268 loss)
I0603 05:10:59.172376   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10927 (* 0.3 = 0.33278 loss)
I0603 05:10:59.172389   861 sgd_solver.cpp:176] Iteration 620, lr = 0.00595119
I0603 05:11:06.846068   861 solver.cpp:316] Iteration 622, loss = 1.38999
I0603 05:11:06.846138   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:11:06.846156   861 solver.cpp:332]     Train net output #1: loss = 0.906696 (* 1 = 0.906696 loss)
I0603 05:11:06.846166   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.787604 (* 0.3 = 0.236281 loss)
I0603 05:11:06.846176   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.82339 (* 0.3 = 0.247017 loss)
I0603 05:11:06.846191   861 sgd_solver.cpp:176] Iteration 622, lr = 0.00593366
I0603 05:11:14.462680   861 solver.cpp:316] Iteration 624, loss = 1.49067
I0603 05:11:14.462788   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:11:14.462808   861 solver.cpp:332]     Train net output #1: loss = 0.970222 (* 1 = 0.970222 loss)
I0603 05:11:14.462818   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.861605 (* 0.3 = 0.258482 loss)
I0603 05:11:14.462828   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.873211 (* 0.3 = 0.261963 loss)
I0603 05:11:14.462843   861 sgd_solver.cpp:176] Iteration 624, lr = 0.00591608
I0603 05:11:22.096045   861 solver.cpp:316] Iteration 626, loss = 1.42649
I0603 05:11:22.096107   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:11:22.096127   861 solver.cpp:332]     Train net output #1: loss = 0.901836 (* 1 = 0.901836 loss)
I0603 05:11:22.096137   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.831512 (* 0.3 = 0.249454 loss)
I0603 05:11:22.096145   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.917339 (* 0.3 = 0.275202 loss)
I0603 05:11:22.096159   861 sgd_solver.cpp:176] Iteration 626, lr = 0.00589845
I0603 05:11:29.758384   861 solver.cpp:316] Iteration 628, loss = 1.41155
I0603 05:11:29.758441   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:11:29.758460   861 solver.cpp:332]     Train net output #1: loss = 0.892428 (* 1 = 0.892428 loss)
I0603 05:11:29.758471   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.808917 (* 0.3 = 0.242675 loss)
I0603 05:11:29.758481   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.921494 (* 0.3 = 0.276448 loss)
I0603 05:11:29.758496   861 sgd_solver.cpp:176] Iteration 628, lr = 0.00588076
I0603 05:11:37.667812   861 solver.cpp:316] Iteration 630, loss = 1.60171
I0603 05:11:37.667867   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:11:37.667886   861 solver.cpp:332]     Train net output #1: loss = 1.02078 (* 1 = 1.02078 loss)
I0603 05:11:37.667896   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.869189 (* 0.3 = 0.260757 loss)
I0603 05:11:37.667906   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.06724 (* 0.3 = 0.320172 loss)
I0603 05:11:37.667922   861 sgd_solver.cpp:176] Iteration 630, lr = 0.00586302
I0603 05:11:45.354147   861 solver.cpp:316] Iteration 632, loss = 1.46054
I0603 05:11:45.354327   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:11:45.354348   861 solver.cpp:332]     Train net output #1: loss = 0.912616 (* 1 = 0.912616 loss)
I0603 05:11:45.354359   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.899704 (* 0.3 = 0.269911 loss)
I0603 05:11:45.354369   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.926696 (* 0.3 = 0.278009 loss)
I0603 05:11:45.354383   861 sgd_solver.cpp:176] Iteration 632, lr = 0.00584523
I0603 05:11:53.004132   861 solver.cpp:316] Iteration 634, loss = 1.42758
I0603 05:11:53.004195   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:11:53.004215   861 solver.cpp:332]     Train net output #1: loss = 0.888495 (* 1 = 0.888495 loss)
I0603 05:11:53.004225   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.819544 (* 0.3 = 0.245863 loss)
I0603 05:11:53.004235   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.977394 (* 0.3 = 0.293218 loss)
I0603 05:11:53.004248   861 sgd_solver.cpp:176] Iteration 634, lr = 0.00582738
I0603 05:12:00.595671   861 solver.cpp:316] Iteration 636, loss = 1.42029
I0603 05:12:00.595734   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:12:00.595754   861 solver.cpp:332]     Train net output #1: loss = 0.902523 (* 1 = 0.902523 loss)
I0603 05:12:00.595765   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.827028 (* 0.3 = 0.248109 loss)
I0603 05:12:00.595774   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.898858 (* 0.3 = 0.269657 loss)
I0603 05:12:00.595788   861 sgd_solver.cpp:176] Iteration 636, lr = 0.00580947
I0603 05:12:08.280086   861 solver.cpp:316] Iteration 638, loss = 1.50391
I0603 05:12:08.280143   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:12:08.280160   861 solver.cpp:332]     Train net output #1: loss = 0.949087 (* 1 = 0.949087 loss)
I0603 05:12:08.280170   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.940435 (* 0.3 = 0.28213 loss)
I0603 05:12:08.280181   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.908978 (* 0.3 = 0.272693 loss)
I0603 05:12:08.280196   861 sgd_solver.cpp:176] Iteration 638, lr = 0.00579152
I0603 05:12:12.162989   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_640.caffemodel
I0603 05:12:12.323199   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_640.solverstate
I0603 05:12:16.194550   861 solver.cpp:316] Iteration 640, loss = 1.39944
I0603 05:12:16.194659   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:12:16.194674   861 solver.cpp:332]     Train net output #1: loss = 0.868696 (* 1 = 0.868696 loss)
I0603 05:12:16.194682   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.895148 (* 0.3 = 0.268544 loss)
I0603 05:12:16.194689   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.874006 (* 0.3 = 0.262202 loss)
I0603 05:12:16.194700   861 sgd_solver.cpp:176] Iteration 640, lr = 0.0057735
I0603 05:12:23.901298   861 solver.cpp:316] Iteration 642, loss = 1.27975
I0603 05:12:23.901356   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:12:23.901371   861 solver.cpp:332]     Train net output #1: loss = 0.821508 (* 1 = 0.821508 loss)
I0603 05:12:23.901378   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.785231 (* 0.3 = 0.235569 loss)
I0603 05:12:23.901384   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.742232 (* 0.3 = 0.22267 loss)
I0603 05:12:23.901396   861 sgd_solver.cpp:176] Iteration 642, lr = 0.00575543
I0603 05:12:39.274330   861 solver.cpp:316] Iteration 644, loss = 1.3356
I0603 05:12:39.274389   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:12:39.274411   861 solver.cpp:332]     Train net output #1: loss = 0.842861 (* 1 = 0.842861 loss)
I0603 05:12:39.274423   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.834715 (* 0.3 = 0.250414 loss)
I0603 05:12:39.274432   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.807746 (* 0.3 = 0.242324 loss)
I0603 05:12:39.274447   861 sgd_solver.cpp:176] Iteration 644, lr = 0.0057373
I0603 05:12:54.152451   861 solver.cpp:316] Iteration 646, loss = 1.45432
I0603 05:12:54.152592   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:12:54.152614   861 solver.cpp:332]     Train net output #1: loss = 0.935849 (* 1 = 0.935849 loss)
I0603 05:12:54.152626   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.882015 (* 0.3 = 0.264604 loss)
I0603 05:12:54.152636   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.846213 (* 0.3 = 0.253864 loss)
I0603 05:12:54.152650   861 sgd_solver.cpp:176] Iteration 646, lr = 0.00571912
I0603 05:13:04.002796   861 solver.cpp:316] Iteration 648, loss = 1.75134
I0603 05:13:04.002856   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:13:04.002874   861 solver.cpp:332]     Train net output #1: loss = 1.05852 (* 1 = 1.05852 loss)
I0603 05:13:04.002885   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.2319 (* 0.3 = 0.36957 loss)
I0603 05:13:04.002895   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0775 (* 0.3 = 0.323251 loss)
I0603 05:13:04.002909   861 sgd_solver.cpp:176] Iteration 648, lr = 0.00570088
I0603 05:13:11.623838   861 solver.cpp:316] Iteration 650, loss = 1.584
I0603 05:13:11.623914   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:13:11.623935   861 solver.cpp:332]     Train net output #1: loss = 0.995648 (* 1 = 0.995648 loss)
I0603 05:13:11.623946   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.98165 (* 0.3 = 0.294495 loss)
I0603 05:13:11.623956   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.97953 (* 0.3 = 0.293859 loss)
I0603 05:13:11.623971   861 sgd_solver.cpp:176] Iteration 650, lr = 0.00568258
I0603 05:13:19.302708   861 solver.cpp:316] Iteration 652, loss = 1.87131
I0603 05:13:19.302767   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:13:19.302785   861 solver.cpp:332]     Train net output #1: loss = 1.25709 (* 1 = 1.25709 loss)
I0603 05:13:19.302796   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.956805 (* 0.3 = 0.287042 loss)
I0603 05:13:19.302806   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.09061 (* 0.3 = 0.327184 loss)
I0603 05:13:19.302822   861 sgd_solver.cpp:176] Iteration 652, lr = 0.00566421
I0603 05:13:26.948022   861 solver.cpp:316] Iteration 654, loss = 1.89905
I0603 05:13:26.948151   861 solver.cpp:332]     Train net output #0: accuracy = 0.3125
I0603 05:13:26.948173   861 solver.cpp:332]     Train net output #1: loss = 1.33454 (* 1 = 1.33454 loss)
I0603 05:13:26.948182   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.888539 (* 0.3 = 0.266562 loss)
I0603 05:13:26.948192   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.993138 (* 0.3 = 0.297942 loss)
I0603 05:13:26.948207   861 sgd_solver.cpp:176] Iteration 654, lr = 0.00564579
I0603 05:13:34.760294   861 solver.cpp:316] Iteration 656, loss = 1.41629
I0603 05:13:34.760352   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:13:34.760370   861 solver.cpp:332]     Train net output #1: loss = 0.897546 (* 1 = 0.897546 loss)
I0603 05:13:34.760381   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847319 (* 0.3 = 0.254196 loss)
I0603 05:13:34.760391   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.881834 (* 0.3 = 0.26455 loss)
I0603 05:13:34.760406   861 sgd_solver.cpp:176] Iteration 656, lr = 0.00562731
I0603 05:13:42.505614   861 solver.cpp:316] Iteration 658, loss = 1.56376
I0603 05:13:42.505672   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:13:42.505686   861 solver.cpp:332]     Train net output #1: loss = 0.973955 (* 1 = 0.973955 loss)
I0603 05:13:42.505692   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.999427 (* 0.3 = 0.299828 loss)
I0603 05:13:42.505699   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.966577 (* 0.3 = 0.289973 loss)
I0603 05:13:42.505710   861 sgd_solver.cpp:176] Iteration 658, lr = 0.00560877
I0603 05:13:50.177304   861 solver.cpp:316] Iteration 660, loss = 1.62596
I0603 05:13:50.177359   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:13:50.177372   861 solver.cpp:332]     Train net output #1: loss = 1.03357 (* 1 = 1.03357 loss)
I0603 05:13:50.177379   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.982131 (* 0.3 = 0.294639 loss)
I0603 05:13:50.177386   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.992513 (* 0.3 = 0.297754 loss)
I0603 05:13:50.177397   861 sgd_solver.cpp:176] Iteration 660, lr = 0.00559017
I0603 05:13:57.808362   861 solver.cpp:316] Iteration 662, loss = 1.48148
I0603 05:13:57.808519   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:13:57.808540   861 solver.cpp:332]     Train net output #1: loss = 0.933826 (* 1 = 0.933826 loss)
I0603 05:13:57.808552   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.89874 (* 0.3 = 0.269622 loss)
I0603 05:13:57.808562   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.926787 (* 0.3 = 0.278036 loss)
I0603 05:13:57.808576   861 sgd_solver.cpp:176] Iteration 662, lr = 0.0055715
I0603 05:14:05.446478   861 solver.cpp:316] Iteration 664, loss = 1.46819
I0603 05:14:05.446542   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:14:05.446560   861 solver.cpp:332]     Train net output #1: loss = 0.924835 (* 1 = 0.924835 loss)
I0603 05:14:05.446571   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.900764 (* 0.3 = 0.270229 loss)
I0603 05:14:05.446580   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.910428 (* 0.3 = 0.273128 loss)
I0603 05:14:05.446594   861 sgd_solver.cpp:176] Iteration 664, lr = 0.00555278
I0603 05:14:13.097817   861 solver.cpp:316] Iteration 666, loss = 1.41785
I0603 05:14:13.097882   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:14:13.097899   861 solver.cpp:332]     Train net output #1: loss = 0.915491 (* 1 = 0.915491 loss)
I0603 05:14:13.097910   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.894412 (* 0.3 = 0.268323 loss)
I0603 05:14:13.097919   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.780128 (* 0.3 = 0.234038 loss)
I0603 05:14:13.097934   861 sgd_solver.cpp:176] Iteration 666, lr = 0.00553399
I0603 05:14:20.725697   861 solver.cpp:316] Iteration 668, loss = 1.71362
I0603 05:14:20.725755   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:14:20.725774   861 solver.cpp:332]     Train net output #1: loss = 1.11322 (* 1 = 1.11322 loss)
I0603 05:14:20.725785   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.92751 (* 0.3 = 0.278253 loss)
I0603 05:14:20.725795   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.07385 (* 0.3 = 0.322154 loss)
I0603 05:14:20.725810   861 sgd_solver.cpp:176] Iteration 668, lr = 0.00551513
I0603 05:14:28.432265   861 solver.cpp:316] Iteration 670, loss = 1.60104
I0603 05:14:28.432456   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:14:28.432473   861 solver.cpp:332]     Train net output #1: loss = 1.02102 (* 1 = 1.02102 loss)
I0603 05:14:28.432482   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.06617 (* 0.3 = 0.319851 loss)
I0603 05:14:28.432487   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.867204 (* 0.3 = 0.260161 loss)
I0603 05:14:28.432498   861 sgd_solver.cpp:176] Iteration 670, lr = 0.00549621
I0603 05:14:32.268548   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_672.caffemodel
I0603 05:14:32.427567   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_672.solverstate
I0603 05:14:36.518190   861 solver.cpp:316] Iteration 672, loss = 1.24544
I0603 05:14:36.518254   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 05:14:36.518287   861 solver.cpp:332]     Train net output #1: loss = 0.796369 (* 1 = 0.796369 loss)
I0603 05:14:36.518301   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.776692 (* 0.3 = 0.233008 loss)
I0603 05:14:36.518311   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.72022 (* 0.3 = 0.216066 loss)
I0603 05:14:36.518326   861 sgd_solver.cpp:176] Iteration 672, lr = 0.00547723
I0603 05:14:44.278093   861 solver.cpp:316] Iteration 674, loss = 1.28101
I0603 05:14:44.278153   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:14:44.278172   861 solver.cpp:332]     Train net output #1: loss = 0.824418 (* 1 = 0.824418 loss)
I0603 05:14:44.278182   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.742346 (* 0.3 = 0.222704 loss)
I0603 05:14:44.278193   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.779621 (* 0.3 = 0.233886 loss)
I0603 05:14:44.278208   861 sgd_solver.cpp:176] Iteration 674, lr = 0.00545817
I0603 05:14:59.284883   861 solver.cpp:316] Iteration 676, loss = 1.55682
I0603 05:14:59.294308   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:14:59.294327   861 solver.cpp:332]     Train net output #1: loss = 0.994741 (* 1 = 0.994741 loss)
I0603 05:14:59.294333   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.915527 (* 0.3 = 0.274658 loss)
I0603 05:14:59.294340   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.958071 (* 0.3 = 0.287421 loss)
I0603 05:14:59.294353   861 sgd_solver.cpp:176] Iteration 676, lr = 0.00543906
I0603 05:15:13.982323   861 solver.cpp:316] Iteration 678, loss = 1.46766
I0603 05:15:13.982376   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:15:13.982389   861 solver.cpp:332]     Train net output #1: loss = 0.958619 (* 1 = 0.958619 loss)
I0603 05:15:13.982396   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.846006 (* 0.3 = 0.253802 loss)
I0603 05:15:13.982403   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.850801 (* 0.3 = 0.25524 loss)
I0603 05:15:13.982414   861 sgd_solver.cpp:176] Iteration 678, lr = 0.00541987
I0603 05:15:24.077240   861 solver.cpp:316] Iteration 680, loss = 1.66553
I0603 05:15:24.077296   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:15:24.077311   861 solver.cpp:332]     Train net output #1: loss = 1.0561 (* 1 = 1.0561 loss)
I0603 05:15:24.077317   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04163 (* 0.3 = 0.312489 loss)
I0603 05:15:24.077324   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.989805 (* 0.3 = 0.296941 loss)
I0603 05:15:24.077334   861 sgd_solver.cpp:176] Iteration 680, lr = 0.00540062
I0603 05:15:31.700903   861 solver.cpp:316] Iteration 682, loss = 1.4879
I0603 05:15:31.701086   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:15:31.701102   861 solver.cpp:332]     Train net output #1: loss = 0.897595 (* 1 = 0.897595 loss)
I0603 05:15:31.701108   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.01236 (* 0.3 = 0.303707 loss)
I0603 05:15:31.701115   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.955335 (* 0.3 = 0.286601 loss)
I0603 05:15:31.701126   861 sgd_solver.cpp:176] Iteration 682, lr = 0.00538129
I0603 05:15:39.616976   861 solver.cpp:316] Iteration 684, loss = 1.45011
I0603 05:15:39.617038   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:15:39.617051   861 solver.cpp:332]     Train net output #1: loss = 0.96114 (* 1 = 0.96114 loss)
I0603 05:15:39.617059   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.797059 (* 0.3 = 0.239118 loss)
I0603 05:15:39.617066   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.832836 (* 0.3 = 0.249851 loss)
I0603 05:15:39.617077   861 sgd_solver.cpp:176] Iteration 684, lr = 0.0053619
I0603 05:15:47.295334   861 solver.cpp:316] Iteration 686, loss = 1.48707
I0603 05:15:47.295389   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:15:47.295403   861 solver.cpp:332]     Train net output #1: loss = 0.940996 (* 1 = 0.940996 loss)
I0603 05:15:47.295410   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.883808 (* 0.3 = 0.265142 loss)
I0603 05:15:47.295418   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.936424 (* 0.3 = 0.280927 loss)
I0603 05:15:47.295428   861 sgd_solver.cpp:176] Iteration 686, lr = 0.00534244
I0603 05:15:54.929069   861 solver.cpp:316] Iteration 688, loss = 1.47577
I0603 05:15:54.929126   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:15:54.929141   861 solver.cpp:332]     Train net output #1: loss = 0.894025 (* 1 = 0.894025 loss)
I0603 05:15:54.929148   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.956907 (* 0.3 = 0.287072 loss)
I0603 05:15:54.929154   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.982258 (* 0.3 = 0.294677 loss)
I0603 05:15:54.929165   861 sgd_solver.cpp:176] Iteration 688, lr = 0.00532291
I0603 05:16:02.571611   861 solver.cpp:316] Iteration 690, loss = 1.50335
I0603 05:16:02.571753   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:16:02.571768   861 solver.cpp:332]     Train net output #1: loss = 0.941531 (* 1 = 0.941531 loss)
I0603 05:16:02.571776   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.955896 (* 0.3 = 0.286769 loss)
I0603 05:16:02.571784   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.916818 (* 0.3 = 0.275046 loss)
I0603 05:16:02.571794   861 sgd_solver.cpp:176] Iteration 690, lr = 0.0053033
I0603 05:16:10.209601   861 solver.cpp:316] Iteration 692, loss = 1.29974
I0603 05:16:10.209657   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:16:10.209671   861 solver.cpp:332]     Train net output #1: loss = 0.820043 (* 1 = 0.820043 loss)
I0603 05:16:10.209679   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.741323 (* 0.3 = 0.222397 loss)
I0603 05:16:10.209686   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.85765 (* 0.3 = 0.257295 loss)
I0603 05:16:10.209697   861 sgd_solver.cpp:176] Iteration 692, lr = 0.00528362
I0603 05:16:17.843740   861 solver.cpp:316] Iteration 694, loss = 1.35016
I0603 05:16:17.843799   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:16:17.843812   861 solver.cpp:332]     Train net output #1: loss = 0.844378 (* 1 = 0.844378 loss)
I0603 05:16:17.843821   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.873819 (* 0.3 = 0.262146 loss)
I0603 05:16:17.843827   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.812138 (* 0.3 = 0.243641 loss)
I0603 05:16:17.843838   861 sgd_solver.cpp:176] Iteration 694, lr = 0.00526387
I0603 05:16:25.538749   861 solver.cpp:316] Iteration 696, loss = 1.40201
I0603 05:16:25.538810   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:16:25.538830   861 solver.cpp:332]     Train net output #1: loss = 0.891831 (* 1 = 0.891831 loss)
I0603 05:16:25.538841   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.849491 (* 0.3 = 0.254847 loss)
I0603 05:16:25.538851   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.85109 (* 0.3 = 0.255327 loss)
I0603 05:16:25.538866   861 sgd_solver.cpp:176] Iteration 696, lr = 0.00524404
I0603 05:16:33.174548   861 solver.cpp:316] Iteration 698, loss = 1.32786
I0603 05:16:33.174706   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:16:33.174722   861 solver.cpp:332]     Train net output #1: loss = 0.855149 (* 1 = 0.855149 loss)
I0603 05:16:33.174731   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.784044 (* 0.3 = 0.235213 loss)
I0603 05:16:33.174737   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.791661 (* 0.3 = 0.237498 loss)
I0603 05:16:33.174747   861 sgd_solver.cpp:176] Iteration 698, lr = 0.00522414
I0603 05:16:41.071966   861 solver.cpp:316] Iteration 700, loss = 1.71809
I0603 05:16:41.072031   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:16:41.072049   861 solver.cpp:332]     Train net output #1: loss = 1.08599 (* 1 = 1.08599 loss)
I0603 05:16:41.072059   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0886 (* 0.3 = 0.32658 loss)
I0603 05:16:41.072069   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.0184 (* 0.3 = 0.305521 loss)
I0603 05:16:41.072084   861 sgd_solver.cpp:176] Iteration 700, lr = 0.00520416
I0603 05:16:48.789538   861 solver.cpp:316] Iteration 702, loss = 1.24255
I0603 05:16:48.789593   861 solver.cpp:332]     Train net output #0: accuracy = 0.75
I0603 05:16:48.789608   861 solver.cpp:332]     Train net output #1: loss = 0.768996 (* 1 = 0.768996 loss)
I0603 05:16:48.789614   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.789673 (* 0.3 = 0.236902 loss)
I0603 05:16:48.789621   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.788829 (* 0.3 = 0.236649 loss)
I0603 05:16:48.789633   861 sgd_solver.cpp:176] Iteration 702, lr = 0.00518411
I0603 05:16:52.631181   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_704.caffemodel
I0603 05:16:52.788121   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_704.solverstate
I0603 05:16:56.705389   861 solver.cpp:316] Iteration 704, loss = 1.24106
I0603 05:16:56.705445   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:16:56.705457   861 solver.cpp:332]     Train net output #1: loss = 0.790588 (* 1 = 0.790588 loss)
I0603 05:16:56.705466   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.748832 (* 0.3 = 0.22465 loss)
I0603 05:16:56.705472   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.752748 (* 0.3 = 0.225824 loss)
I0603 05:16:56.705482   861 sgd_solver.cpp:176] Iteration 704, lr = 0.00516398
I0603 05:17:04.358307   861 solver.cpp:316] Iteration 706, loss = 1.34157
I0603 05:17:04.358408   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:17:04.358428   861 solver.cpp:332]     Train net output #1: loss = 0.84624 (* 1 = 0.84624 loss)
I0603 05:17:04.358439   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.831248 (* 0.3 = 0.249375 loss)
I0603 05:17:04.358449   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.81986 (* 0.3 = 0.245958 loss)
I0603 05:17:04.358464   861 sgd_solver.cpp:176] Iteration 706, lr = 0.00514377
I0603 05:17:19.471632   861 solver.cpp:316] Iteration 708, loss = 1.63587
I0603 05:17:19.471678   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 05:17:19.471690   861 solver.cpp:332]     Train net output #1: loss = 1.03172 (* 1 = 1.03172 loss)
I0603 05:17:19.471698   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.973954 (* 0.3 = 0.292186 loss)
I0603 05:17:19.471704   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03986 (* 0.3 = 0.311959 loss)
I0603 05:17:19.471715   861 sgd_solver.cpp:176] Iteration 708, lr = 0.00512348
I0603 05:17:34.178323   861 solver.cpp:316] Iteration 710, loss = 1.2609
I0603 05:17:34.178377   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:17:34.178395   861 solver.cpp:332]     Train net output #1: loss = 0.767801 (* 1 = 0.767801 loss)
I0603 05:17:34.178406   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.823848 (* 0.3 = 0.247154 loss)
I0603 05:17:34.178416   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.819809 (* 0.3 = 0.245943 loss)
I0603 05:17:34.178431   861 sgd_solver.cpp:176] Iteration 710, lr = 0.0051031
I0603 05:17:44.418246   861 solver.cpp:316] Iteration 712, loss = 1.30128
I0603 05:17:44.418452   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:17:44.418475   861 solver.cpp:332]     Train net output #1: loss = 0.825405 (* 1 = 0.825405 loss)
I0603 05:17:44.418488   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.809728 (* 0.3 = 0.242918 loss)
I0603 05:17:44.418498   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.77651 (* 0.3 = 0.232953 loss)
I0603 05:17:44.418512   861 sgd_solver.cpp:176] Iteration 712, lr = 0.00508265
I0603 05:17:52.070475   861 solver.cpp:316] Iteration 714, loss = 1.48232
I0603 05:17:52.070534   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:17:52.070549   861 solver.cpp:332]     Train net output #1: loss = 0.947535 (* 1 = 0.947535 loss)
I0603 05:17:52.070555   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.910307 (* 0.3 = 0.273092 loss)
I0603 05:17:52.070562   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.872296 (* 0.3 = 0.261689 loss)
I0603 05:17:52.070574   861 sgd_solver.cpp:176] Iteration 714, lr = 0.00506211
I0603 05:17:59.684069   861 solver.cpp:316] Iteration 716, loss = 1.39692
I0603 05:17:59.684132   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:17:59.684149   861 solver.cpp:332]     Train net output #1: loss = 0.902576 (* 1 = 0.902576 loss)
I0603 05:17:59.684159   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.827944 (* 0.3 = 0.248383 loss)
I0603 05:17:59.684168   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.819858 (* 0.3 = 0.245957 loss)
I0603 05:17:59.684181   861 sgd_solver.cpp:176] Iteration 716, lr = 0.00504149
I0603 05:18:07.369786   861 solver.cpp:316] Iteration 718, loss = 1.77292
I0603 05:18:07.369840   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:18:07.369854   861 solver.cpp:332]     Train net output #1: loss = 1.09305 (* 1 = 1.09305 loss)
I0603 05:18:07.369863   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.10189 (* 0.3 = 0.330568 loss)
I0603 05:18:07.369869   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.16434 (* 0.3 = 0.349303 loss)
I0603 05:18:07.369880   861 sgd_solver.cpp:176] Iteration 718, lr = 0.00502079
I0603 05:18:15.033723   861 solver.cpp:316] Iteration 720, loss = 1.5294
I0603 05:18:15.033844   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:18:15.033859   861 solver.cpp:332]     Train net output #1: loss = 0.894672 (* 1 = 0.894672 loss)
I0603 05:18:15.033867   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.16881 (* 0.3 = 0.350643 loss)
I0603 05:18:15.033874   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.946949 (* 0.3 = 0.284085 loss)
I0603 05:18:15.033885   861 sgd_solver.cpp:176] Iteration 720, lr = 0.005
I0603 05:18:22.701896   861 solver.cpp:316] Iteration 722, loss = 1.61535
I0603 05:18:22.701963   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:18:22.701982   861 solver.cpp:332]     Train net output #1: loss = 1.02355 (* 1 = 1.02355 loss)
I0603 05:18:22.701992   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.960148 (* 0.3 = 0.288044 loss)
I0603 05:18:22.702003   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01252 (* 0.3 = 0.303755 loss)
I0603 05:18:22.702018   861 sgd_solver.cpp:176] Iteration 722, lr = 0.00497912
I0603 05:18:30.341094   861 solver.cpp:316] Iteration 724, loss = 1.48503
I0603 05:18:30.341152   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:18:30.341171   861 solver.cpp:332]     Train net output #1: loss = 0.926404 (* 1 = 0.926404 loss)
I0603 05:18:30.341181   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.894245 (* 0.3 = 0.268274 loss)
I0603 05:18:30.341190   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.967828 (* 0.3 = 0.290349 loss)
I0603 05:18:30.341205   861 sgd_solver.cpp:176] Iteration 724, lr = 0.00495816
I0603 05:18:38.234040   861 solver.cpp:316] Iteration 726, loss = 1.4079
I0603 05:18:38.234096   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:18:38.234108   861 solver.cpp:332]     Train net output #1: loss = 0.866251 (* 1 = 0.866251 loss)
I0603 05:18:38.234115   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.922609 (* 0.3 = 0.276783 loss)
I0603 05:18:38.234122   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.882882 (* 0.3 = 0.264864 loss)
I0603 05:18:38.234133   861 sgd_solver.cpp:176] Iteration 726, lr = 0.0049371
I0603 05:18:45.921634   861 solver.cpp:316] Iteration 728, loss = 1.41314
I0603 05:18:45.921756   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:18:45.921772   861 solver.cpp:332]     Train net output #1: loss = 0.891409 (* 1 = 0.891409 loss)
I0603 05:18:45.921780   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.823069 (* 0.3 = 0.246921 loss)
I0603 05:18:45.921787   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.916041 (* 0.3 = 0.274812 loss)
I0603 05:18:45.921798   861 sgd_solver.cpp:176] Iteration 728, lr = 0.00491596
I0603 05:18:53.535873   861 solver.cpp:316] Iteration 730, loss = 1.17479
I0603 05:18:53.535933   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:18:53.535948   861 solver.cpp:332]     Train net output #1: loss = 0.765151 (* 1 = 0.765151 loss)
I0603 05:18:53.535956   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.676108 (* 0.3 = 0.202833 loss)
I0603 05:18:53.535962   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.689371 (* 0.3 = 0.206811 loss)
I0603 05:18:53.535974   861 sgd_solver.cpp:176] Iteration 730, lr = 0.00489472
I0603 05:19:01.186091   861 solver.cpp:316] Iteration 732, loss = 1.61016
I0603 05:19:01.186153   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:19:01.186167   861 solver.cpp:332]     Train net output #1: loss = 1.01763 (* 1 = 1.01763 loss)
I0603 05:19:01.186174   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.04454 (* 0.3 = 0.313363 loss)
I0603 05:19:01.186182   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.930557 (* 0.3 = 0.279167 loss)
I0603 05:19:01.186192   861 sgd_solver.cpp:176] Iteration 732, lr = 0.0048734
I0603 05:19:08.863605   861 solver.cpp:316] Iteration 734, loss = 1.24945
I0603 05:19:08.863662   861 solver.cpp:332]     Train net output #0: accuracy = 0.75
I0603 05:19:08.863677   861 solver.cpp:332]     Train net output #1: loss = 0.778134 (* 1 = 0.778134 loss)
I0603 05:19:08.863685   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.799181 (* 0.3 = 0.239754 loss)
I0603 05:19:08.863692   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.771866 (* 0.3 = 0.23156 loss)
I0603 05:19:08.863703   861 sgd_solver.cpp:176] Iteration 734, lr = 0.00485198
I0603 05:19:12.718861   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_736.caffemodel
I0603 05:19:12.876303   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_736.solverstate
I0603 05:19:16.800685   861 solver.cpp:316] Iteration 736, loss = 1.24607
I0603 05:19:16.800849   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:19:16.800870   861 solver.cpp:332]     Train net output #1: loss = 0.792599 (* 1 = 0.792599 loss)
I0603 05:19:16.800881   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.764357 (* 0.3 = 0.229307 loss)
I0603 05:19:16.800891   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.747218 (* 0.3 = 0.224165 loss)
I0603 05:19:16.800905   861 sgd_solver.cpp:176] Iteration 736, lr = 0.00483046
I0603 05:19:24.479564   861 solver.cpp:316] Iteration 738, loss = 1.39264
I0603 05:19:24.479630   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:19:24.479650   861 solver.cpp:332]     Train net output #1: loss = 0.898632 (* 1 = 0.898632 loss)
I0603 05:19:24.479662   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.849041 (* 0.3 = 0.254712 loss)
I0603 05:19:24.479672   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.797659 (* 0.3 = 0.239298 loss)
I0603 05:19:24.479686   861 sgd_solver.cpp:176] Iteration 738, lr = 0.00480885
I0603 05:19:39.862315   861 solver.cpp:316] Iteration 740, loss = 1.81724
I0603 05:19:39.862361   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 05:19:39.862373   861 solver.cpp:332]     Train net output #1: loss = 1.11403 (* 1 = 1.11403 loss)
I0603 05:19:39.862381   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.19828 (* 0.3 = 0.359484 loss)
I0603 05:19:39.862387   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.14574 (* 0.3 = 0.343723 loss)
I0603 05:19:39.862399   861 sgd_solver.cpp:176] Iteration 740, lr = 0.00478714
I0603 05:19:54.594314   861 solver.cpp:316] Iteration 742, loss = 1.38506
I0603 05:19:54.594440   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:19:54.594460   861 solver.cpp:332]     Train net output #1: loss = 0.837097 (* 1 = 0.837097 loss)
I0603 05:19:54.594471   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.895204 (* 0.3 = 0.268561 loss)
I0603 05:19:54.594481   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.931324 (* 0.3 = 0.279397 loss)
I0603 05:19:54.594496   861 sgd_solver.cpp:176] Iteration 742, lr = 0.00476533
I0603 05:20:04.579308   861 solver.cpp:316] Iteration 744, loss = 1.39061
I0603 05:20:04.579367   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:20:04.579386   861 solver.cpp:332]     Train net output #1: loss = 0.866602 (* 1 = 0.866602 loss)
I0603 05:20:04.579396   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.879851 (* 0.3 = 0.263955 loss)
I0603 05:20:04.579406   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.866858 (* 0.3 = 0.260057 loss)
I0603 05:20:04.579421   861 sgd_solver.cpp:176] Iteration 744, lr = 0.00474342
I0603 05:20:12.223594   861 solver.cpp:316] Iteration 746, loss = 1.26765
I0603 05:20:12.223657   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:20:12.223676   861 solver.cpp:332]     Train net output #1: loss = 0.79601 (* 1 = 0.79601 loss)
I0603 05:20:12.223687   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.766568 (* 0.3 = 0.229971 loss)
I0603 05:20:12.223695   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.805556 (* 0.3 = 0.241667 loss)
I0603 05:20:12.223711   861 sgd_solver.cpp:176] Iteration 746, lr = 0.0047214
I0603 05:20:19.876963   861 solver.cpp:316] Iteration 748, loss = 1.5066
I0603 05:20:19.877022   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:20:19.877039   861 solver.cpp:332]     Train net output #1: loss = 0.937624 (* 1 = 0.937624 loss)
I0603 05:20:19.877050   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.935026 (* 0.3 = 0.280508 loss)
I0603 05:20:19.877060   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.961562 (* 0.3 = 0.288468 loss)
I0603 05:20:19.877075   861 sgd_solver.cpp:176] Iteration 748, lr = 0.00469929
I0603 05:20:27.583972   861 solver.cpp:316] Iteration 750, loss = 1.67516
I0603 05:20:27.584077   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:20:27.584097   861 solver.cpp:332]     Train net output #1: loss = 1.07938 (* 1 = 1.07938 loss)
I0603 05:20:27.584108   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.956912 (* 0.3 = 0.287074 loss)
I0603 05:20:27.584117   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.02901 (* 0.3 = 0.308704 loss)
I0603 05:20:27.584132   861 sgd_solver.cpp:176] Iteration 750, lr = 0.00467707
I0603 05:20:35.343032   861 solver.cpp:316] Iteration 752, loss = 1.85085
I0603 05:20:35.343097   861 solver.cpp:332]     Train net output #0: accuracy = 0.3125
I0603 05:20:35.343116   861 solver.cpp:332]     Train net output #1: loss = 1.25227 (* 1 = 1.25227 loss)
I0603 05:20:35.343127   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.964482 (* 0.3 = 0.289344 loss)
I0603 05:20:35.343135   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03081 (* 0.3 = 0.309242 loss)
I0603 05:20:35.343152   861 sgd_solver.cpp:176] Iteration 752, lr = 0.00465475
I0603 05:20:43.122722   861 solver.cpp:316] Iteration 754, loss = 1.68073
I0603 05:20:43.122787   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:20:43.122807   861 solver.cpp:332]     Train net output #1: loss = 1.09009 (* 1 = 1.09009 loss)
I0603 05:20:43.122818   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.959368 (* 0.3 = 0.28781 loss)
I0603 05:20:43.122829   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.00944 (* 0.3 = 0.302832 loss)
I0603 05:20:43.122843   861 sgd_solver.cpp:176] Iteration 754, lr = 0.00463231
I0603 05:20:50.783110   861 solver.cpp:316] Iteration 756, loss = 1.41643
I0603 05:20:50.783167   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:20:50.783185   861 solver.cpp:332]     Train net output #1: loss = 0.924116 (* 1 = 0.924116 loss)
I0603 05:20:50.783196   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.786014 (* 0.3 = 0.235804 loss)
I0603 05:20:50.783206   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.85503 (* 0.3 = 0.256509 loss)
I0603 05:20:50.783221   861 sgd_solver.cpp:176] Iteration 756, lr = 0.00460977
I0603 05:20:58.423485   861 solver.cpp:316] Iteration 758, loss = 1.73874
I0603 05:20:58.423617   861 solver.cpp:332]     Train net output #0: accuracy = 0.28125
I0603 05:20:58.423637   861 solver.cpp:332]     Train net output #1: loss = 1.11603 (* 1 = 1.11603 loss)
I0603 05:20:58.423647   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.958689 (* 0.3 = 0.287607 loss)
I0603 05:20:58.423657   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.117 (* 0.3 = 0.335102 loss)
I0603 05:20:58.423672   861 sgd_solver.cpp:176] Iteration 758, lr = 0.00458712
I0603 05:21:06.057463   861 solver.cpp:316] Iteration 760, loss = 1.33113
I0603 05:21:06.057520   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:21:06.057533   861 solver.cpp:332]     Train net output #1: loss = 0.823961 (* 1 = 0.823961 loss)
I0603 05:21:06.057540   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.893794 (* 0.3 = 0.268138 loss)
I0603 05:21:06.057548   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.796764 (* 0.3 = 0.239029 loss)
I0603 05:21:06.057559   861 sgd_solver.cpp:176] Iteration 760, lr = 0.00456435
I0603 05:21:13.664813   861 solver.cpp:316] Iteration 762, loss = 1.41663
I0603 05:21:13.664870   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:21:13.664885   861 solver.cpp:332]     Train net output #1: loss = 0.907668 (* 1 = 0.907668 loss)
I0603 05:21:13.664891   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.845732 (* 0.3 = 0.253719 loss)
I0603 05:21:13.664897   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.850822 (* 0.3 = 0.255247 loss)
I0603 05:21:13.664908   861 sgd_solver.cpp:176] Iteration 762, lr = 0.00454148
I0603 05:21:21.296919   861 solver.cpp:316] Iteration 764, loss = 1.41968
I0603 05:21:21.296975   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:21:21.296989   861 solver.cpp:332]     Train net output #1: loss = 0.912289 (* 1 = 0.912289 loss)
I0603 05:21:21.296996   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.862062 (* 0.3 = 0.258619 loss)
I0603 05:21:21.297003   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.829236 (* 0.3 = 0.248771 loss)
I0603 05:21:21.297014   861 sgd_solver.cpp:176] Iteration 764, lr = 0.00451848
I0603 05:21:28.994380   861 solver.cpp:316] Iteration 766, loss = 1.43057
I0603 05:21:28.994498   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:21:28.994518   861 solver.cpp:332]     Train net output #1: loss = 0.863872 (* 1 = 0.863872 loss)
I0603 05:21:28.994529   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.928356 (* 0.3 = 0.278507 loss)
I0603 05:21:28.994539   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.960635 (* 0.3 = 0.28819 loss)
I0603 05:21:28.994554   861 sgd_solver.cpp:176] Iteration 766, lr = 0.00449537
I0603 05:21:32.821424   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_768.caffemodel
I0603 05:21:32.978639   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_768.solverstate
I0603 05:21:37.061064   861 solver.cpp:316] Iteration 768, loss = 1.54341
I0603 05:21:37.061122   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:21:37.061141   861 solver.cpp:332]     Train net output #1: loss = 0.972421 (* 1 = 0.972421 loss)
I0603 05:21:37.061151   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.957532 (* 0.3 = 0.28726 loss)
I0603 05:21:37.061161   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.94576 (* 0.3 = 0.283728 loss)
I0603 05:21:37.061175   861 sgd_solver.cpp:176] Iteration 768, lr = 0.00447214
I0603 05:21:44.744251   861 solver.cpp:316] Iteration 770, loss = 1.29343
I0603 05:21:44.744305   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:21:44.744318   861 solver.cpp:332]     Train net output #1: loss = 0.805209 (* 1 = 0.805209 loss)
I0603 05:21:44.744325   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.7893 (* 0.3 = 0.23679 loss)
I0603 05:21:44.744333   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.838118 (* 0.3 = 0.251435 loss)
I0603 05:21:44.744343   861 sgd_solver.cpp:176] Iteration 770, lr = 0.00444878
I0603 05:21:59.782320   861 solver.cpp:316] Iteration 772, loss = 1.75273
I0603 05:21:59.782455   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:21:59.782470   861 solver.cpp:332]     Train net output #1: loss = 1.11943 (* 1 = 1.11943 loss)
I0603 05:21:59.782479   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0727 (* 0.3 = 0.321811 loss)
I0603 05:21:59.782485   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.03829 (* 0.3 = 0.311487 loss)
I0603 05:21:59.782495   861 sgd_solver.cpp:176] Iteration 772, lr = 0.00442531
I0603 05:22:14.346316   861 solver.cpp:316] Iteration 774, loss = 1.29584
I0603 05:22:14.346372   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:22:14.346390   861 solver.cpp:332]     Train net output #1: loss = 0.848181 (* 1 = 0.848181 loss)
I0603 05:22:14.346401   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.697892 (* 0.3 = 0.209368 loss)
I0603 05:22:14.346411   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.794317 (* 0.3 = 0.238295 loss)
I0603 05:22:14.346426   861 sgd_solver.cpp:176] Iteration 774, lr = 0.0044017
I0603 05:22:24.453642   861 solver.cpp:316] Iteration 776, loss = 1.44485
I0603 05:22:24.453701   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:22:24.453718   861 solver.cpp:332]     Train net output #1: loss = 0.948878 (* 1 = 0.948878 loss)
I0603 05:22:24.453728   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.792535 (* 0.3 = 0.23776 loss)
I0603 05:22:24.453738   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.860693 (* 0.3 = 0.258208 loss)
I0603 05:22:24.453752   861 sgd_solver.cpp:176] Iteration 776, lr = 0.00437798
I0603 05:22:32.085844   861 solver.cpp:316] Iteration 778, loss = 1.44947
I0603 05:22:32.086010   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:22:32.086030   861 solver.cpp:332]     Train net output #1: loss = 0.914771 (* 1 = 0.914771 loss)
I0603 05:22:32.086040   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.939992 (* 0.3 = 0.281998 loss)
I0603 05:22:32.086051   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.842335 (* 0.3 = 0.2527 loss)
I0603 05:22:32.086066   861 sgd_solver.cpp:176] Iteration 778, lr = 0.00435412
I0603 05:22:39.988734   861 solver.cpp:316] Iteration 780, loss = 1.45256
I0603 05:22:39.988790   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:22:39.988807   861 solver.cpp:332]     Train net output #1: loss = 0.910149 (* 1 = 0.910149 loss)
I0603 05:22:39.988817   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.897061 (* 0.3 = 0.269118 loss)
I0603 05:22:39.988827   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.910959 (* 0.3 = 0.273288 loss)
I0603 05:22:39.988842   861 sgd_solver.cpp:176] Iteration 780, lr = 0.00433013
I0603 05:22:47.689932   861 solver.cpp:316] Iteration 782, loss = 1.53639
I0603 05:22:47.689991   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:22:47.690009   861 solver.cpp:332]     Train net output #1: loss = 1.00113 (* 1 = 1.00113 loss)
I0603 05:22:47.690021   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.807194 (* 0.3 = 0.242158 loss)
I0603 05:22:47.690029   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.977015 (* 0.3 = 0.293104 loss)
I0603 05:22:47.690044   861 sgd_solver.cpp:176] Iteration 782, lr = 0.004306
I0603 05:22:55.307279   861 solver.cpp:316] Iteration 784, loss = 1.29011
I0603 05:22:55.307335   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:22:55.307353   861 solver.cpp:332]     Train net output #1: loss = 0.838015 (* 1 = 0.838015 loss)
I0603 05:22:55.307364   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.747814 (* 0.3 = 0.224344 loss)
I0603 05:22:55.307374   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.75918 (* 0.3 = 0.227754 loss)
I0603 05:22:55.307389   861 sgd_solver.cpp:176] Iteration 784, lr = 0.00428174
I0603 05:23:02.947438   861 solver.cpp:316] Iteration 786, loss = 1.43802
I0603 05:23:02.947576   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:23:02.947597   861 solver.cpp:332]     Train net output #1: loss = 0.918484 (* 1 = 0.918484 loss)
I0603 05:23:02.947607   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.789186 (* 0.3 = 0.236756 loss)
I0603 05:23:02.947618   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.942611 (* 0.3 = 0.282783 loss)
I0603 05:23:02.947631   861 sgd_solver.cpp:176] Iteration 786, lr = 0.00425735
I0603 05:23:10.558727   861 solver.cpp:316] Iteration 788, loss = 1.43396
I0603 05:23:10.558784   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:23:10.558801   861 solver.cpp:332]     Train net output #1: loss = 0.894916 (* 1 = 0.894916 loss)
I0603 05:23:10.558812   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.871184 (* 0.3 = 0.261355 loss)
I0603 05:23:10.558821   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.925645 (* 0.3 = 0.277694 loss)
I0603 05:23:10.558836   861 sgd_solver.cpp:176] Iteration 788, lr = 0.00423281
I0603 05:23:18.200528   861 solver.cpp:316] Iteration 790, loss = 1.33426
I0603 05:23:18.200589   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:23:18.200608   861 solver.cpp:332]     Train net output #1: loss = 0.851047 (* 1 = 0.851047 loss)
I0603 05:23:18.200618   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.792854 (* 0.3 = 0.237856 loss)
I0603 05:23:18.200628   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.817864 (* 0.3 = 0.245359 loss)
I0603 05:23:18.200641   861 sgd_solver.cpp:176] Iteration 790, lr = 0.00420813
I0603 05:23:25.796942   861 solver.cpp:316] Iteration 792, loss = 1.36314
I0603 05:23:25.797003   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:23:25.797020   861 solver.cpp:332]     Train net output #1: loss = 0.860066 (* 1 = 0.860066 loss)
I0603 05:23:25.797030   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.827742 (* 0.3 = 0.248323 loss)
I0603 05:23:25.797040   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.849186 (* 0.3 = 0.254756 loss)
I0603 05:23:25.797055   861 sgd_solver.cpp:176] Iteration 792, lr = 0.0041833
I0603 05:23:33.472323   861 solver.cpp:316] Iteration 794, loss = 1.30194
I0603 05:23:33.472481   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:23:33.472501   861 solver.cpp:332]     Train net output #1: loss = 0.80223 (* 1 = 0.80223 loss)
I0603 05:23:33.472510   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.83038 (* 0.3 = 0.249114 loss)
I0603 05:23:33.472520   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.835328 (* 0.3 = 0.250598 loss)
I0603 05:23:33.472535   861 sgd_solver.cpp:176] Iteration 794, lr = 0.00415832
I0603 05:23:41.349273   861 solver.cpp:316] Iteration 796, loss = 1.29684
I0603 05:23:41.349336   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:23:41.349355   861 solver.cpp:332]     Train net output #1: loss = 0.830781 (* 1 = 0.830781 loss)
I0603 05:23:41.349366   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.794974 (* 0.3 = 0.238492 loss)
I0603 05:23:41.349375   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.758545 (* 0.3 = 0.227563 loss)
I0603 05:23:41.349390   861 sgd_solver.cpp:176] Iteration 796, lr = 0.0041332
I0603 05:23:49.038424   861 solver.cpp:316] Iteration 798, loss = 1.41841
I0603 05:23:49.038478   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:23:49.038496   861 solver.cpp:332]     Train net output #1: loss = 0.948185 (* 1 = 0.948185 loss)
I0603 05:23:49.038506   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.75237 (* 0.3 = 0.225711 loss)
I0603 05:23:49.038516   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.815046 (* 0.3 = 0.244514 loss)
I0603 05:23:49.038530   861 sgd_solver.cpp:176] Iteration 798, lr = 0.00410792
I0603 05:23:52.853775   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_800.caffemodel
I0603 05:23:53.019356   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_800.solverstate
I0603 05:23:56.864780   861 solver.cpp:316] Iteration 800, loss = 1.39093
I0603 05:23:56.864840   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:23:56.864857   861 solver.cpp:332]     Train net output #1: loss = 0.860268 (* 1 = 0.860268 loss)
I0603 05:23:56.864867   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.920725 (* 0.3 = 0.276218 loss)
I0603 05:23:56.864876   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.848143 (* 0.3 = 0.254443 loss)
I0603 05:23:56.864890   861 sgd_solver.cpp:176] Iteration 800, lr = 0.00408248
I0603 05:24:04.530937   861 solver.cpp:316] Iteration 802, loss = 1.29742
I0603 05:24:04.531040   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:24:04.531060   861 solver.cpp:332]     Train net output #1: loss = 0.834179 (* 1 = 0.834179 loss)
I0603 05:24:04.531072   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.7851 (* 0.3 = 0.23553 loss)
I0603 05:24:04.531082   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.759047 (* 0.3 = 0.227714 loss)
I0603 05:24:04.531097   861 sgd_solver.cpp:176] Iteration 802, lr = 0.00405689
I0603 05:24:19.550331   861 solver.cpp:316] Iteration 804, loss = 1.20798
I0603 05:24:19.550392   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 05:24:19.550417   861 solver.cpp:332]     Train net output #1: loss = 0.7626 (* 1 = 0.7626 loss)
I0603 05:24:19.550433   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.729428 (* 0.3 = 0.218828 loss)
I0603 05:24:19.550448   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.755177 (* 0.3 = 0.226553 loss)
I0603 05:24:19.550467   861 sgd_solver.cpp:176] Iteration 804, lr = 0.00403113
I0603 05:24:34.170313   861 solver.cpp:316] Iteration 806, loss = 1.44644
I0603 05:24:34.170369   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:24:34.170382   861 solver.cpp:332]     Train net output #1: loss = 0.91132 (* 1 = 0.91132 loss)
I0603 05:24:34.170388   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.912964 (* 0.3 = 0.273889 loss)
I0603 05:24:34.170394   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.870755 (* 0.3 = 0.261227 loss)
I0603 05:24:34.170404   861 sgd_solver.cpp:176] Iteration 806, lr = 0.0040052
I0603 05:24:44.460883   861 solver.cpp:316] Iteration 808, loss = 1.45942
I0603 05:24:44.461076   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:24:44.461092   861 solver.cpp:332]     Train net output #1: loss = 0.954734 (* 1 = 0.954734 loss)
I0603 05:24:44.461100   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.833465 (* 0.3 = 0.25004 loss)
I0603 05:24:44.461107   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.848818 (* 0.3 = 0.254645 loss)
I0603 05:24:44.461117   861 sgd_solver.cpp:176] Iteration 808, lr = 0.00397911
I0603 05:24:52.157667   861 solver.cpp:316] Iteration 810, loss = 1.75965
I0603 05:24:52.157718   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:24:52.157732   861 solver.cpp:332]     Train net output #1: loss = 1.08425 (* 1 = 1.08425 loss)
I0603 05:24:52.157739   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.09621 (* 0.3 = 0.328864 loss)
I0603 05:24:52.157745   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.15512 (* 0.3 = 0.346535 loss)
I0603 05:24:52.157755   861 sgd_solver.cpp:176] Iteration 810, lr = 0.00395285
I0603 05:24:59.805394   861 solver.cpp:316] Iteration 812, loss = 1.55603
I0603 05:24:59.808159   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:24:59.808193   861 solver.cpp:332]     Train net output #1: loss = 0.97863 (* 1 = 0.97863 loss)
I0603 05:24:59.808205   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.935066 (* 0.3 = 0.28052 loss)
I0603 05:24:59.808217   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.989603 (* 0.3 = 0.296881 loss)
I0603 05:24:59.808231   861 sgd_solver.cpp:176] Iteration 812, lr = 0.00392641
I0603 05:25:07.435849   861 solver.cpp:316] Iteration 814, loss = 1.67667
I0603 05:25:07.435909   861 solver.cpp:332]     Train net output #0: accuracy = 0.3125
I0603 05:25:07.435926   861 solver.cpp:332]     Train net output #1: loss = 1.12996 (* 1 = 1.12996 loss)
I0603 05:25:07.435937   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.822502 (* 0.3 = 0.246751 loss)
I0603 05:25:07.435946   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.999867 (* 0.3 = 0.29996 loss)
I0603 05:25:07.435961   861 sgd_solver.cpp:176] Iteration 814, lr = 0.00389979
I0603 05:25:15.045667   861 solver.cpp:316] Iteration 816, loss = 1.46994
I0603 05:25:15.045765   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:25:15.045784   861 solver.cpp:332]     Train net output #1: loss = 0.953924 (* 1 = 0.953924 loss)
I0603 05:25:15.045795   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.814519 (* 0.3 = 0.244356 loss)
I0603 05:25:15.045804   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.90552 (* 0.3 = 0.271656 loss)
I0603 05:25:15.045819   861 sgd_solver.cpp:176] Iteration 816, lr = 0.00387298
I0603 05:25:22.742251   861 solver.cpp:316] Iteration 818, loss = 1.37034
I0603 05:25:22.742326   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:25:22.742341   861 solver.cpp:332]     Train net output #1: loss = 0.862358 (* 1 = 0.862358 loss)
I0603 05:25:22.742348   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.861178 (* 0.3 = 0.258353 loss)
I0603 05:25:22.742354   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.83209 (* 0.3 = 0.249627 loss)
I0603 05:25:22.742364   861 sgd_solver.cpp:176] Iteration 818, lr = 0.00384599
I0603 05:25:30.391546   861 solver.cpp:316] Iteration 820, loss = 1.69422
I0603 05:25:30.391602   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:25:30.391615   861 solver.cpp:332]     Train net output #1: loss = 1.04191 (* 1 = 1.04191 loss)
I0603 05:25:30.391623   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.07302 (* 0.3 = 0.321906 loss)
I0603 05:25:30.391629   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.10135 (* 0.3 = 0.330406 loss)
I0603 05:25:30.391640   861 sgd_solver.cpp:176] Iteration 820, lr = 0.00381881
I0603 05:25:38.262984   861 solver.cpp:316] Iteration 822, loss = 1.35946
I0603 05:25:38.263038   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:25:38.263052   861 solver.cpp:332]     Train net output #1: loss = 0.872989 (* 1 = 0.872989 loss)
I0603 05:25:38.263059   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.824301 (* 0.3 = 0.24729 loss)
I0603 05:25:38.263065   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.797271 (* 0.3 = 0.239181 loss)
I0603 05:25:38.263077   861 sgd_solver.cpp:176] Iteration 822, lr = 0.00379144
I0603 05:25:45.949715   861 solver.cpp:316] Iteration 824, loss = 1.3843
I0603 05:25:45.949854   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:25:45.949870   861 solver.cpp:332]     Train net output #1: loss = 0.868512 (* 1 = 0.868512 loss)
I0603 05:25:45.949877   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.861758 (* 0.3 = 0.258527 loss)
I0603 05:25:45.949883   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.857529 (* 0.3 = 0.257259 loss)
I0603 05:25:45.949893   861 sgd_solver.cpp:176] Iteration 824, lr = 0.00376386
I0603 05:25:53.618474   861 solver.cpp:316] Iteration 826, loss = 1.367
I0603 05:25:53.618535   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:25:53.618548   861 solver.cpp:332]     Train net output #1: loss = 0.835819 (* 1 = 0.835819 loss)
I0603 05:25:53.618556   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.892743 (* 0.3 = 0.267823 loss)
I0603 05:25:53.618561   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.877848 (* 0.3 = 0.263354 loss)
I0603 05:25:53.618572   861 sgd_solver.cpp:176] Iteration 826, lr = 0.00373609
I0603 05:26:01.280469   861 solver.cpp:316] Iteration 828, loss = 1.28675
I0603 05:26:01.280522   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:26:01.280535   861 solver.cpp:332]     Train net output #1: loss = 0.82431 (* 1 = 0.82431 loss)
I0603 05:26:01.280544   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.746283 (* 0.3 = 0.223885 loss)
I0603 05:26:01.280550   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.79517 (* 0.3 = 0.238551 loss)
I0603 05:26:01.280560   861 sgd_solver.cpp:176] Iteration 828, lr = 0.0037081
I0603 05:26:08.927186   861 solver.cpp:316] Iteration 830, loss = 1.58798
I0603 05:26:08.927240   861 solver.cpp:332]     Train net output #0: accuracy = 0.375
I0603 05:26:08.927258   861 solver.cpp:332]     Train net output #1: loss = 1.03253 (* 1 = 1.03253 loss)
I0603 05:26:08.927268   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.956607 (* 0.3 = 0.286982 loss)
I0603 05:26:08.927278   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.894866 (* 0.3 = 0.26846 loss)
I0603 05:26:08.927291   861 sgd_solver.cpp:176] Iteration 830, lr = 0.0036799
I0603 05:26:12.776883   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_832.caffemodel
I0603 05:26:12.935155   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_832.solverstate
I0603 05:26:16.795523   861 solver.cpp:316] Iteration 832, loss = 1.38757
I0603 05:26:16.795624   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:26:16.795644   861 solver.cpp:332]     Train net output #1: loss = 0.877668 (* 1 = 0.877668 loss)
I0603 05:26:16.795655   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.848257 (* 0.3 = 0.254477 loss)
I0603 05:26:16.795663   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.85141 (* 0.3 = 0.255423 loss)
I0603 05:26:16.795677   861 sgd_solver.cpp:176] Iteration 832, lr = 0.00365148
I0603 05:26:24.501812   861 solver.cpp:316] Iteration 834, loss = 1.24378
I0603 05:26:24.501868   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:26:24.501886   861 solver.cpp:332]     Train net output #1: loss = 0.796422 (* 1 = 0.796422 loss)
I0603 05:26:24.501896   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.767527 (* 0.3 = 0.230258 loss)
I0603 05:26:24.501906   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.723669 (* 0.3 = 0.217101 loss)
I0603 05:26:24.501921   861 sgd_solver.cpp:176] Iteration 834, lr = 0.00362284
I0603 05:26:39.954319   861 solver.cpp:316] Iteration 836, loss = 1.28401
I0603 05:26:39.954362   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:26:39.954375   861 solver.cpp:332]     Train net output #1: loss = 0.813735 (* 1 = 0.813735 loss)
I0603 05:26:39.954381   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.779562 (* 0.3 = 0.233869 loss)
I0603 05:26:39.954387   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.788037 (* 0.3 = 0.236411 loss)
I0603 05:26:39.954398   861 sgd_solver.cpp:176] Iteration 836, lr = 0.00359398
I0603 05:26:54.776795   861 solver.cpp:316] Iteration 838, loss = 1.39456
I0603 05:26:54.776911   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:26:54.776931   861 solver.cpp:332]     Train net output #1: loss = 0.887343 (* 1 = 0.887343 loss)
I0603 05:26:54.776940   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.842512 (* 0.3 = 0.252754 loss)
I0603 05:26:54.776950   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.848219 (* 0.3 = 0.254466 loss)
I0603 05:26:54.776964   861 sgd_solver.cpp:176] Iteration 838, lr = 0.00356488
I0603 05:27:04.637257   861 solver.cpp:316] Iteration 840, loss = 1.41001
I0603 05:27:04.637317   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:27:04.637336   861 solver.cpp:332]     Train net output #1: loss = 0.913859 (* 1 = 0.913859 loss)
I0603 05:27:04.637344   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.784251 (* 0.3 = 0.235275 loss)
I0603 05:27:04.637354   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.869594 (* 0.3 = 0.260878 loss)
I0603 05:27:04.637368   861 sgd_solver.cpp:176] Iteration 840, lr = 0.00353553
I0603 05:27:12.276293   861 solver.cpp:316] Iteration 842, loss = 1.44047
I0603 05:27:12.276351   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:27:12.276370   861 solver.cpp:332]     Train net output #1: loss = 0.921316 (* 1 = 0.921316 loss)
I0603 05:27:12.276379   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.888858 (* 0.3 = 0.266657 loss)
I0603 05:27:12.276388   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.841645 (* 0.3 = 0.252494 loss)
I0603 05:27:12.276403   861 sgd_solver.cpp:176] Iteration 842, lr = 0.00350595
I0603 05:27:19.871495   861 solver.cpp:316] Iteration 844, loss = 1.39517
I0603 05:27:19.871556   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:27:19.871569   861 solver.cpp:332]     Train net output #1: loss = 0.883681 (* 1 = 0.883681 loss)
I0603 05:27:19.871577   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.822806 (* 0.3 = 0.246842 loss)
I0603 05:27:19.871582   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.882158 (* 0.3 = 0.264648 loss)
I0603 05:27:19.871593   861 sgd_solver.cpp:176] Iteration 844, lr = 0.00347611
I0603 05:27:27.520921   861 solver.cpp:316] Iteration 846, loss = 1.42708
I0603 05:27:27.521088   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:27:27.521106   861 solver.cpp:332]     Train net output #1: loss = 0.936673 (* 1 = 0.936673 loss)
I0603 05:27:27.521112   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.798868 (* 0.3 = 0.23966 loss)
I0603 05:27:27.521118   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.835822 (* 0.3 = 0.250747 loss)
I0603 05:27:27.521131   861 sgd_solver.cpp:176] Iteration 846, lr = 0.00344601
I0603 05:27:35.374665   861 solver.cpp:316] Iteration 848, loss = 1.52342
I0603 05:27:35.374723   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:27:35.374737   861 solver.cpp:332]     Train net output #1: loss = 0.977847 (* 1 = 0.977847 loss)
I0603 05:27:35.374743   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.955012 (* 0.3 = 0.286504 loss)
I0603 05:27:35.374749   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.863582 (* 0.3 = 0.259075 loss)
I0603 05:27:35.374760   861 sgd_solver.cpp:176] Iteration 848, lr = 0.00341565
I0603 05:27:43.109694   861 solver.cpp:316] Iteration 850, loss = 1.37285
I0603 05:27:43.109757   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:27:43.109776   861 solver.cpp:332]     Train net output #1: loss = 0.862979 (* 1 = 0.862979 loss)
I0603 05:27:43.109786   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.829002 (* 0.3 = 0.248701 loss)
I0603 05:27:43.109796   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.870572 (* 0.3 = 0.261172 loss)
I0603 05:27:43.109810   861 sgd_solver.cpp:176] Iteration 850, lr = 0.00338502
I0603 05:27:50.802243   861 solver.cpp:316] Iteration 852, loss = 1.5415
I0603 05:27:50.802325   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:27:50.802343   861 solver.cpp:332]     Train net output #1: loss = 0.954798 (* 1 = 0.954798 loss)
I0603 05:27:50.802353   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.98213 (* 0.3 = 0.294639 loss)
I0603 05:27:50.802363   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.973526 (* 0.3 = 0.292058 loss)
I0603 05:27:50.802377   861 sgd_solver.cpp:176] Iteration 852, lr = 0.0033541
I0603 05:27:58.416476   861 solver.cpp:316] Iteration 854, loss = 1.26749
I0603 05:27:58.416661   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:27:58.416681   861 solver.cpp:332]     Train net output #1: loss = 0.783328 (* 1 = 0.783328 loss)
I0603 05:27:58.416692   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.792824 (* 0.3 = 0.237847 loss)
I0603 05:27:58.416702   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.821046 (* 0.3 = 0.246314 loss)
I0603 05:27:58.416715   861 sgd_solver.cpp:176] Iteration 854, lr = 0.0033229
I0603 05:28:06.106458   861 solver.cpp:316] Iteration 856, loss = 1.27542
I0603 05:28:06.106520   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:28:06.106539   861 solver.cpp:332]     Train net output #1: loss = 0.794609 (* 1 = 0.794609 loss)
I0603 05:28:06.106549   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.786689 (* 0.3 = 0.236007 loss)
I0603 05:28:06.106557   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.816031 (* 0.3 = 0.244809 loss)
I0603 05:28:06.106572   861 sgd_solver.cpp:176] Iteration 856, lr = 0.0032914
I0603 05:28:13.739075   861 solver.cpp:316] Iteration 858, loss = 1.18683
I0603 05:28:13.739138   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:28:13.739157   861 solver.cpp:332]     Train net output #1: loss = 0.772631 (* 1 = 0.772631 loss)
I0603 05:28:13.739167   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.660736 (* 0.3 = 0.198221 loss)
I0603 05:28:13.739176   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.719923 (* 0.3 = 0.215977 loss)
I0603 05:28:13.739190   861 sgd_solver.cpp:176] Iteration 858, lr = 0.0032596
I0603 05:28:21.396668   861 solver.cpp:316] Iteration 860, loss = 1.26243
I0603 05:28:21.396724   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:28:21.396739   861 solver.cpp:332]     Train net output #1: loss = 0.828968 (* 1 = 0.828968 loss)
I0603 05:28:21.396745   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.703588 (* 0.3 = 0.211077 loss)
I0603 05:28:21.396752   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.741274 (* 0.3 = 0.222382 loss)
I0603 05:28:21.396762   861 sgd_solver.cpp:176] Iteration 860, lr = 0.00322749
I0603 05:28:29.070768   861 solver.cpp:316] Iteration 862, loss = 1.54777
I0603 05:28:29.070919   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:28:29.070935   861 solver.cpp:332]     Train net output #1: loss = 0.993279 (* 1 = 0.993279 loss)
I0603 05:28:29.070942   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.911539 (* 0.3 = 0.273462 loss)
I0603 05:28:29.070948   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.936755 (* 0.3 = 0.281026 loss)
I0603 05:28:29.070960   861 sgd_solver.cpp:176] Iteration 862, lr = 0.00319505
I0603 05:28:32.946507   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_864.caffemodel
I0603 05:28:33.103164   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_864.solverstate
I0603 05:28:37.210232   861 solver.cpp:316] Iteration 864, loss = 1.19153
I0603 05:28:37.210309   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:28:37.210330   861 solver.cpp:332]     Train net output #1: loss = 0.733869 (* 1 = 0.733869 loss)
I0603 05:28:37.210340   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.783399 (* 0.3 = 0.23502 loss)
I0603 05:28:37.210348   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.742123 (* 0.3 = 0.222637 loss)
I0603 05:28:37.210362   861 sgd_solver.cpp:176] Iteration 864, lr = 0.00316228
I0603 05:28:44.970343   861 solver.cpp:316] Iteration 866, loss = 1.21493
I0603 05:28:44.970396   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:28:44.970408   861 solver.cpp:332]     Train net output #1: loss = 0.770794 (* 1 = 0.770794 loss)
I0603 05:28:44.970415   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.765134 (* 0.3 = 0.22954 loss)
I0603 05:28:44.970422   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.715311 (* 0.3 = 0.214593 loss)
I0603 05:28:44.970432   861 sgd_solver.cpp:176] Iteration 866, lr = 0.00312916
I0603 05:28:59.892858   861 solver.cpp:316] Iteration 868, loss = 1.22012
I0603 05:28:59.902317   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:28:59.902345   861 solver.cpp:332]     Train net output #1: loss = 0.79528 (* 1 = 0.79528 loss)
I0603 05:28:59.902353   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.675423 (* 0.3 = 0.202627 loss)
I0603 05:28:59.902359   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.740724 (* 0.3 = 0.222217 loss)
I0603 05:28:59.902369   861 sgd_solver.cpp:176] Iteration 868, lr = 0.0030957
I0603 05:29:14.707166   861 solver.cpp:316] Iteration 870, loss = 1.68678
I0603 05:29:14.707223   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:29:14.707240   861 solver.cpp:332]     Train net output #1: loss = 1.04743 (* 1 = 1.04743 loss)
I0603 05:29:14.707252   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.08879 (* 0.3 = 0.326638 loss)
I0603 05:29:14.707262   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.04239 (* 0.3 = 0.312716 loss)
I0603 05:29:14.707275   861 sgd_solver.cpp:176] Iteration 870, lr = 0.00306186
I0603 05:29:24.708776   861 solver.cpp:316] Iteration 872, loss = 1.19127
I0603 05:29:24.708837   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:29:24.708855   861 solver.cpp:332]     Train net output #1: loss = 0.745914 (* 1 = 0.745914 loss)
I0603 05:29:24.708864   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.672635 (* 0.3 = 0.201791 loss)
I0603 05:29:24.708873   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.811872 (* 0.3 = 0.243562 loss)
I0603 05:29:24.708887   861 sgd_solver.cpp:176] Iteration 872, lr = 0.00302765
I0603 05:29:32.369026   861 solver.cpp:316] Iteration 874, loss = 1.17551
I0603 05:29:32.369123   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:29:32.369143   861 solver.cpp:332]     Train net output #1: loss = 0.759678 (* 1 = 0.759678 loss)
I0603 05:29:32.369151   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.674969 (* 0.3 = 0.202491 loss)
I0603 05:29:32.369160   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.711146 (* 0.3 = 0.213344 loss)
I0603 05:29:32.369174   861 sgd_solver.cpp:176] Iteration 874, lr = 0.00299305
I0603 05:29:40.299880   861 solver.cpp:316] Iteration 876, loss = 1.38529
I0603 05:29:40.299940   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:29:40.299957   861 solver.cpp:332]     Train net output #1: loss = 0.874255 (* 1 = 0.874255 loss)
I0603 05:29:40.299968   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.850965 (* 0.3 = 0.25529 loss)
I0603 05:29:40.299978   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.852477 (* 0.3 = 0.255743 loss)
I0603 05:29:40.299991   861 sgd_solver.cpp:176] Iteration 876, lr = 0.00295804
I0603 05:29:47.966508   861 solver.cpp:316] Iteration 878, loss = 1.31565
I0603 05:29:47.966567   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:29:47.966583   861 solver.cpp:332]     Train net output #1: loss = 0.828797 (* 1 = 0.828797 loss)
I0603 05:29:47.966593   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.805377 (* 0.3 = 0.241613 loss)
I0603 05:29:47.966603   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.817475 (* 0.3 = 0.245242 loss)
I0603 05:29:47.966617   861 sgd_solver.cpp:176] Iteration 878, lr = 0.00292261
I0603 05:29:55.628880   861 solver.cpp:316] Iteration 880, loss = 1.63852
I0603 05:29:55.628942   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:29:55.628958   861 solver.cpp:332]     Train net output #1: loss = 1.05243 (* 1 = 1.05243 loss)
I0603 05:29:55.628968   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.0119 (* 0.3 = 0.303569 loss)
I0603 05:29:55.628978   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.941729 (* 0.3 = 0.282519 loss)
I0603 05:29:55.628991   861 sgd_solver.cpp:176] Iteration 880, lr = 0.00288675
I0603 05:30:03.310757   861 solver.cpp:316] Iteration 882, loss = 1.4085
I0603 05:30:03.310879   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:30:03.310900   861 solver.cpp:332]     Train net output #1: loss = 0.862591 (* 1 = 0.862591 loss)
I0603 05:30:03.310910   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.879883 (* 0.3 = 0.263965 loss)
I0603 05:30:03.310920   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.939817 (* 0.3 = 0.281945 loss)
I0603 05:30:03.310935   861 sgd_solver.cpp:176] Iteration 882, lr = 0.00285044
I0603 05:30:10.920884   861 solver.cpp:316] Iteration 884, loss = 1.63496
I0603 05:30:10.920946   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:30:10.920964   861 solver.cpp:332]     Train net output #1: loss = 1.05885 (* 1 = 1.05885 loss)
I0603 05:30:10.920974   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.933858 (* 0.3 = 0.280157 loss)
I0603 05:30:10.920982   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.986494 (* 0.3 = 0.295948 loss)
I0603 05:30:10.920997   861 sgd_solver.cpp:176] Iteration 884, lr = 0.00281366
I0603 05:30:18.531007   861 solver.cpp:316] Iteration 886, loss = 1.40125
I0603 05:30:18.531064   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:30:18.531083   861 solver.cpp:332]     Train net output #1: loss = 0.86867 (* 1 = 0.86867 loss)
I0603 05:30:18.531093   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.886207 (* 0.3 = 0.265862 loss)
I0603 05:30:18.531103   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.889042 (* 0.3 = 0.266713 loss)
I0603 05:30:18.531118   861 sgd_solver.cpp:176] Iteration 886, lr = 0.00277639
I0603 05:30:26.193927   861 solver.cpp:316] Iteration 888, loss = 1.43909
I0603 05:30:26.197835   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:30:26.197867   861 solver.cpp:332]     Train net output #1: loss = 0.92032 (* 1 = 0.92032 loss)
I0603 05:30:26.197880   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847112 (* 0.3 = 0.254134 loss)
I0603 05:30:26.197891   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.882123 (* 0.3 = 0.264637 loss)
I0603 05:30:26.197907   861 sgd_solver.cpp:176] Iteration 888, lr = 0.00273861
I0603 05:30:33.825415   861 solver.cpp:316] Iteration 890, loss = 1.29716
I0603 05:30:33.825546   861 solver.cpp:332]     Train net output #0: accuracy = 0.40625
I0603 05:30:33.825565   861 solver.cpp:332]     Train net output #1: loss = 0.8311 (* 1 = 0.8311 loss)
I0603 05:30:33.825577   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.696499 (* 0.3 = 0.20895 loss)
I0603 05:30:33.825587   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.857023 (* 0.3 = 0.257107 loss)
I0603 05:30:33.825601   861 sgd_solver.cpp:176] Iteration 890, lr = 0.00270031
I0603 05:30:41.666307   861 solver.cpp:316] Iteration 892, loss = 1.19903
I0603 05:30:41.666364   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:30:41.666383   861 solver.cpp:332]     Train net output #1: loss = 0.77726 (* 1 = 0.77726 loss)
I0603 05:30:41.666393   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.685833 (* 0.3 = 0.20575 loss)
I0603 05:30:41.666401   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.720071 (* 0.3 = 0.216021 loss)
I0603 05:30:41.666416   861 sgd_solver.cpp:176] Iteration 892, lr = 0.00266145
I0603 05:30:49.347081   861 solver.cpp:316] Iteration 894, loss = 1.53416
I0603 05:30:49.347142   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:30:49.347160   861 solver.cpp:332]     Train net output #1: loss = 0.947887 (* 1 = 0.947887 loss)
I0603 05:30:49.347169   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00598 (* 0.3 = 0.301795 loss)
I0603 05:30:49.347179   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.948264 (* 0.3 = 0.284479 loss)
I0603 05:30:49.347193   861 sgd_solver.cpp:176] Iteration 894, lr = 0.00262202
I0603 05:30:53.211336   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_896.caffemodel
I0603 05:30:53.367586   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_896.solverstate
I0603 05:30:57.239598   861 solver.cpp:316] Iteration 896, loss = 1.22142
I0603 05:30:57.239658   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 05:30:57.239677   861 solver.cpp:332]     Train net output #1: loss = 0.750832 (* 1 = 0.750832 loss)
I0603 05:30:57.239687   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.792912 (* 0.3 = 0.237874 loss)
I0603 05:30:57.239696   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.775725 (* 0.3 = 0.232717 loss)
I0603 05:30:57.239711   861 sgd_solver.cpp:176] Iteration 896, lr = 0.00258199
I0603 05:31:04.897979   861 solver.cpp:316] Iteration 898, loss = 1.13676
I0603 05:31:04.898094   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:31:04.898113   861 solver.cpp:332]     Train net output #1: loss = 0.739296 (* 1 = 0.739296 loss)
I0603 05:31:04.898123   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.674998 (* 0.3 = 0.202499 loss)
I0603 05:31:04.898133   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.649893 (* 0.3 = 0.194968 loss)
I0603 05:31:04.898149   861 sgd_solver.cpp:176] Iteration 898, lr = 0.00254133
I0603 05:31:19.778316   861 solver.cpp:316] Iteration 900, loss = 1.3397
I0603 05:31:19.778362   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:31:19.778375   861 solver.cpp:332]     Train net output #1: loss = 0.887721 (* 1 = 0.887721 loss)
I0603 05:31:19.778383   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.718331 (* 0.3 = 0.215499 loss)
I0603 05:31:19.778388   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.788271 (* 0.3 = 0.236481 loss)
I0603 05:31:19.778399   861 sgd_solver.cpp:176] Iteration 900, lr = 0.0025
I0603 05:31:34.774312   861 solver.cpp:316] Iteration 902, loss = 1.72399
I0603 05:31:34.774363   861 solver.cpp:332]     Train net output #0: accuracy = 0.28125
I0603 05:31:34.774375   861 solver.cpp:332]     Train net output #1: loss = 1.0956 (* 1 = 1.0956 loss)
I0603 05:31:34.774384   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.03865 (* 0.3 = 0.311595 loss)
I0603 05:31:34.774389   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.05596 (* 0.3 = 0.316788 loss)
I0603 05:31:34.774400   861 sgd_solver.cpp:176] Iteration 902, lr = 0.00245798
I0603 05:31:44.773500   861 solver.cpp:316] Iteration 904, loss = 1.22553
I0603 05:31:44.773670   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:31:44.773689   861 solver.cpp:332]     Train net output #1: loss = 0.759324 (* 1 = 0.759324 loss)
I0603 05:31:44.773696   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.754518 (* 0.3 = 0.226355 loss)
I0603 05:31:44.773702   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.799517 (* 0.3 = 0.239855 loss)
I0603 05:31:44.773713   861 sgd_solver.cpp:176] Iteration 904, lr = 0.00241523
I0603 05:31:52.424963   861 solver.cpp:316] Iteration 906, loss = 1.27134
I0603 05:31:52.425032   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:31:52.425053   861 solver.cpp:332]     Train net output #1: loss = 0.82963 (* 1 = 0.82963 loss)
I0603 05:31:52.425065   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.746116 (* 0.3 = 0.223835 loss)
I0603 05:31:52.425076   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.726256 (* 0.3 = 0.217877 loss)
I0603 05:31:52.425092   861 sgd_solver.cpp:176] Iteration 906, lr = 0.00237171
I0603 05:32:00.038872   861 solver.cpp:316] Iteration 908, loss = 1.14407
I0603 05:32:00.038931   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:32:00.038951   861 solver.cpp:332]     Train net output #1: loss = 0.724623 (* 1 = 0.724623 loss)
I0603 05:32:00.038961   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.692475 (* 0.3 = 0.207743 loss)
I0603 05:32:00.038970   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.705668 (* 0.3 = 0.2117 loss)
I0603 05:32:00.038985   861 sgd_solver.cpp:176] Iteration 908, lr = 0.00232737
I0603 05:32:07.723878   861 solver.cpp:316] Iteration 910, loss = 1.41534
I0603 05:32:07.723933   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:32:07.723950   861 solver.cpp:332]     Train net output #1: loss = 0.908644 (* 1 = 0.908644 loss)
I0603 05:32:07.723961   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.843436 (* 0.3 = 0.253031 loss)
I0603 05:32:07.723971   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.845539 (* 0.3 = 0.253662 loss)
I0603 05:32:07.723986   861 sgd_solver.cpp:176] Iteration 910, lr = 0.00228218
I0603 05:32:15.388535   861 solver.cpp:316] Iteration 912, loss = 1.61743
I0603 05:32:15.388651   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:32:15.388672   861 solver.cpp:332]     Train net output #1: loss = 1.02227 (* 1 = 1.02227 loss)
I0603 05:32:15.388684   861 solver.cpp:332]     Train net output #2: loss1/loss = 1.00557 (* 0.3 = 0.301672 loss)
I0603 05:32:15.388694   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.978301 (* 0.3 = 0.29349 loss)
I0603 05:32:15.388708   861 sgd_solver.cpp:176] Iteration 912, lr = 0.00223607
I0603 05:32:23.048877   861 solver.cpp:316] Iteration 914, loss = 1.3667
I0603 05:32:23.048941   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:32:23.048959   861 solver.cpp:332]     Train net output #1: loss = 0.89351 (* 1 = 0.89351 loss)
I0603 05:32:23.048969   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.822776 (* 0.3 = 0.246833 loss)
I0603 05:32:23.048979   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.754512 (* 0.3 = 0.226354 loss)
I0603 05:32:23.048993   861 sgd_solver.cpp:176] Iteration 914, lr = 0.00218899
I0603 05:32:30.677858   861 solver.cpp:316] Iteration 916, loss = 1.45433
I0603 05:32:30.677912   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:32:30.677925   861 solver.cpp:332]     Train net output #1: loss = 0.935569 (* 1 = 0.935569 loss)
I0603 05:32:30.677933   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.847461 (* 0.3 = 0.254238 loss)
I0603 05:32:30.677939   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.881743 (* 0.3 = 0.264523 loss)
I0603 05:32:30.677950   861 sgd_solver.cpp:176] Iteration 916, lr = 0.00214087
I0603 05:32:38.541584   861 solver.cpp:316] Iteration 918, loss = 1.2691
I0603 05:32:38.541643   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:32:38.541657   861 solver.cpp:332]     Train net output #1: loss = 0.838616 (* 1 = 0.838616 loss)
I0603 05:32:38.541664   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.724599 (* 0.3 = 0.21738 loss)
I0603 05:32:38.541671   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.710351 (* 0.3 = 0.213105 loss)
I0603 05:32:38.541682   861 sgd_solver.cpp:176] Iteration 918, lr = 0.00209165
I0603 05:32:46.238418   861 solver.cpp:316] Iteration 920, loss = 1.48437
I0603 05:32:46.238575   861 solver.cpp:332]     Train net output #0: accuracy = 0.53125
I0603 05:32:46.238598   861 solver.cpp:332]     Train net output #1: loss = 0.929111 (* 1 = 0.929111 loss)
I0603 05:32:46.238611   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.839022 (* 0.3 = 0.251707 loss)
I0603 05:32:46.238621   861 solver.cpp:332]     Train net output #3: loss2/loss = 1.01185 (* 0.3 = 0.303556 loss)
I0603 05:32:46.238636   861 sgd_solver.cpp:176] Iteration 920, lr = 0.00204124
I0603 05:32:53.883631   861 solver.cpp:316] Iteration 922, loss = 1.16399
I0603 05:32:53.883688   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:32:53.883702   861 solver.cpp:332]     Train net output #1: loss = 0.738446 (* 1 = 0.738446 loss)
I0603 05:32:53.883708   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.655724 (* 0.3 = 0.196717 loss)
I0603 05:32:53.883715   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.762766 (* 0.3 = 0.22883 loss)
I0603 05:32:53.883726   861 sgd_solver.cpp:176] Iteration 922, lr = 0.00198956
I0603 05:33:01.518970   861 solver.cpp:316] Iteration 924, loss = 1.21035
I0603 05:33:01.519026   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:33:01.519040   861 solver.cpp:332]     Train net output #1: loss = 0.787308 (* 1 = 0.787308 loss)
I0603 05:33:01.519047   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.650428 (* 0.3 = 0.195128 loss)
I0603 05:33:01.519054   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.759725 (* 0.3 = 0.227918 loss)
I0603 05:33:01.519065   861 sgd_solver.cpp:176] Iteration 924, lr = 0.00193649
I0603 05:33:09.167829   861 solver.cpp:316] Iteration 926, loss = 1.30671
I0603 05:33:09.167886   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:33:09.167898   861 solver.cpp:332]     Train net output #1: loss = 0.817718 (* 1 = 0.817718 loss)
I0603 05:33:09.167906   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.854854 (* 0.3 = 0.256456 loss)
I0603 05:33:09.167912   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.775117 (* 0.3 = 0.232535 loss)
I0603 05:33:09.167922   861 sgd_solver.cpp:176] Iteration 926, lr = 0.00188193
I0603 05:33:13.041172   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_928.caffemodel
I0603 05:33:13.232944   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_928.solverstate
I0603 05:33:17.112141   861 solver.cpp:316] Iteration 928, loss = 1.22852
I0603 05:33:17.112318   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:33:17.112334   861 solver.cpp:332]     Train net output #1: loss = 0.758584 (* 1 = 0.758584 loss)
I0603 05:33:17.112342   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.762721 (* 0.3 = 0.228816 loss)
I0603 05:33:17.112349   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.803744 (* 0.3 = 0.241123 loss)
I0603 05:33:17.112360   861 sgd_solver.cpp:176] Iteration 928, lr = 0.00182574
I0603 05:33:24.819322   861 solver.cpp:316] Iteration 930, loss = 1.31568
I0603 05:33:24.819382   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:33:24.819396   861 solver.cpp:332]     Train net output #1: loss = 0.807581 (* 1 = 0.807581 loss)
I0603 05:33:24.819402   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.833111 (* 0.3 = 0.249933 loss)
I0603 05:33:24.819409   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.860549 (* 0.3 = 0.258165 loss)
I0603 05:33:24.819420   861 sgd_solver.cpp:176] Iteration 930, lr = 0.00176777
I0603 05:33:40.216588   861 solver.cpp:316] Iteration 932, loss = 1.22634
I0603 05:33:40.216632   861 solver.cpp:332]     Train net output #0: accuracy = 0.6875
I0603 05:33:40.216645   861 solver.cpp:332]     Train net output #1: loss = 0.778373 (* 1 = 0.778373 loss)
I0603 05:33:40.216653   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.75389 (* 0.3 = 0.226167 loss)
I0603 05:33:40.216660   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.739337 (* 0.3 = 0.221801 loss)
I0603 05:33:40.216670   861 sgd_solver.cpp:176] Iteration 932, lr = 0.00170782
I0603 05:33:54.916419   861 solver.cpp:316] Iteration 934, loss = 1.51103
I0603 05:33:54.916623   861 solver.cpp:332]     Train net output #0: accuracy = 0.4375
I0603 05:33:54.916646   861 solver.cpp:332]     Train net output #1: loss = 0.973419 (* 1 = 0.973419 loss)
I0603 05:33:54.916656   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.874409 (* 0.3 = 0.262323 loss)
I0603 05:33:54.916666   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.917623 (* 0.3 = 0.275287 loss)
I0603 05:33:54.916682   861 sgd_solver.cpp:176] Iteration 934, lr = 0.0016457
I0603 05:34:04.939266   861 solver.cpp:316] Iteration 936, loss = 1.17279
I0603 05:34:04.939328   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:34:04.939347   861 solver.cpp:332]     Train net output #1: loss = 0.75316 (* 1 = 0.75316 loss)
I0603 05:34:04.939357   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.671646 (* 0.3 = 0.201494 loss)
I0603 05:34:04.939366   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.727111 (* 0.3 = 0.218133 loss)
I0603 05:34:04.939381   861 sgd_solver.cpp:176] Iteration 936, lr = 0.00158114
I0603 05:34:12.558828   861 solver.cpp:316] Iteration 938, loss = 1.32286
I0603 05:34:12.558886   861 solver.cpp:332]     Train net output #0: accuracy = 0.46875
I0603 05:34:12.558903   861 solver.cpp:332]     Train net output #1: loss = 0.878105 (* 1 = 0.878105 loss)
I0603 05:34:12.558914   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.737492 (* 0.3 = 0.221248 loss)
I0603 05:34:12.558924   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.745036 (* 0.3 = 0.223511 loss)
I0603 05:34:12.558938   861 sgd_solver.cpp:176] Iteration 938, lr = 0.00151383
I0603 05:34:20.221460   861 solver.cpp:316] Iteration 940, loss = 1.16341
I0603 05:34:20.221521   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:34:20.221539   861 solver.cpp:332]     Train net output #1: loss = 0.721616 (* 1 = 0.721616 loss)
I0603 05:34:20.221549   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.722822 (* 0.3 = 0.216847 loss)
I0603 05:34:20.221557   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.749842 (* 0.3 = 0.224953 loss)
I0603 05:34:20.221572   861 sgd_solver.cpp:176] Iteration 940, lr = 0.00144337
I0603 05:34:27.907133   861 solver.cpp:316] Iteration 942, loss = 1.39532
I0603 05:34:27.907263   861 solver.cpp:332]     Train net output #0: accuracy = 0.59375
I0603 05:34:27.907282   861 solver.cpp:332]     Train net output #1: loss = 0.88599 (* 1 = 0.88599 loss)
I0603 05:34:27.907294   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.802622 (* 0.3 = 0.240786 loss)
I0603 05:34:27.907304   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.895158 (* 0.3 = 0.268547 loss)
I0603 05:34:27.907320   861 sgd_solver.cpp:176] Iteration 942, lr = 0.00136931
I0603 05:34:35.735249   861 solver.cpp:316] Iteration 944, loss = 1.52448
I0603 05:34:35.735311   861 solver.cpp:332]     Train net output #0: accuracy = 0.34375
I0603 05:34:35.735329   861 solver.cpp:332]     Train net output #1: loss = 1.02859 (* 1 = 1.02859 loss)
I0603 05:34:35.735339   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.79223 (* 0.3 = 0.237669 loss)
I0603 05:34:35.735349   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.860713 (* 0.3 = 0.258214 loss)
I0603 05:34:35.735363   861 sgd_solver.cpp:176] Iteration 944, lr = 0.00129099
I0603 05:34:43.420025   861 solver.cpp:316] Iteration 946, loss = 1.32576
I0603 05:34:43.420083   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:34:43.420099   861 solver.cpp:332]     Train net output #1: loss = 0.84635 (* 1 = 0.84635 loss)
I0603 05:34:43.420110   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.859668 (* 0.3 = 0.2579 loss)
I0603 05:34:43.420120   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.73837 (* 0.3 = 0.221511 loss)
I0603 05:34:43.420135   861 sgd_solver.cpp:176] Iteration 946, lr = 0.00120762
I0603 05:34:51.104127   861 solver.cpp:316] Iteration 948, loss = 1.21127
I0603 05:34:51.104187   861 solver.cpp:332]     Train net output #0: accuracy = 0.71875
I0603 05:34:51.104205   861 solver.cpp:332]     Train net output #1: loss = 0.815529 (* 1 = 0.815529 loss)
I0603 05:34:51.104216   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.630796 (* 0.3 = 0.189239 loss)
I0603 05:34:51.104225   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.688356 (* 0.3 = 0.206507 loss)
I0603 05:34:51.104239   861 sgd_solver.cpp:176] Iteration 948, lr = 0.00111803
I0603 05:34:58.729545   861 solver.cpp:316] Iteration 950, loss = 1.36254
I0603 05:34:58.729658   861 solver.cpp:332]     Train net output #0: accuracy = 0.5625
I0603 05:34:58.729679   861 solver.cpp:332]     Train net output #1: loss = 0.862 (* 1 = 0.862 loss)
I0603 05:34:58.729691   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.846624 (* 0.3 = 0.253987 loss)
I0603 05:34:58.729699   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.821841 (* 0.3 = 0.246552 loss)
I0603 05:34:58.729713   861 sgd_solver.cpp:176] Iteration 950, lr = 0.00102062
I0603 05:35:06.399448   861 solver.cpp:316] Iteration 952, loss = 1.32563
I0603 05:35:06.399507   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:35:06.399528   861 solver.cpp:332]     Train net output #1: loss = 0.848514 (* 1 = 0.848514 loss)
I0603 05:35:06.399538   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.74859 (* 0.3 = 0.224577 loss)
I0603 05:35:06.399547   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.8418 (* 0.3 = 0.25254 loss)
I0603 05:35:06.399562   861 sgd_solver.cpp:176] Iteration 952, lr = 0.00091287
I0603 05:35:14.025504   861 solver.cpp:316] Iteration 954, loss = 1.35127
I0603 05:35:14.025563   861 solver.cpp:332]     Train net output #0: accuracy = 0.5
I0603 05:35:14.025580   861 solver.cpp:332]     Train net output #1: loss = 0.882272 (* 1 = 0.882272 loss)
I0603 05:35:14.025591   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.778583 (* 0.3 = 0.233575 loss)
I0603 05:35:14.025600   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.78473 (* 0.3 = 0.235419 loss)
I0603 05:35:14.025616   861 sgd_solver.cpp:176] Iteration 954, lr = 0.000790571
I0603 05:35:21.675133   861 solver.cpp:316] Iteration 956, loss = 1.19037
I0603 05:35:21.675191   861 solver.cpp:332]     Train net output #0: accuracy = 0.625
I0603 05:35:21.675209   861 solver.cpp:332]     Train net output #1: loss = 0.759217 (* 1 = 0.759217 loss)
I0603 05:35:21.675220   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.691674 (* 0.3 = 0.207502 loss)
I0603 05:35:21.675230   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.745508 (* 0.3 = 0.223652 loss)
I0603 05:35:21.675242   861 sgd_solver.cpp:176] Iteration 956, lr = 0.000645497
I0603 05:35:29.368583   861 solver.cpp:316] Iteration 958, loss = 1.25063
I0603 05:35:29.368796   861 solver.cpp:332]     Train net output #0: accuracy = 0.65625
I0603 05:35:29.368816   861 solver.cpp:332]     Train net output #1: loss = 0.796183 (* 1 = 0.796183 loss)
I0603 05:35:29.368827   861 solver.cpp:332]     Train net output #2: loss1/loss = 0.743492 (* 0.3 = 0.223048 loss)
I0603 05:35:29.368837   861 solver.cpp:332]     Train net output #3: loss2/loss = 0.771338 (* 0.3 = 0.231401 loss)
I0603 05:35:29.368852   861 sgd_solver.cpp:176] Iteration 958, lr = 0.000456438
I0603 05:35:33.204783   861 solver.cpp:821] Snapshotting to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_960.caffemodel
I0603 05:35:33.369417   861 sgd_solver.cpp:498] Snapshotting solver state to binary proto file /workspace/dlsdk/jobs/caffe/models/b5143a70-cfeb-433e-b066-800d9d8263f9/snapshot_iter_960.solverstate
I0603 05:35:35.032167   861 solver.cpp:534] Iteration 960, loss = 1.34066
I0603 05:35:35.032217   861 solver.cpp:543] Optimization Done.
I0603 05:35:35.032224   861 caffe.cpp:332] Optimization Done.
